[{"type":"js","data":"(function () {\n\n/* Imports */\nvar Meteor = Package.meteor.Meteor;\nvar global = Package.meteor.global;\nvar meteorEnv = Package.meteor.meteorEnv;\nvar NpmModuleMongodb = Package['npm-mongo'].NpmModuleMongodb;\nvar NpmModuleMongodbVersion = Package['npm-mongo'].NpmModuleMongodbVersion;\nvar AllowDeny = Package['allow-deny'].AllowDeny;\nvar Random = Package.random.Random;\nvar EJSON = Package.ejson.EJSON;\nvar LocalCollection = Package.minimongo.LocalCollection;\nvar Minimongo = Package.minimongo.Minimongo;\nvar DDP = Package['ddp-client'].DDP;\nvar DDPServer = Package['ddp-server'].DDPServer;\nvar Tracker = Package.tracker.Tracker;\nvar Deps = Package.tracker.Deps;\nvar DiffSequence = Package['diff-sequence'].DiffSequence;\nvar MongoID = Package['mongo-id'].MongoID;\nvar check = Package.check.check;\nvar Match = Package.check.Match;\nvar ECMAScript = Package.ecmascript.ECMAScript;\nvar _ = Package.underscore._;\nvar MaxHeap = Package['binary-heap'].MaxHeap;\nvar MinHeap = Package['binary-heap'].MinHeap;\nvar MinMaxHeap = Package['binary-heap'].MinMaxHeap;\nvar Hook = Package['callback-hook'].Hook;\nvar meteorInstall = Package.modules.meteorInstall;\nvar meteorBabelHelpers = Package['babel-runtime'].meteorBabelHelpers;\nvar Promise = Package.promise.Promise;\n\n/* Package-scope variables */\nvar MongoInternals, MongoTest, MongoConnection, CursorDescription, Cursor, listenAll, forEachTrigger, OPLOG_COLLECTION, idForOp, OplogHandle, ObserveMultiplexer, ObserveHandle, DocFetcher, PollingObserveDriver, OplogObserveDriver, Mongo, selector, callback, options;\n\nvar require = meteorInstall({\"node_modules\":{\"meteor\":{\"mongo\":{\"mongo_driver.js\":function(require,exports,module){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/mongo_driver.js                                                                                      //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\n/**\n * Provide a synchronous Collection API using fibers, backed by\n * MongoDB.  This is only for use on the server, and mostly identical\n * to the client API.\n *\n * NOTE: the public API methods must be run within a fiber. If you call\n * these outside of a fiber they will explode!\n */\nvar MongoDB = NpmModuleMongodb;\n\nvar Future = Npm.require('fibers/future');\n\nMongoInternals = {};\nMongoTest = {};\nMongoInternals.NpmModules = {\n  mongodb: {\n    version: NpmModuleMongodbVersion,\n    module: MongoDB\n  }\n}; // Older version of what is now available via\n// MongoInternals.NpmModules.mongodb.module.  It was never documented, but\n// people do use it.\n// XXX COMPAT WITH 1.0.3.2\n\nMongoInternals.NpmModule = MongoDB; // This is used to add or remove EJSON from the beginning of everything nested\n// inside an EJSON custom type. It should only be called on pure JSON!\n\nvar replaceNames = function (filter, thing) {\n  if (typeof thing === \"object\" && thing !== null) {\n    if (_.isArray(thing)) {\n      return _.map(thing, _.bind(replaceNames, null, filter));\n    }\n\n    var ret = {};\n\n    _.each(thing, function (value, key) {\n      ret[filter(key)] = replaceNames(filter, value);\n    });\n\n    return ret;\n  }\n\n  return thing;\n}; // Ensure that EJSON.clone keeps a Timestamp as a Timestamp (instead of just\n// doing a structural clone).\n// XXX how ok is this? what if there are multiple copies of MongoDB loaded?\n\n\nMongoDB.Timestamp.prototype.clone = function () {\n  // Timestamps should be immutable.\n  return this;\n};\n\nvar makeMongoLegal = function (name) {\n  return \"EJSON\" + name;\n};\n\nvar unmakeMongoLegal = function (name) {\n  return name.substr(5);\n};\n\nvar replaceMongoAtomWithMeteor = function (document) {\n  if (document instanceof MongoDB.Binary) {\n    var buffer = document.value(true);\n    return new Uint8Array(buffer);\n  }\n\n  if (document instanceof MongoDB.ObjectID) {\n    return new Mongo.ObjectID(document.toHexString());\n  }\n\n  if (document[\"EJSON$type\"] && document[\"EJSON$value\"] && _.size(document) === 2) {\n    return EJSON.fromJSONValue(replaceNames(unmakeMongoLegal, document));\n  }\n\n  if (document instanceof MongoDB.Timestamp) {\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\n    // this is a weird internal thing used in the oplog!) is the same as the\n    // Mongo representation. We need to do this explicitly or else we would do a\n    // structural clone and lose the prototype.\n    return document;\n  }\n\n  return undefined;\n};\n\nvar replaceMeteorAtomWithMongo = function (document) {\n  if (EJSON.isBinary(document)) {\n    // This does more copies than we'd like, but is necessary because\n    // MongoDB.BSON only looks like it takes a Uint8Array (and doesn't actually\n    // serialize it correctly).\n    return new MongoDB.Binary(Buffer.from(document));\n  }\n\n  if (document instanceof Mongo.ObjectID) {\n    return new MongoDB.ObjectID(document.toHexString());\n  }\n\n  if (document instanceof MongoDB.Timestamp) {\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\n    // this is a weird internal thing used in the oplog!) is the same as the\n    // Mongo representation. We need to do this explicitly or else we would do a\n    // structural clone and lose the prototype.\n    return document;\n  }\n\n  if (EJSON._isCustomType(document)) {\n    return replaceNames(makeMongoLegal, EJSON.toJSONValue(document));\n  } // It is not ordinarily possible to stick dollar-sign keys into mongo\n  // so we don't bother checking for things that need escaping at this time.\n\n\n  return undefined;\n};\n\nvar replaceTypes = function (document, atomTransformer) {\n  if (typeof document !== 'object' || document === null) return document;\n  var replacedTopLevelAtom = atomTransformer(document);\n  if (replacedTopLevelAtom !== undefined) return replacedTopLevelAtom;\n  var ret = document;\n\n  _.each(document, function (val, key) {\n    var valReplaced = replaceTypes(val, atomTransformer);\n\n    if (val !== valReplaced) {\n      // Lazy clone. Shallow copy.\n      if (ret === document) ret = _.clone(document);\n      ret[key] = valReplaced;\n    }\n  });\n\n  return ret;\n};\n\nMongoConnection = function (url, options) {\n  var self = this;\n  options = options || {};\n  self._observeMultiplexers = {};\n  self._onFailoverHook = new Hook();\n  var mongoOptions = Object.assign({\n    // Reconnect on error.\n    autoReconnect: true,\n    // Try to reconnect forever, instead of stopping after 30 tries (the\n    // default), with each attempt separated by 1000ms.\n    reconnectTries: Infinity,\n    ignoreUndefined: true\n  }, Mongo._connectionOptions); // Disable the native parser by default, unless specifically enabled\n  // in the mongo URL.\n  // - The native driver can cause errors which normally would be\n  //   thrown, caught, and handled into segfaults that take down the\n  //   whole app.\n  // - Binary modules don't yet work when you bundle and move the bundle\n  //   to a different platform (aka deploy)\n  // We should revisit this after binary npm module support lands.\n\n  if (!/[\\?&]native_?[pP]arser=/.test(url)) {\n    mongoOptions.native_parser = false;\n  } // Internally the oplog connections specify their own poolSize\n  // which we don't want to overwrite with any user defined value\n\n\n  if (_.has(options, 'poolSize')) {\n    // If we just set this for \"server\", replSet will override it. If we just\n    // set it for replSet, it will be ignored if we're not using a replSet.\n    mongoOptions.poolSize = options.poolSize;\n  }\n\n  self.db = null; // We keep track of the ReplSet's primary, so that we can trigger hooks when\n  // it changes.  The Node driver's joined callback seems to fire way too\n  // often, which is why we need to track it ourselves.\n\n  self._primary = null;\n  self._oplogHandle = null;\n  self._docFetcher = null;\n  var connectFuture = new Future();\n  MongoDB.connect(url, mongoOptions, Meteor.bindEnvironment(function (err, db) {\n    if (err) {\n      throw err;\n    } // First, figure out what the current primary is, if any.\n\n\n    if (db.serverConfig.isMasterDoc) {\n      self._primary = db.serverConfig.isMasterDoc.primary;\n    }\n\n    db.serverConfig.on('joined', Meteor.bindEnvironment(function (kind, doc) {\n      if (kind === 'primary') {\n        if (doc.primary !== self._primary) {\n          self._primary = doc.primary;\n\n          self._onFailoverHook.each(function (callback) {\n            callback();\n            return true;\n          });\n        }\n      } else if (doc.me === self._primary) {\n        // The thing we thought was primary is now something other than\n        // primary.  Forget that we thought it was primary.  (This means\n        // that if a server stops being primary and then starts being\n        // primary again without another server becoming primary in the\n        // middle, we'll correctly count it as a failover.)\n        self._primary = null;\n      }\n    })); // Allow the constructor to return.\n\n    connectFuture['return'](db);\n  }, connectFuture.resolver() // onException\n  )); // Wait for the connection to be successful; throws on failure.\n\n  self.db = connectFuture.wait();\n\n  if (options.oplogUrl && !Package['disable-oplog']) {\n    self._oplogHandle = new OplogHandle(options.oplogUrl, self.db.databaseName);\n    self._docFetcher = new DocFetcher(self);\n  }\n};\n\nMongoConnection.prototype.close = function () {\n  var self = this;\n  if (!self.db) throw Error(\"close called before Connection created?\"); // XXX probably untested\n\n  var oplogHandle = self._oplogHandle;\n  self._oplogHandle = null;\n  if (oplogHandle) oplogHandle.stop(); // Use Future.wrap so that errors get thrown. This happens to\n  // work even outside a fiber since the 'close' method is not\n  // actually asynchronous.\n\n  Future.wrap(_.bind(self.db.close, self.db))(true).wait();\n}; // Returns the Mongo Collection object; may yield.\n\n\nMongoConnection.prototype.rawCollection = function (collectionName) {\n  var self = this;\n  if (!self.db) throw Error(\"rawCollection called before Connection created?\");\n  var future = new Future();\n  self.db.collection(collectionName, future.resolver());\n  return future.wait();\n};\n\nMongoConnection.prototype._createCappedCollection = function (collectionName, byteSize, maxDocuments) {\n  var self = this;\n  if (!self.db) throw Error(\"_createCappedCollection called before Connection created?\");\n  var future = new Future();\n  self.db.createCollection(collectionName, {\n    capped: true,\n    size: byteSize,\n    max: maxDocuments\n  }, future.resolver());\n  future.wait();\n}; // This should be called synchronously with a write, to create a\n// transaction on the current write fence, if any. After we can read\n// the write, and after observers have been notified (or at least,\n// after the observer notifiers have added themselves to the write\n// fence), you should call 'committed()' on the object returned.\n\n\nMongoConnection.prototype._maybeBeginWrite = function () {\n  var fence = DDPServer._CurrentWriteFence.get();\n\n  if (fence) {\n    return fence.beginWrite();\n  } else {\n    return {\n      committed: function () {}\n    };\n  }\n}; // Internal interface: adds a callback which is called when the Mongo primary\n// changes. Returns a stop handle.\n\n\nMongoConnection.prototype._onFailover = function (callback) {\n  return this._onFailoverHook.register(callback);\n}; //////////// Public API //////////\n// The write methods block until the database has confirmed the write (it may\n// not be replicated or stable on disk, but one server has confirmed it) if no\n// callback is provided. If a callback is provided, then they call the callback\n// when the write is confirmed. They return nothing on success, and raise an\n// exception on failure.\n//\n// After making a write (with insert, update, remove), observers are\n// notified asynchronously. If you want to receive a callback once all\n// of the observer notifications have landed for your write, do the\n// writes inside a write fence (set DDPServer._CurrentWriteFence to a new\n// _WriteFence, and then set a callback on the write fence.)\n//\n// Since our execution environment is single-threaded, this is\n// well-defined -- a write \"has been made\" if it's returned, and an\n// observer \"has been notified\" if its callback has returned.\n\n\nvar writeCallback = function (write, refresh, callback) {\n  return function (err, result) {\n    if (!err) {\n      // XXX We don't have to run this on error, right?\n      try {\n        refresh();\n      } catch (refreshErr) {\n        if (callback) {\n          callback(refreshErr);\n          return;\n        } else {\n          throw refreshErr;\n        }\n      }\n    }\n\n    write.committed();\n\n    if (callback) {\n      callback(err, result);\n    } else if (err) {\n      throw err;\n    }\n  };\n};\n\nvar bindEnvironmentForWrite = function (callback) {\n  return Meteor.bindEnvironment(callback, \"Mongo write\");\n};\n\nMongoConnection.prototype._insert = function (collection_name, document, callback) {\n  var self = this;\n\n  var sendError = function (e) {\n    if (callback) return callback(e);\n    throw e;\n  };\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n    sendError(e);\n    return;\n  }\n\n  if (!(LocalCollection._isPlainObject(document) && !EJSON._isCustomType(document))) {\n    sendError(new Error(\"Only plain objects may be inserted into MongoDB\"));\n    return;\n  }\n\n  var write = self._maybeBeginWrite();\n\n  var refresh = function () {\n    Meteor.refresh({\n      collection: collection_name,\n      id: document._id\n    });\n  };\n\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\n\n  try {\n    var collection = self.rawCollection(collection_name);\n    collection.insert(replaceTypes(document, replaceMeteorAtomWithMongo), {\n      safe: true\n    }, callback);\n  } catch (err) {\n    write.committed();\n    throw err;\n  }\n}; // Cause queries that may be affected by the selector to poll in this write\n// fence.\n\n\nMongoConnection.prototype._refresh = function (collectionName, selector) {\n  var refreshKey = {\n    collection: collectionName\n  }; // If we know which documents we're removing, don't poll queries that are\n  // specific to other documents. (Note that multiple notifications here should\n  // not cause multiple polls, since all our listener is doing is enqueueing a\n  // poll.)\n\n  var specificIds = LocalCollection._idsMatchedBySelector(selector);\n\n  if (specificIds) {\n    _.each(specificIds, function (id) {\n      Meteor.refresh(_.extend({\n        id: id\n      }, refreshKey));\n    });\n  } else {\n    Meteor.refresh(refreshKey);\n  }\n};\n\nMongoConnection.prototype._remove = function (collection_name, selector, callback) {\n  var self = this;\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n\n    if (callback) {\n      return callback(e);\n    } else {\n      throw e;\n    }\n  }\n\n  var write = self._maybeBeginWrite();\n\n  var refresh = function () {\n    self._refresh(collection_name, selector);\n  };\n\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\n\n  try {\n    var collection = self.rawCollection(collection_name);\n\n    var wrappedCallback = function (err, driverResult) {\n      callback(err, transformResult(driverResult).numberAffected);\n    };\n\n    collection.remove(replaceTypes(selector, replaceMeteorAtomWithMongo), {\n      safe: true\n    }, wrappedCallback);\n  } catch (err) {\n    write.committed();\n    throw err;\n  }\n};\n\nMongoConnection.prototype._dropCollection = function (collectionName, cb) {\n  var self = this;\n\n  var write = self._maybeBeginWrite();\n\n  var refresh = function () {\n    Meteor.refresh({\n      collection: collectionName,\n      id: null,\n      dropCollection: true\n    });\n  };\n\n  cb = bindEnvironmentForWrite(writeCallback(write, refresh, cb));\n\n  try {\n    var collection = self.rawCollection(collectionName);\n    collection.drop(cb);\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n}; // For testing only.  Slightly better than `c.rawDatabase().dropDatabase()`\n// because it lets the test's fence wait for it to be complete.\n\n\nMongoConnection.prototype._dropDatabase = function (cb) {\n  var self = this;\n\n  var write = self._maybeBeginWrite();\n\n  var refresh = function () {\n    Meteor.refresh({\n      dropDatabase: true\n    });\n  };\n\n  cb = bindEnvironmentForWrite(writeCallback(write, refresh, cb));\n\n  try {\n    self.db.dropDatabase(cb);\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n};\n\nMongoConnection.prototype._update = function (collection_name, selector, mod, options, callback) {\n  var self = this;\n\n  if (!callback && options instanceof Function) {\n    callback = options;\n    options = null;\n  }\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n\n    if (callback) {\n      return callback(e);\n    } else {\n      throw e;\n    }\n  } // explicit safety check. null and undefined can crash the mongo\n  // driver. Although the node driver and minimongo do 'support'\n  // non-object modifier in that they don't crash, they are not\n  // meaningful operations and do not do anything. Defensively throw an\n  // error here.\n\n\n  if (!mod || typeof mod !== 'object') throw new Error(\"Invalid modifier. Modifier must be an object.\");\n\n  if (!(LocalCollection._isPlainObject(mod) && !EJSON._isCustomType(mod))) {\n    throw new Error(\"Only plain objects may be used as replacement\" + \" documents in MongoDB\");\n  }\n\n  if (!options) options = {};\n\n  var write = self._maybeBeginWrite();\n\n  var refresh = function () {\n    self._refresh(collection_name, selector);\n  };\n\n  callback = writeCallback(write, refresh, callback);\n\n  try {\n    var collection = self.rawCollection(collection_name);\n    var mongoOpts = {\n      safe: true\n    }; // explictly enumerate options that minimongo supports\n\n    if (options.upsert) mongoOpts.upsert = true;\n    if (options.multi) mongoOpts.multi = true; // Lets you get a more more full result from MongoDB. Use with caution:\n    // might not work with C.upsert (as opposed to C.update({upsert:true}) or\n    // with simulated upsert.\n\n    if (options.fullResult) mongoOpts.fullResult = true;\n    var mongoSelector = replaceTypes(selector, replaceMeteorAtomWithMongo);\n    var mongoMod = replaceTypes(mod, replaceMeteorAtomWithMongo);\n\n    var isModify = LocalCollection._isModificationMod(mongoMod);\n\n    if (options._forbidReplace && !isModify) {\n      var err = new Error(\"Invalid modifier. Replacements are forbidden.\");\n\n      if (callback) {\n        return callback(err);\n      } else {\n        throw err;\n      }\n    } // We've already run replaceTypes/replaceMeteorAtomWithMongo on\n    // selector and mod.  We assume it doesn't matter, as far as\n    // the behavior of modifiers is concerned, whether `_modify`\n    // is run on EJSON or on mongo-converted EJSON.\n    // Run this code up front so that it fails fast if someone uses\n    // a Mongo update operator we don't support.\n\n\n    let knownId;\n\n    if (options.upsert) {\n      try {\n        let newDoc = LocalCollection._createUpsertDocument(selector, mod);\n\n        knownId = newDoc._id;\n      } catch (err) {\n        if (callback) {\n          return callback(err);\n        } else {\n          throw err;\n        }\n      }\n    }\n\n    if (options.upsert && !isModify && !knownId && options.insertedId && !(options.insertedId instanceof Mongo.ObjectID && options.generatedId)) {\n      // In case of an upsert with a replacement, where there is no _id defined\n      // in either the query or the replacement doc, mongo will generate an id itself.\n      // Therefore we need this special strategy if we want to control the id ourselves.\n      // We don't need to do this when:\n      // - This is not a replacement, so we can add an _id to $setOnInsert\n      // - The id is defined by query or mod we can just add it to the replacement doc\n      // - The user did not specify any id preference and the id is a Mongo ObjectId,\n      //     then we can just let Mongo generate the id\n      simulateUpsertWithInsertedId(collection, mongoSelector, mongoMod, options, // This callback does not need to be bindEnvironment'ed because\n      // simulateUpsertWithInsertedId() wraps it and then passes it through\n      // bindEnvironmentForWrite.\n      function (error, result) {\n        // If we got here via a upsert() call, then options._returnObject will\n        // be set and we should return the whole object. Otherwise, we should\n        // just return the number of affected docs to match the mongo API.\n        if (result && !options._returnObject) {\n          callback(error, result.numberAffected);\n        } else {\n          callback(error, result);\n        }\n      });\n    } else {\n      if (options.upsert && !knownId && options.insertedId && isModify) {\n        if (!mongoMod.hasOwnProperty('$setOnInsert')) {\n          mongoMod.$setOnInsert = {};\n        }\n\n        knownId = options.insertedId;\n        Object.assign(mongoMod.$setOnInsert, replaceTypes({\n          _id: options.insertedId\n        }, replaceMeteorAtomWithMongo));\n      }\n\n      collection.update(mongoSelector, mongoMod, mongoOpts, bindEnvironmentForWrite(function (err, result) {\n        if (!err) {\n          var meteorResult = transformResult(result);\n\n          if (meteorResult && options._returnObject) {\n            // If this was an upsert() call, and we ended up\n            // inserting a new doc and we know its id, then\n            // return that id as well.\n            if (options.upsert && meteorResult.insertedId) {\n              if (knownId) {\n                meteorResult.insertedId = knownId;\n              } else if (meteorResult.insertedId instanceof MongoDB.ObjectID) {\n                meteorResult.insertedId = new Mongo.ObjectID(meteorResult.insertedId.toHexString());\n              }\n            }\n\n            callback(err, meteorResult);\n          } else {\n            callback(err, meteorResult.numberAffected);\n          }\n        } else {\n          callback(err);\n        }\n      }));\n    }\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n};\n\nvar transformResult = function (driverResult) {\n  var meteorResult = {\n    numberAffected: 0\n  };\n\n  if (driverResult) {\n    var mongoResult = driverResult.result; // On updates with upsert:true, the inserted values come as a list of\n    // upserted values -- even with options.multi, when the upsert does insert,\n    // it only inserts one element.\n\n    if (mongoResult.upserted) {\n      meteorResult.numberAffected += mongoResult.upserted.length;\n\n      if (mongoResult.upserted.length == 1) {\n        meteorResult.insertedId = mongoResult.upserted[0]._id;\n      }\n    } else {\n      meteorResult.numberAffected = mongoResult.n;\n    }\n  }\n\n  return meteorResult;\n};\n\nvar NUM_OPTIMISTIC_TRIES = 3; // exposed for testing\n\nMongoConnection._isCannotChangeIdError = function (err) {\n  // Mongo 3.2.* returns error as next Object:\n  // {name: String, code: Number, errmsg: String}\n  // Older Mongo returns:\n  // {name: String, code: Number, err: String}\n  var error = err.errmsg || err.err; // We don't use the error code here\n  // because the error code we observed it producing (16837) appears to be\n  // a far more generic error code based on examining the source.\n\n  if (error.indexOf('The _id field cannot be changed') === 0 || error.indexOf(\"the (immutable) field '_id' was found to have been altered to _id\") !== -1) {\n    return true;\n  }\n\n  return false;\n};\n\nvar simulateUpsertWithInsertedId = function (collection, selector, mod, options, callback) {\n  // STRATEGY: First try doing an upsert with a generated ID.\n  // If this throws an error about changing the ID on an existing document\n  // then without affecting the database, we know we should probably try\n  // an update without the generated ID. If it affected 0 documents,\n  // then without affecting the database, we the document that first\n  // gave the error is probably removed and we need to try an insert again\n  // We go back to step one and repeat.\n  // Like all \"optimistic write\" schemes, we rely on the fact that it's\n  // unlikely our writes will continue to be interfered with under normal\n  // circumstances (though sufficiently heavy contention with writers\n  // disagreeing on the existence of an object will cause writes to fail\n  // in theory).\n  var insertedId = options.insertedId; // must exist\n\n  var mongoOptsForUpdate = {\n    safe: true,\n    multi: options.multi\n  };\n  var mongoOptsForInsert = {\n    safe: true,\n    upsert: true\n  };\n  var replacementWithId = Object.assign(replaceTypes({\n    _id: insertedId\n  }, replaceMeteorAtomWithMongo), mod);\n  var tries = NUM_OPTIMISTIC_TRIES;\n\n  var doUpdate = function () {\n    tries--;\n\n    if (!tries) {\n      callback(new Error(\"Upsert failed after \" + NUM_OPTIMISTIC_TRIES + \" tries.\"));\n    } else {\n      collection.update(selector, mod, mongoOptsForUpdate, bindEnvironmentForWrite(function (err, result) {\n        if (err) {\n          callback(err);\n        } else if (result && result.result.n != 0) {\n          callback(null, {\n            numberAffected: result.result.n\n          });\n        } else {\n          doConditionalInsert();\n        }\n      }));\n    }\n  };\n\n  var doConditionalInsert = function () {\n    collection.update(selector, replacementWithId, mongoOptsForInsert, bindEnvironmentForWrite(function (err, result) {\n      if (err) {\n        // figure out if this is a\n        // \"cannot change _id of document\" error, and\n        // if so, try doUpdate() again, up to 3 times.\n        if (MongoConnection._isCannotChangeIdError(err)) {\n          doUpdate();\n        } else {\n          callback(err);\n        }\n      } else {\n        callback(null, {\n          numberAffected: result.result.upserted.length,\n          insertedId: insertedId\n        });\n      }\n    }));\n  };\n\n  doUpdate();\n};\n\n_.each([\"insert\", \"update\", \"remove\", \"dropCollection\", \"dropDatabase\"], function (method) {\n  MongoConnection.prototype[method] = function ()\n  /* arguments */\n  {\n    var self = this;\n    return Meteor.wrapAsync(self[\"_\" + method]).apply(self, arguments);\n  };\n}); // XXX MongoConnection.upsert() does not return the id of the inserted document\n// unless you set it explicitly in the selector or modifier (as a replacement\n// doc).\n\n\nMongoConnection.prototype.upsert = function (collectionName, selector, mod, options, callback) {\n  var self = this;\n\n  if (typeof options === \"function\" && !callback) {\n    callback = options;\n    options = {};\n  }\n\n  return self.update(collectionName, selector, mod, _.extend({}, options, {\n    upsert: true,\n    _returnObject: true\n  }), callback);\n};\n\nMongoConnection.prototype.find = function (collectionName, selector, options) {\n  var self = this;\n  if (arguments.length === 1) selector = {};\n  return new Cursor(self, new CursorDescription(collectionName, selector, options));\n};\n\nMongoConnection.prototype.findOne = function (collection_name, selector, options) {\n  var self = this;\n  if (arguments.length === 1) selector = {};\n  options = options || {};\n  options.limit = 1;\n  return self.find(collection_name, selector, options).fetch()[0];\n}; // We'll actually design an index API later. For now, we just pass through to\n// Mongo's, but make it synchronous.\n\n\nMongoConnection.prototype._ensureIndex = function (collectionName, index, options) {\n  var self = this; // We expect this function to be called at startup, not from within a method,\n  // so we don't interact with the write fence.\n\n  var collection = self.rawCollection(collectionName);\n  var future = new Future();\n  var indexName = collection.ensureIndex(index, options, future.resolver());\n  future.wait();\n};\n\nMongoConnection.prototype._dropIndex = function (collectionName, index) {\n  var self = this; // This function is only used by test code, not within a method, so we don't\n  // interact with the write fence.\n\n  var collection = self.rawCollection(collectionName);\n  var future = new Future();\n  var indexName = collection.dropIndex(index, future.resolver());\n  future.wait();\n}; // CURSORS\n// There are several classes which relate to cursors:\n//\n// CursorDescription represents the arguments used to construct a cursor:\n// collectionName, selector, and (find) options.  Because it is used as a key\n// for cursor de-dup, everything in it should either be JSON-stringifiable or\n// not affect observeChanges output (eg, options.transform functions are not\n// stringifiable but do not affect observeChanges).\n//\n// SynchronousCursor is a wrapper around a MongoDB cursor\n// which includes fully-synchronous versions of forEach, etc.\n//\n// Cursor is the cursor object returned from find(), which implements the\n// documented Mongo.Collection cursor API.  It wraps a CursorDescription and a\n// SynchronousCursor (lazily: it doesn't contact Mongo until you call a method\n// like fetch or forEach on it).\n//\n// ObserveHandle is the \"observe handle\" returned from observeChanges. It has a\n// reference to an ObserveMultiplexer.\n//\n// ObserveMultiplexer allows multiple identical ObserveHandles to be driven by a\n// single observe driver.\n//\n// There are two \"observe drivers\" which drive ObserveMultiplexers:\n//   - PollingObserveDriver caches the results of a query and reruns it when\n//     necessary.\n//   - OplogObserveDriver follows the Mongo operation log to directly observe\n//     database changes.\n// Both implementations follow the same simple interface: when you create them,\n// they start sending observeChanges callbacks (and a ready() invocation) to\n// their ObserveMultiplexer, and you stop them by calling their stop() method.\n\n\nCursorDescription = function (collectionName, selector, options) {\n  var self = this;\n  self.collectionName = collectionName;\n  self.selector = Mongo.Collection._rewriteSelector(selector);\n  self.options = options || {};\n};\n\nCursor = function (mongo, cursorDescription) {\n  var self = this;\n  self._mongo = mongo;\n  self._cursorDescription = cursorDescription;\n  self._synchronousCursor = null;\n};\n\n_.each(['forEach', 'map', 'fetch', 'count', Symbol.iterator], function (method) {\n  Cursor.prototype[method] = function () {\n    var self = this; // You can only observe a tailable cursor.\n\n    if (self._cursorDescription.options.tailable) throw new Error(\"Cannot call \" + method + \" on a tailable cursor\");\n\n    if (!self._synchronousCursor) {\n      self._synchronousCursor = self._mongo._createSynchronousCursor(self._cursorDescription, {\n        // Make sure that the \"self\" argument to forEach/map callbacks is the\n        // Cursor, not the SynchronousCursor.\n        selfForIteration: self,\n        useTransform: true\n      });\n    }\n\n    return self._synchronousCursor[method].apply(self._synchronousCursor, arguments);\n  };\n}); // Since we don't actually have a \"nextObject\" interface, there's really no\n// reason to have a \"rewind\" interface.  All it did was make multiple calls\n// to fetch/map/forEach return nothing the second time.\n// XXX COMPAT WITH 0.8.1\n\n\nCursor.prototype.rewind = function () {};\n\nCursor.prototype.getTransform = function () {\n  return this._cursorDescription.options.transform;\n}; // When you call Meteor.publish() with a function that returns a Cursor, we need\n// to transmute it into the equivalent subscription.  This is the function that\n// does that.\n\n\nCursor.prototype._publishCursor = function (sub) {\n  var self = this;\n  var collection = self._cursorDescription.collectionName;\n  return Mongo.Collection._publishCursor(self, sub, collection);\n}; // Used to guarantee that publish functions return at most one cursor per\n// collection. Private, because we might later have cursors that include\n// documents from multiple collections somehow.\n\n\nCursor.prototype._getCollectionName = function () {\n  var self = this;\n  return self._cursorDescription.collectionName;\n};\n\nCursor.prototype.observe = function (callbacks) {\n  var self = this;\n  return LocalCollection._observeFromObserveChanges(self, callbacks);\n};\n\nCursor.prototype.observeChanges = function (callbacks) {\n  var self = this;\n  var methods = ['addedAt', 'added', 'changedAt', 'changed', 'removedAt', 'removed', 'movedTo'];\n\n  var ordered = LocalCollection._observeChangesCallbacksAreOrdered(callbacks); // XXX: Can we find out if callbacks are from observe?\n\n\n  var exceptionName = ' observe/observeChanges callback';\n  methods.forEach(function (method) {\n    if (callbacks[method] && typeof callbacks[method] == \"function\") {\n      callbacks[method] = Meteor.bindEnvironment(callbacks[method], method + exceptionName);\n    }\n  });\n  return self._mongo._observeChanges(self._cursorDescription, ordered, callbacks);\n};\n\nMongoConnection.prototype._createSynchronousCursor = function (cursorDescription, options) {\n  var self = this;\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\n  var collection = self.rawCollection(cursorDescription.collectionName);\n  var cursorOptions = cursorDescription.options;\n  var mongoOptions = {\n    sort: cursorOptions.sort,\n    limit: cursorOptions.limit,\n    skip: cursorOptions.skip\n  }; // Do we want a tailable cursor (which only works on capped collections)?\n\n  if (cursorOptions.tailable) {\n    // We want a tailable cursor...\n    mongoOptions.tailable = true; // ... and for the server to wait a bit if any getMore has no data (rather\n    // than making us put the relevant sleeps in the client)...\n\n    mongoOptions.awaitdata = true; // ... and to keep querying the server indefinitely rather than just 5 times\n    // if there's no more data.\n\n    mongoOptions.numberOfRetries = -1; // And if this is on the oplog collection and the cursor specifies a 'ts',\n    // then set the undocumented oplog replay flag, which does a special scan to\n    // find the first document (instead of creating an index on ts). This is a\n    // very hard-coded Mongo flag which only works on the oplog collection and\n    // only works with the ts field.\n\n    if (cursorDescription.collectionName === OPLOG_COLLECTION && cursorDescription.selector.ts) {\n      mongoOptions.oplogReplay = true;\n    }\n  }\n\n  var dbCursor = collection.find(replaceTypes(cursorDescription.selector, replaceMeteorAtomWithMongo), cursorOptions.fields, mongoOptions);\n\n  if (typeof cursorOptions.maxTimeMs !== 'undefined') {\n    dbCursor = dbCursor.maxTimeMS(cursorOptions.maxTimeMs);\n  }\n\n  if (typeof cursorOptions.hint !== 'undefined') {\n    dbCursor = dbCursor.hint(cursorOptions.hint);\n  }\n\n  return new SynchronousCursor(dbCursor, cursorDescription, options);\n};\n\nvar SynchronousCursor = function (dbCursor, cursorDescription, options) {\n  var self = this;\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\n  self._dbCursor = dbCursor;\n  self._cursorDescription = cursorDescription; // The \"self\" argument passed to forEach/map callbacks. If we're wrapped\n  // inside a user-visible Cursor, we want to provide the outer cursor!\n\n  self._selfForIteration = options.selfForIteration || self;\n\n  if (options.useTransform && cursorDescription.options.transform) {\n    self._transform = LocalCollection.wrapTransform(cursorDescription.options.transform);\n  } else {\n    self._transform = null;\n  } // Need to specify that the callback is the first argument to nextObject,\n  // since otherwise when we try to call it with no args the driver will\n  // interpret \"undefined\" first arg as an options hash and crash.\n\n\n  self._synchronousNextObject = Future.wrap(dbCursor.nextObject.bind(dbCursor), 0);\n  self._synchronousCount = Future.wrap(dbCursor.count.bind(dbCursor));\n  self._visitedIds = new LocalCollection._IdMap();\n};\n\n_.extend(SynchronousCursor.prototype, {\n  _nextObject: function () {\n    var self = this;\n\n    while (true) {\n      var doc = self._synchronousNextObject().wait();\n\n      if (!doc) return null;\n      doc = replaceTypes(doc, replaceMongoAtomWithMeteor);\n\n      if (!self._cursorDescription.options.tailable && _.has(doc, '_id')) {\n        // Did Mongo give us duplicate documents in the same cursor? If so,\n        // ignore this one. (Do this before the transform, since transform might\n        // return some unrelated value.) We don't do this for tailable cursors,\n        // because we want to maintain O(1) memory usage. And if there isn't _id\n        // for some reason (maybe it's the oplog), then we don't do this either.\n        // (Be careful to do this for falsey but existing _id, though.)\n        if (self._visitedIds.has(doc._id)) continue;\n\n        self._visitedIds.set(doc._id, true);\n      }\n\n      if (self._transform) doc = self._transform(doc);\n      return doc;\n    }\n  },\n  forEach: function (callback, thisArg) {\n    var self = this; // Get back to the beginning.\n\n    self._rewind(); // We implement the loop ourself instead of using self._dbCursor.each,\n    // because \"each\" will call its callback outside of a fiber which makes it\n    // much more complex to make this function synchronous.\n\n\n    var index = 0;\n\n    while (true) {\n      var doc = self._nextObject();\n\n      if (!doc) return;\n      callback.call(thisArg, doc, index++, self._selfForIteration);\n    }\n  },\n  // XXX Allow overlapping callback executions if callback yields.\n  map: function (callback, thisArg) {\n    var self = this;\n    var res = [];\n    self.forEach(function (doc, index) {\n      res.push(callback.call(thisArg, doc, index, self._selfForIteration));\n    });\n    return res;\n  },\n  _rewind: function () {\n    var self = this; // known to be synchronous\n\n    self._dbCursor.rewind();\n\n    self._visitedIds = new LocalCollection._IdMap();\n  },\n  // Mostly usable for tailable cursors.\n  close: function () {\n    var self = this;\n\n    self._dbCursor.close();\n  },\n  fetch: function () {\n    var self = this;\n    return self.map(_.identity);\n  },\n  count: function (applySkipLimit = false) {\n    var self = this;\n    return self._synchronousCount(applySkipLimit).wait();\n  },\n  // This method is NOT wrapped in Cursor.\n  getRawObjects: function (ordered) {\n    var self = this;\n\n    if (ordered) {\n      return self.fetch();\n    } else {\n      var results = new LocalCollection._IdMap();\n      self.forEach(function (doc) {\n        results.set(doc._id, doc);\n      });\n      return results;\n    }\n  }\n});\n\nSynchronousCursor.prototype[Symbol.iterator] = function () {\n  var self = this; // Get back to the beginning.\n\n  self._rewind();\n\n  return {\n    next() {\n      const doc = self._nextObject();\n\n      return doc ? {\n        value: doc\n      } : {\n        done: true\n      };\n    }\n\n  };\n};\n\nMongoConnection.prototype.tail = function (cursorDescription, docCallback) {\n  var self = this;\n  if (!cursorDescription.options.tailable) throw new Error(\"Can only tail a tailable cursor\");\n\n  var cursor = self._createSynchronousCursor(cursorDescription);\n\n  var stopped = false;\n  var lastTS;\n\n  var loop = function () {\n    var doc = null;\n\n    while (true) {\n      if (stopped) return;\n\n      try {\n        doc = cursor._nextObject();\n      } catch (err) {\n        // There's no good way to figure out if this was actually an error\n        // from Mongo. Ah well. But either way, we need to retry the cursor\n        // (unless the failure was because the observe got stopped).\n        doc = null;\n      } // Since cursor._nextObject can yield, we need to check again to see if\n      // we've been stopped before calling the callback.\n\n\n      if (stopped) return;\n\n      if (doc) {\n        // If a tailable cursor contains a \"ts\" field, use it to recreate the\n        // cursor on error. (\"ts\" is a standard that Mongo uses internally for\n        // the oplog, and there's a special flag that lets you do binary search\n        // on it instead of needing to use an index.)\n        lastTS = doc.ts;\n        docCallback(doc);\n      } else {\n        var newSelector = _.clone(cursorDescription.selector);\n\n        if (lastTS) {\n          newSelector.ts = {\n            $gt: lastTS\n          };\n        }\n\n        cursor = self._createSynchronousCursor(new CursorDescription(cursorDescription.collectionName, newSelector, cursorDescription.options)); // Mongo failover takes many seconds.  Retry in a bit.  (Without this\n        // setTimeout, we peg the CPU at 100% and never notice the actual\n        // failover.\n\n        Meteor.setTimeout(loop, 100);\n        break;\n      }\n    }\n  };\n\n  Meteor.defer(loop);\n  return {\n    stop: function () {\n      stopped = true;\n      cursor.close();\n    }\n  };\n};\n\nMongoConnection.prototype._observeChanges = function (cursorDescription, ordered, callbacks) {\n  var self = this;\n\n  if (cursorDescription.options.tailable) {\n    return self._observeChangesTailable(cursorDescription, ordered, callbacks);\n  } // You may not filter out _id when observing changes, because the id is a core\n  // part of the observeChanges API.\n\n\n  if (cursorDescription.options.fields && (cursorDescription.options.fields._id === 0 || cursorDescription.options.fields._id === false)) {\n    throw Error(\"You may not observe a cursor with {fields: {_id: 0}}\");\n  }\n\n  var observeKey = EJSON.stringify(_.extend({\n    ordered: ordered\n  }, cursorDescription));\n  var multiplexer, observeDriver;\n  var firstHandle = false; // Find a matching ObserveMultiplexer, or create a new one. This next block is\n  // guaranteed to not yield (and it doesn't call anything that can observe a\n  // new query), so no other calls to this function can interleave with it.\n\n  Meteor._noYieldsAllowed(function () {\n    if (_.has(self._observeMultiplexers, observeKey)) {\n      multiplexer = self._observeMultiplexers[observeKey];\n    } else {\n      firstHandle = true; // Create a new ObserveMultiplexer.\n\n      multiplexer = new ObserveMultiplexer({\n        ordered: ordered,\n        onStop: function () {\n          delete self._observeMultiplexers[observeKey];\n          observeDriver.stop();\n        }\n      });\n      self._observeMultiplexers[observeKey] = multiplexer;\n    }\n  });\n\n  var observeHandle = new ObserveHandle(multiplexer, callbacks);\n\n  if (firstHandle) {\n    var matcher, sorter;\n\n    var canUseOplog = _.all([function () {\n      // At a bare minimum, using the oplog requires us to have an oplog, to\n      // want unordered callbacks, and to not want a callback on the polls\n      // that won't happen.\n      return self._oplogHandle && !ordered && !callbacks._testOnlyPollCallback;\n    }, function () {\n      // We need to be able to compile the selector. Fall back to polling for\n      // some newfangled $selector that minimongo doesn't support yet.\n      try {\n        matcher = new Minimongo.Matcher(cursorDescription.selector);\n        return true;\n      } catch (e) {\n        // XXX make all compilation errors MinimongoError or something\n        //     so that this doesn't ignore unrelated exceptions\n        return false;\n      }\n    }, function () {\n      // ... and the selector itself needs to support oplog.\n      return OplogObserveDriver.cursorSupported(cursorDescription, matcher);\n    }, function () {\n      // And we need to be able to compile the sort, if any.  eg, can't be\n      // {$natural: 1}.\n      if (!cursorDescription.options.sort) return true;\n\n      try {\n        sorter = new Minimongo.Sorter(cursorDescription.options.sort, {\n          matcher: matcher\n        });\n        return true;\n      } catch (e) {\n        // XXX make all compilation errors MinimongoError or something\n        //     so that this doesn't ignore unrelated exceptions\n        return false;\n      }\n    }], function (f) {\n      return f();\n    }); // invoke each function\n\n\n    var driverClass = canUseOplog ? OplogObserveDriver : PollingObserveDriver;\n    observeDriver = new driverClass({\n      cursorDescription: cursorDescription,\n      mongoHandle: self,\n      multiplexer: multiplexer,\n      ordered: ordered,\n      matcher: matcher,\n      // ignored by polling\n      sorter: sorter,\n      // ignored by polling\n      _testOnlyPollCallback: callbacks._testOnlyPollCallback\n    }); // This field is only set for use in tests.\n\n    multiplexer._observeDriver = observeDriver;\n  } // Blocks until the initial adds have been sent.\n\n\n  multiplexer.addHandleAndSendInitialAdds(observeHandle);\n  return observeHandle;\n}; // Listen for the invalidation messages that will trigger us to poll the\n// database for changes. If this selector specifies specific IDs, specify them\n// here, so that updates to different specific IDs don't cause us to poll.\n// listenCallback is the same kind of (notification, complete) callback passed\n// to InvalidationCrossbar.listen.\n\n\nlistenAll = function (cursorDescription, listenCallback) {\n  var listeners = [];\n  forEachTrigger(cursorDescription, function (trigger) {\n    listeners.push(DDPServer._InvalidationCrossbar.listen(trigger, listenCallback));\n  });\n  return {\n    stop: function () {\n      _.each(listeners, function (listener) {\n        listener.stop();\n      });\n    }\n  };\n};\n\nforEachTrigger = function (cursorDescription, triggerCallback) {\n  var key = {\n    collection: cursorDescription.collectionName\n  };\n\n  var specificIds = LocalCollection._idsMatchedBySelector(cursorDescription.selector);\n\n  if (specificIds) {\n    _.each(specificIds, function (id) {\n      triggerCallback(_.extend({\n        id: id\n      }, key));\n    });\n\n    triggerCallback(_.extend({\n      dropCollection: true,\n      id: null\n    }, key));\n  } else {\n    triggerCallback(key);\n  } // Everyone cares about the database being dropped.\n\n\n  triggerCallback({\n    dropDatabase: true\n  });\n}; // observeChanges for tailable cursors on capped collections.\n//\n// Some differences from normal cursors:\n//   - Will never produce anything other than 'added' or 'addedBefore'. If you\n//     do update a document that has already been produced, this will not notice\n//     it.\n//   - If you disconnect and reconnect from Mongo, it will essentially restart\n//     the query, which will lead to duplicate results. This is pretty bad,\n//     but if you include a field called 'ts' which is inserted as\n//     new MongoInternals.MongoTimestamp(0, 0) (which is initialized to the\n//     current Mongo-style timestamp), we'll be able to find the place to\n//     restart properly. (This field is specifically understood by Mongo with an\n//     optimization which allows it to find the right place to start without\n//     an index on ts. It's how the oplog works.)\n//   - No callbacks are triggered synchronously with the call (there's no\n//     differentiation between \"initial data\" and \"later changes\"; everything\n//     that matches the query gets sent asynchronously).\n//   - De-duplication is not implemented.\n//   - Does not yet interact with the write fence. Probably, this should work by\n//     ignoring removes (which don't work on capped collections) and updates\n//     (which don't affect tailable cursors), and just keeping track of the ID\n//     of the inserted object, and closing the write fence once you get to that\n//     ID (or timestamp?).  This doesn't work well if the document doesn't match\n//     the query, though.  On the other hand, the write fence can close\n//     immediately if it does not match the query. So if we trust minimongo\n//     enough to accurately evaluate the query against the write fence, we\n//     should be able to do this...  Of course, minimongo doesn't even support\n//     Mongo Timestamps yet.\n\n\nMongoConnection.prototype._observeChangesTailable = function (cursorDescription, ordered, callbacks) {\n  var self = this; // Tailable cursors only ever call added/addedBefore callbacks, so it's an\n  // error if you didn't provide them.\n\n  if (ordered && !callbacks.addedBefore || !ordered && !callbacks.added) {\n    throw new Error(\"Can't observe an \" + (ordered ? \"ordered\" : \"unordered\") + \" tailable cursor without a \" + (ordered ? \"addedBefore\" : \"added\") + \" callback\");\n  }\n\n  return self.tail(cursorDescription, function (doc) {\n    var id = doc._id;\n    delete doc._id; // The ts is an implementation detail. Hide it.\n\n    delete doc.ts;\n\n    if (ordered) {\n      callbacks.addedBefore(id, doc, null);\n    } else {\n      callbacks.added(id, doc);\n    }\n  });\n}; // XXX We probably need to find a better way to expose this. Right now\n// it's only used by tests, but in fact you need it in normal\n// operation to interact with capped collections.\n\n\nMongoInternals.MongoTimestamp = MongoDB.Timestamp;\nMongoInternals.Connection = MongoConnection;\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"oplog_tailing.js\":function(require){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/oplog_tailing.js                                                                                     //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nvar Future = Npm.require('fibers/future');\n\nOPLOG_COLLECTION = 'oplog.rs';\nvar TOO_FAR_BEHIND = process.env.METEOR_OPLOG_TOO_FAR_BEHIND || 2000;\n\nvar showTS = function (ts) {\n  return \"Timestamp(\" + ts.getHighBits() + \", \" + ts.getLowBits() + \")\";\n};\n\nidForOp = function (op) {\n  if (op.op === 'd') return op.o._id;else if (op.op === 'i') return op.o._id;else if (op.op === 'u') return op.o2._id;else if (op.op === 'c') throw Error(\"Operator 'c' doesn't supply an object with id: \" + EJSON.stringify(op));else throw Error(\"Unknown op: \" + EJSON.stringify(op));\n};\n\nOplogHandle = function (oplogUrl, dbName) {\n  var self = this;\n  self._oplogUrl = oplogUrl;\n  self._dbName = dbName;\n  self._oplogLastEntryConnection = null;\n  self._oplogTailConnection = null;\n  self._stopped = false;\n  self._tailHandle = null;\n  self._readyFuture = new Future();\n  self._crossbar = new DDPServer._Crossbar({\n    factPackage: \"mongo-livedata\",\n    factName: \"oplog-watchers\"\n  });\n  self._baseOplogSelector = {\n    ns: new RegExp('^' + Meteor._escapeRegExp(self._dbName) + '\\\\.'),\n    $or: [{\n      op: {\n        $in: ['i', 'u', 'd']\n      }\n    }, // drop collection\n    {\n      op: 'c',\n      'o.drop': {\n        $exists: true\n      }\n    }, {\n      op: 'c',\n      'o.dropDatabase': 1\n    }]\n  }; // Data structures to support waitUntilCaughtUp(). Each oplog entry has a\n  // MongoTimestamp object on it (which is not the same as a Date --- it's a\n  // combination of time and an incrementing counter; see\n  // http://docs.mongodb.org/manual/reference/bson-types/#timestamps).\n  //\n  // _catchingUpFutures is an array of {ts: MongoTimestamp, future: Future}\n  // objects, sorted by ascending timestamp. _lastProcessedTS is the\n  // MongoTimestamp of the last oplog entry we've processed.\n  //\n  // Each time we call waitUntilCaughtUp, we take a peek at the final oplog\n  // entry in the db.  If we've already processed it (ie, it is not greater than\n  // _lastProcessedTS), waitUntilCaughtUp immediately returns. Otherwise,\n  // waitUntilCaughtUp makes a new Future and inserts it along with the final\n  // timestamp entry that it read, into _catchingUpFutures. waitUntilCaughtUp\n  // then waits on that future, which is resolved once _lastProcessedTS is\n  // incremented to be past its timestamp by the worker fiber.\n  //\n  // XXX use a priority queue or something else that's faster than an array\n\n  self._catchingUpFutures = [];\n  self._lastProcessedTS = null;\n  self._onSkippedEntriesHook = new Hook({\n    debugPrintExceptions: \"onSkippedEntries callback\"\n  });\n  self._entryQueue = new Meteor._DoubleEndedQueue();\n  self._workerActive = false;\n\n  self._startTailing();\n};\n\n_.extend(OplogHandle.prototype, {\n  stop: function () {\n    var self = this;\n    if (self._stopped) return;\n    self._stopped = true;\n    if (self._tailHandle) self._tailHandle.stop(); // XXX should close connections too\n  },\n  onOplogEntry: function (trigger, callback) {\n    var self = this;\n    if (self._stopped) throw new Error(\"Called onOplogEntry on stopped handle!\"); // Calling onOplogEntry requires us to wait for the tailing to be ready.\n\n    self._readyFuture.wait();\n\n    var originalCallback = callback;\n    callback = Meteor.bindEnvironment(function (notification) {\n      // XXX can we avoid this clone by making oplog.js careful?\n      originalCallback(EJSON.clone(notification));\n    }, function (err) {\n      Meteor._debug(\"Error in oplog callback\", err);\n    });\n\n    var listenHandle = self._crossbar.listen(trigger, callback);\n\n    return {\n      stop: function () {\n        listenHandle.stop();\n      }\n    };\n  },\n  // Register a callback to be invoked any time we skip oplog entries (eg,\n  // because we are too far behind).\n  onSkippedEntries: function (callback) {\n    var self = this;\n    if (self._stopped) throw new Error(\"Called onSkippedEntries on stopped handle!\");\n    return self._onSkippedEntriesHook.register(callback);\n  },\n  // Calls `callback` once the oplog has been processed up to a point that is\n  // roughly \"now\": specifically, once we've processed all ops that are\n  // currently visible.\n  // XXX become convinced that this is actually safe even if oplogConnection\n  // is some kind of pool\n  waitUntilCaughtUp: function () {\n    var self = this;\n    if (self._stopped) throw new Error(\"Called waitUntilCaughtUp on stopped handle!\"); // Calling waitUntilCaughtUp requries us to wait for the oplog connection to\n    // be ready.\n\n    self._readyFuture.wait();\n\n    var lastEntry;\n\n    while (!self._stopped) {\n      // We need to make the selector at least as restrictive as the actual\n      // tailing selector (ie, we need to specify the DB name) or else we might\n      // find a TS that won't show up in the actual tail stream.\n      try {\n        lastEntry = self._oplogLastEntryConnection.findOne(OPLOG_COLLECTION, self._baseOplogSelector, {\n          fields: {\n            ts: 1\n          },\n          sort: {\n            $natural: -1\n          }\n        });\n        break;\n      } catch (e) {\n        // During failover (eg) if we get an exception we should log and retry\n        // instead of crashing.\n        Meteor._debug(\"Got exception while reading last entry\", e);\n\n        Meteor._sleepForMs(100);\n      }\n    }\n\n    if (self._stopped) return;\n\n    if (!lastEntry) {\n      // Really, nothing in the oplog? Well, we've processed everything.\n      return;\n    }\n\n    var ts = lastEntry.ts;\n    if (!ts) throw Error(\"oplog entry without ts: \" + EJSON.stringify(lastEntry));\n\n    if (self._lastProcessedTS && ts.lessThanOrEqual(self._lastProcessedTS)) {\n      // We've already caught up to here.\n      return;\n    } // Insert the future into our list. Almost always, this will be at the end,\n    // but it's conceivable that if we fail over from one primary to another,\n    // the oplog entries we see will go backwards.\n\n\n    var insertAfter = self._catchingUpFutures.length;\n\n    while (insertAfter - 1 > 0 && self._catchingUpFutures[insertAfter - 1].ts.greaterThan(ts)) {\n      insertAfter--;\n    }\n\n    var f = new Future();\n\n    self._catchingUpFutures.splice(insertAfter, 0, {\n      ts: ts,\n      future: f\n    });\n\n    f.wait();\n  },\n  _startTailing: function () {\n    var self = this; // First, make sure that we're talking to the local database.\n\n    var mongodbUri = Npm.require('mongodb-uri');\n\n    if (mongodbUri.parse(self._oplogUrl).database !== 'local') {\n      throw Error(\"$MONGO_OPLOG_URL must be set to the 'local' database of \" + \"a Mongo replica set\");\n    } // We make two separate connections to Mongo. The Node Mongo driver\n    // implements a naive round-robin connection pool: each \"connection\" is a\n    // pool of several (5 by default) TCP connections, and each request is\n    // rotated through the pools. Tailable cursor queries block on the server\n    // until there is some data to return (or until a few seconds have\n    // passed). So if the connection pool used for tailing cursors is the same\n    // pool used for other queries, the other queries will be delayed by seconds\n    // 1/5 of the time.\n    //\n    // The tail connection will only ever be running a single tail command, so\n    // it only needs to make one underlying TCP connection.\n\n\n    self._oplogTailConnection = new MongoConnection(self._oplogUrl, {\n      poolSize: 1\n    }); // XXX better docs, but: it's to get monotonic results\n    // XXX is it safe to say \"if there's an in flight query, just use its\n    //     results\"? I don't think so but should consider that\n\n    self._oplogLastEntryConnection = new MongoConnection(self._oplogUrl, {\n      poolSize: 1\n    }); // Now, make sure that there actually is a repl set here. If not, oplog\n    // tailing won't ever find anything!\n    // More on the isMasterDoc\n    // https://docs.mongodb.com/manual/reference/command/isMaster/\n\n    var f = new Future();\n\n    self._oplogLastEntryConnection.db.admin().command({\n      ismaster: 1\n    }, f.resolver());\n\n    var isMasterDoc = f.wait();\n\n    if (!(isMasterDoc && isMasterDoc.setName)) {\n      throw Error(\"$MONGO_OPLOG_URL must be set to the 'local' database of \" + \"a Mongo replica set\");\n    } // Find the last oplog entry.\n\n\n    var lastOplogEntry = self._oplogLastEntryConnection.findOne(OPLOG_COLLECTION, {}, {\n      sort: {\n        $natural: -1\n      },\n      fields: {\n        ts: 1\n      }\n    });\n\n    var oplogSelector = _.clone(self._baseOplogSelector);\n\n    if (lastOplogEntry) {\n      // Start after the last entry that currently exists.\n      oplogSelector.ts = {\n        $gt: lastOplogEntry.ts\n      }; // If there are any calls to callWhenProcessedLatest before any other\n      // oplog entries show up, allow callWhenProcessedLatest to call its\n      // callback immediately.\n\n      self._lastProcessedTS = lastOplogEntry.ts;\n    }\n\n    var cursorDescription = new CursorDescription(OPLOG_COLLECTION, oplogSelector, {\n      tailable: true\n    });\n    self._tailHandle = self._oplogTailConnection.tail(cursorDescription, function (doc) {\n      self._entryQueue.push(doc);\n\n      self._maybeStartWorker();\n    });\n\n    self._readyFuture.return();\n  },\n  _maybeStartWorker: function () {\n    var self = this;\n    if (self._workerActive) return;\n    self._workerActive = true;\n    Meteor.defer(function () {\n      try {\n        while (!self._stopped && !self._entryQueue.isEmpty()) {\n          // Are we too far behind? Just tell our observers that they need to\n          // repoll, and drop our queue.\n          if (self._entryQueue.length > TOO_FAR_BEHIND) {\n            var lastEntry = self._entryQueue.pop();\n\n            self._entryQueue.clear();\n\n            self._onSkippedEntriesHook.each(function (callback) {\n              callback();\n              return true;\n            }); // Free any waitUntilCaughtUp() calls that were waiting for us to\n            // pass something that we just skipped.\n\n\n            self._setLastProcessedTS(lastEntry.ts);\n\n            continue;\n          }\n\n          var doc = self._entryQueue.shift();\n\n          if (!(doc.ns && doc.ns.length > self._dbName.length + 1 && doc.ns.substr(0, self._dbName.length + 1) === self._dbName + '.')) {\n            throw new Error(\"Unexpected ns\");\n          }\n\n          var trigger = {\n            collection: doc.ns.substr(self._dbName.length + 1),\n            dropCollection: false,\n            dropDatabase: false,\n            op: doc\n          }; // Is it a special command and the collection name is hidden somewhere\n          // in operator?\n\n          if (trigger.collection === \"$cmd\") {\n            if (doc.o.dropDatabase) {\n              delete trigger.collection;\n              trigger.dropDatabase = true;\n            } else if (_.has(doc.o, 'drop')) {\n              trigger.collection = doc.o.drop;\n              trigger.dropCollection = true;\n              trigger.id = null;\n            } else {\n              throw Error(\"Unknown command \" + JSON.stringify(doc));\n            }\n          } else {\n            // All other ops have an id.\n            trigger.id = idForOp(doc);\n          }\n\n          self._crossbar.fire(trigger); // Now that we've processed this operation, process pending\n          // sequencers.\n\n\n          if (!doc.ts) throw Error(\"oplog entry without ts: \" + EJSON.stringify(doc));\n\n          self._setLastProcessedTS(doc.ts);\n        }\n      } finally {\n        self._workerActive = false;\n      }\n    });\n  },\n  _setLastProcessedTS: function (ts) {\n    var self = this;\n    self._lastProcessedTS = ts;\n\n    while (!_.isEmpty(self._catchingUpFutures) && self._catchingUpFutures[0].ts.lessThanOrEqual(self._lastProcessedTS)) {\n      var sequencer = self._catchingUpFutures.shift();\n\n      sequencer.future.return();\n    }\n  },\n  //Methods used on tests to dinamically change TOO_FAR_BEHIND\n  _defineTooFarBehind: function (value) {\n    TOO_FAR_BEHIND = value;\n  },\n  _resetTooFarBehind: function () {\n    TOO_FAR_BEHIND = process.env.METEOR_OPLOG_TOO_FAR_BEHIND || 2000;\n  }\n});\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"observe_multiplex.js\":function(require){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/observe_multiplex.js                                                                                 //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nvar Future = Npm.require('fibers/future');\n\nObserveMultiplexer = function (options) {\n  var self = this;\n  if (!options || !_.has(options, 'ordered')) throw Error(\"must specified ordered\");\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-multiplexers\", 1);\n  self._ordered = options.ordered;\n\n  self._onStop = options.onStop || function () {};\n\n  self._queue = new Meteor._SynchronousQueue();\n  self._handles = {};\n  self._readyFuture = new Future();\n  self._cache = new LocalCollection._CachingChangeObserver({\n    ordered: options.ordered\n  }); // Number of addHandleAndSendInitialAdds tasks scheduled but not yet\n  // running. removeHandle uses this to know if it's time to call the onStop\n  // callback.\n\n  self._addHandleTasksScheduledButNotPerformed = 0;\n\n  _.each(self.callbackNames(), function (callbackName) {\n    self[callbackName] = function ()\n    /* ... */\n    {\n      self._applyCallback(callbackName, _.toArray(arguments));\n    };\n  });\n};\n\n_.extend(ObserveMultiplexer.prototype, {\n  addHandleAndSendInitialAdds: function (handle) {\n    var self = this; // Check this before calling runTask (even though runTask does the same\n    // check) so that we don't leak an ObserveMultiplexer on error by\n    // incrementing _addHandleTasksScheduledButNotPerformed and never\n    // decrementing it.\n\n    if (!self._queue.safeToRunTask()) throw new Error(\"Can't call observeChanges from an observe callback on the same query\");\n    ++self._addHandleTasksScheduledButNotPerformed;\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-handles\", 1);\n\n    self._queue.runTask(function () {\n      self._handles[handle._id] = handle; // Send out whatever adds we have so far (whether or not we the\n      // multiplexer is ready).\n\n      self._sendAdds(handle);\n\n      --self._addHandleTasksScheduledButNotPerformed;\n    }); // *outside* the task, since otherwise we'd deadlock\n\n\n    self._readyFuture.wait();\n  },\n  // Remove an observe handle. If it was the last observe handle, call the\n  // onStop callback; you cannot add any more observe handles after this.\n  //\n  // This is not synchronized with polls and handle additions: this means that\n  // you can safely call it from within an observe callback, but it also means\n  // that we have to be careful when we iterate over _handles.\n  removeHandle: function (id) {\n    var self = this; // This should not be possible: you can only call removeHandle by having\n    // access to the ObserveHandle, which isn't returned to user code until the\n    // multiplex is ready.\n\n    if (!self._ready()) throw new Error(\"Can't remove handles until the multiplex is ready\");\n    delete self._handles[id];\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-handles\", -1);\n\n    if (_.isEmpty(self._handles) && self._addHandleTasksScheduledButNotPerformed === 0) {\n      self._stop();\n    }\n  },\n  _stop: function (options) {\n    var self = this;\n    options = options || {}; // It shouldn't be possible for us to stop when all our handles still\n    // haven't been returned from observeChanges!\n\n    if (!self._ready() && !options.fromQueryError) throw Error(\"surprising _stop: not ready\"); // Call stop callback (which kills the underlying process which sends us\n    // callbacks and removes us from the connection's dictionary).\n\n    self._onStop();\n\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-multiplexers\", -1); // Cause future addHandleAndSendInitialAdds calls to throw (but the onStop\n    // callback should make our connection forget about us).\n\n    self._handles = null;\n  },\n  // Allows all addHandleAndSendInitialAdds calls to return, once all preceding\n  // adds have been processed. Does not block.\n  ready: function () {\n    var self = this;\n\n    self._queue.queueTask(function () {\n      if (self._ready()) throw Error(\"can't make ObserveMultiplex ready twice!\");\n\n      self._readyFuture.return();\n    });\n  },\n  // If trying to execute the query results in an error, call this. This is\n  // intended for permanent errors, not transient network errors that could be\n  // fixed. It should only be called before ready(), because if you called ready\n  // that meant that you managed to run the query once. It will stop this\n  // ObserveMultiplex and cause addHandleAndSendInitialAdds calls (and thus\n  // observeChanges calls) to throw the error.\n  queryError: function (err) {\n    var self = this;\n\n    self._queue.runTask(function () {\n      if (self._ready()) throw Error(\"can't claim query has an error after it worked!\");\n\n      self._stop({\n        fromQueryError: true\n      });\n\n      self._readyFuture.throw(err);\n    });\n  },\n  // Calls \"cb\" once the effects of all \"ready\", \"addHandleAndSendInitialAdds\"\n  // and observe callbacks which came before this call have been propagated to\n  // all handles. \"ready\" must have already been called on this multiplexer.\n  onFlush: function (cb) {\n    var self = this;\n\n    self._queue.queueTask(function () {\n      if (!self._ready()) throw Error(\"only call onFlush on a multiplexer that will be ready\");\n      cb();\n    });\n  },\n  callbackNames: function () {\n    var self = this;\n    if (self._ordered) return [\"addedBefore\", \"changed\", \"movedBefore\", \"removed\"];else return [\"added\", \"changed\", \"removed\"];\n  },\n  _ready: function () {\n    return this._readyFuture.isResolved();\n  },\n  _applyCallback: function (callbackName, args) {\n    var self = this;\n\n    self._queue.queueTask(function () {\n      // If we stopped in the meantime, do nothing.\n      if (!self._handles) return; // First, apply the change to the cache.\n      // XXX We could make applyChange callbacks promise not to hang on to any\n      // state from their arguments (assuming that their supplied callbacks\n      // don't) and skip this clone. Currently 'changed' hangs on to state\n      // though.\n\n      self._cache.applyChange[callbackName].apply(null, EJSON.clone(args)); // If we haven't finished the initial adds, then we should only be getting\n      // adds.\n\n\n      if (!self._ready() && callbackName !== 'added' && callbackName !== 'addedBefore') {\n        throw new Error(\"Got \" + callbackName + \" during initial adds\");\n      } // Now multiplex the callbacks out to all observe handles. It's OK if\n      // these calls yield; since we're inside a task, no other use of our queue\n      // can continue until these are done. (But we do have to be careful to not\n      // use a handle that got removed, because removeHandle does not use the\n      // queue; thus, we iterate over an array of keys that we control.)\n\n\n      _.each(_.keys(self._handles), function (handleId) {\n        var handle = self._handles && self._handles[handleId];\n        if (!handle) return;\n        var callback = handle['_' + callbackName]; // clone arguments so that callbacks can mutate their arguments\n\n        callback && callback.apply(null, EJSON.clone(args));\n      });\n    });\n  },\n  // Sends initial adds to a handle. It should only be called from within a task\n  // (the task that is processing the addHandleAndSendInitialAdds call). It\n  // synchronously invokes the handle's added or addedBefore; there's no need to\n  // flush the queue afterwards to ensure that the callbacks get out.\n  _sendAdds: function (handle) {\n    var self = this;\n    if (self._queue.safeToRunTask()) throw Error(\"_sendAdds may only be called from within a task!\");\n    var add = self._ordered ? handle._addedBefore : handle._added;\n    if (!add) return; // note: docs may be an _IdMap or an OrderedDict\n\n    self._cache.docs.forEach(function (doc, id) {\n      if (!_.has(self._handles, handle._id)) throw Error(\"handle got removed before sending initial adds!\");\n      var fields = EJSON.clone(doc);\n      delete fields._id;\n      if (self._ordered) add(id, fields, null); // we're going in order, so add at end\n      else add(id, fields);\n    });\n  }\n});\n\nvar nextObserveHandleId = 1;\n\nObserveHandle = function (multiplexer, callbacks) {\n  var self = this; // The end user is only supposed to call stop().  The other fields are\n  // accessible to the multiplexer, though.\n\n  self._multiplexer = multiplexer;\n\n  _.each(multiplexer.callbackNames(), function (name) {\n    if (callbacks[name]) {\n      self['_' + name] = callbacks[name];\n    } else if (name === \"addedBefore\" && callbacks.added) {\n      // Special case: if you specify \"added\" and \"movedBefore\", you get an\n      // ordered observe where for some reason you don't get ordering data on\n      // the adds.  I dunno, we wrote tests for it, there must have been a\n      // reason.\n      self._addedBefore = function (id, fields, before) {\n        callbacks.added(id, fields);\n      };\n    }\n  });\n\n  self._stopped = false;\n  self._id = nextObserveHandleId++;\n};\n\nObserveHandle.prototype.stop = function () {\n  var self = this;\n  if (self._stopped) return;\n  self._stopped = true;\n\n  self._multiplexer.removeHandle(self._id);\n};\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"doc_fetcher.js\":function(require){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/doc_fetcher.js                                                                                       //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nvar Fiber = Npm.require('fibers');\n\nvar Future = Npm.require('fibers/future');\n\nDocFetcher = function (mongoConnection) {\n  var self = this;\n  self._mongoConnection = mongoConnection; // Map from cache key -> [callback]\n\n  self._callbacksForCacheKey = {};\n};\n\n_.extend(DocFetcher.prototype, {\n  // Fetches document \"id\" from collectionName, returning it or null if not\n  // found.\n  //\n  // If you make multiple calls to fetch() with the same cacheKey (a string),\n  // DocFetcher may assume that they all return the same document. (It does\n  // not check to see if collectionName/id match.)\n  //\n  // You may assume that callback is never called synchronously (and in fact\n  // OplogObserveDriver does so).\n  fetch: function (collectionName, id, cacheKey, callback) {\n    var self = this;\n    check(collectionName, String); // id is some sort of scalar\n\n    check(cacheKey, String); // If there's already an in-progress fetch for this cache key, yield until\n    // it's done and return whatever it returns.\n\n    if (_.has(self._callbacksForCacheKey, cacheKey)) {\n      self._callbacksForCacheKey[cacheKey].push(callback);\n\n      return;\n    }\n\n    var callbacks = self._callbacksForCacheKey[cacheKey] = [callback];\n    Fiber(function () {\n      try {\n        var doc = self._mongoConnection.findOne(collectionName, {\n          _id: id\n        }) || null; // Return doc to all relevant callbacks. Note that this array can\n        // continue to grow during callback excecution.\n\n        while (!_.isEmpty(callbacks)) {\n          // Clone the document so that the various calls to fetch don't return\n          // objects that are intertwingled with each other. Clone before\n          // popping the future, so that if clone throws, the error gets passed\n          // to the next callback.\n          var clonedDoc = EJSON.clone(doc);\n          callbacks.pop()(null, clonedDoc);\n        }\n      } catch (e) {\n        while (!_.isEmpty(callbacks)) {\n          callbacks.pop()(e);\n        }\n      } finally {\n        // XXX consider keeping the doc around for a period of time before\n        // removing from the cache\n        delete self._callbacksForCacheKey[cacheKey];\n      }\n    }).run();\n  }\n});\n\nMongoTest.DocFetcher = DocFetcher;\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"polling_observe_driver.js\":function(){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/polling_observe_driver.js                                                                            //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nPollingObserveDriver = function (options) {\n  var self = this;\n  self._cursorDescription = options.cursorDescription;\n  self._mongoHandle = options.mongoHandle;\n  self._ordered = options.ordered;\n  self._multiplexer = options.multiplexer;\n  self._stopCallbacks = [];\n  self._stopped = false;\n  self._synchronousCursor = self._mongoHandle._createSynchronousCursor(self._cursorDescription); // previous results snapshot.  on each poll cycle, diffs against\n  // results drives the callbacks.\n\n  self._results = null; // The number of _pollMongo calls that have been added to self._taskQueue but\n  // have not started running. Used to make sure we never schedule more than one\n  // _pollMongo (other than possibly the one that is currently running). It's\n  // also used by _suspendPolling to pretend there's a poll scheduled. Usually,\n  // it's either 0 (for \"no polls scheduled other than maybe one currently\n  // running\") or 1 (for \"a poll scheduled that isn't running yet\"), but it can\n  // also be 2 if incremented by _suspendPolling.\n\n  self._pollsScheduledButNotStarted = 0;\n  self._pendingWrites = []; // people to notify when polling completes\n  // Make sure to create a separately throttled function for each\n  // PollingObserveDriver object.\n\n  self._ensurePollIsScheduled = _.throttle(self._unthrottledEnsurePollIsScheduled, self._cursorDescription.options.pollingThrottleMs || 50\n  /* ms */\n  ); // XXX figure out if we still need a queue\n\n  self._taskQueue = new Meteor._SynchronousQueue();\n  var listenersHandle = listenAll(self._cursorDescription, function (notification) {\n    // When someone does a transaction that might affect us, schedule a poll\n    // of the database. If that transaction happens inside of a write fence,\n    // block the fence until we've polled and notified observers.\n    var fence = DDPServer._CurrentWriteFence.get();\n\n    if (fence) self._pendingWrites.push(fence.beginWrite()); // Ensure a poll is scheduled... but if we already know that one is,\n    // don't hit the throttled _ensurePollIsScheduled function (which might\n    // lead to us calling it unnecessarily in <pollingThrottleMs> ms).\n\n    if (self._pollsScheduledButNotStarted === 0) self._ensurePollIsScheduled();\n  });\n\n  self._stopCallbacks.push(function () {\n    listenersHandle.stop();\n  }); // every once and a while, poll even if we don't think we're dirty, for\n  // eventual consistency with database writes from outside the Meteor\n  // universe.\n  //\n  // For testing, there's an undocumented callback argument to observeChanges\n  // which disables time-based polling and gets called at the beginning of each\n  // poll.\n\n\n  if (options._testOnlyPollCallback) {\n    self._testOnlyPollCallback = options._testOnlyPollCallback;\n  } else {\n    var pollingInterval = self._cursorDescription.options.pollingIntervalMs || self._cursorDescription.options._pollingInterval || // COMPAT with 1.2\n    10 * 1000;\n    var intervalHandle = Meteor.setInterval(_.bind(self._ensurePollIsScheduled, self), pollingInterval);\n\n    self._stopCallbacks.push(function () {\n      Meteor.clearInterval(intervalHandle);\n    });\n  } // Make sure we actually poll soon!\n\n\n  self._unthrottledEnsurePollIsScheduled();\n\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-drivers-polling\", 1);\n};\n\n_.extend(PollingObserveDriver.prototype, {\n  // This is always called through _.throttle (except once at startup).\n  _unthrottledEnsurePollIsScheduled: function () {\n    var self = this;\n    if (self._pollsScheduledButNotStarted > 0) return;\n    ++self._pollsScheduledButNotStarted;\n\n    self._taskQueue.queueTask(function () {\n      self._pollMongo();\n    });\n  },\n  // test-only interface for controlling polling.\n  //\n  // _suspendPolling blocks until any currently running and scheduled polls are\n  // done, and prevents any further polls from being scheduled. (new\n  // ObserveHandles can be added and receive their initial added callbacks,\n  // though.)\n  //\n  // _resumePolling immediately polls, and allows further polls to occur.\n  _suspendPolling: function () {\n    var self = this; // Pretend that there's another poll scheduled (which will prevent\n    // _ensurePollIsScheduled from queueing any more polls).\n\n    ++self._pollsScheduledButNotStarted; // Now block until all currently running or scheduled polls are done.\n\n    self._taskQueue.runTask(function () {}); // Confirm that there is only one \"poll\" (the fake one we're pretending to\n    // have) scheduled.\n\n\n    if (self._pollsScheduledButNotStarted !== 1) throw new Error(\"_pollsScheduledButNotStarted is \" + self._pollsScheduledButNotStarted);\n  },\n  _resumePolling: function () {\n    var self = this; // We should be in the same state as in the end of _suspendPolling.\n\n    if (self._pollsScheduledButNotStarted !== 1) throw new Error(\"_pollsScheduledButNotStarted is \" + self._pollsScheduledButNotStarted); // Run a poll synchronously (which will counteract the\n    // ++_pollsScheduledButNotStarted from _suspendPolling).\n\n    self._taskQueue.runTask(function () {\n      self._pollMongo();\n    });\n  },\n  _pollMongo: function () {\n    var self = this;\n    --self._pollsScheduledButNotStarted;\n    if (self._stopped) return;\n    var first = false;\n    var newResults;\n    var oldResults = self._results;\n\n    if (!oldResults) {\n      first = true; // XXX maybe use OrderedDict instead?\n\n      oldResults = self._ordered ? [] : new LocalCollection._IdMap();\n    }\n\n    self._testOnlyPollCallback && self._testOnlyPollCallback(); // Save the list of pending writes which this round will commit.\n\n    var writesForCycle = self._pendingWrites;\n    self._pendingWrites = []; // Get the new query results. (This yields.)\n\n    try {\n      newResults = self._synchronousCursor.getRawObjects(self._ordered);\n    } catch (e) {\n      if (first && typeof e.code === 'number') {\n        // This is an error document sent to us by mongod, not a connection\n        // error generated by the client. And we've never seen this query work\n        // successfully. Probably it's a bad selector or something, so we should\n        // NOT retry. Instead, we should halt the observe (which ends up calling\n        // `stop` on us).\n        self._multiplexer.queryError(new Error(\"Exception while polling query \" + JSON.stringify(self._cursorDescription) + \": \" + e.message));\n\n        return;\n      } // getRawObjects can throw if we're having trouble talking to the\n      // database.  That's fine --- we will repoll later anyway. But we should\n      // make sure not to lose track of this cycle's writes.\n      // (It also can throw if there's just something invalid about this query;\n      // unfortunately the ObserveDriver API doesn't provide a good way to\n      // \"cancel\" the observe from the inside in this case.\n\n\n      Array.prototype.push.apply(self._pendingWrites, writesForCycle);\n\n      Meteor._debug(\"Exception while polling query \" + JSON.stringify(self._cursorDescription), e);\n\n      return;\n    } // Run diffs.\n\n\n    if (!self._stopped) {\n      LocalCollection._diffQueryChanges(self._ordered, oldResults, newResults, self._multiplexer);\n    } // Signals the multiplexer to allow all observeChanges calls that share this\n    // multiplexer to return. (This happens asynchronously, via the\n    // multiplexer's queue.)\n\n\n    if (first) self._multiplexer.ready(); // Replace self._results atomically.  (This assignment is what makes `first`\n    // stay through on the next cycle, so we've waited until after we've\n    // committed to ready-ing the multiplexer.)\n\n    self._results = newResults; // Once the ObserveMultiplexer has processed everything we've done in this\n    // round, mark all the writes which existed before this call as\n    // commmitted. (If new writes have shown up in the meantime, there'll\n    // already be another _pollMongo task scheduled.)\n\n    self._multiplexer.onFlush(function () {\n      _.each(writesForCycle, function (w) {\n        w.committed();\n      });\n    });\n  },\n  stop: function () {\n    var self = this;\n    self._stopped = true;\n\n    _.each(self._stopCallbacks, function (c) {\n      c();\n    }); // Release any write fences that are waiting on us.\n\n\n    _.each(self._pendingWrites, function (w) {\n      w.committed();\n    });\n\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-drivers-polling\", -1);\n  }\n});\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"oplog_observe_driver.js\":function(require){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/oplog_observe_driver.js                                                                              //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nvar Future = Npm.require('fibers/future');\n\nvar PHASE = {\n  QUERYING: \"QUERYING\",\n  FETCHING: \"FETCHING\",\n  STEADY: \"STEADY\"\n}; // Exception thrown by _needToPollQuery which unrolls the stack up to the\n// enclosing call to finishIfNeedToPollQuery.\n\nvar SwitchedToQuery = function () {};\n\nvar finishIfNeedToPollQuery = function (f) {\n  return function () {\n    try {\n      f.apply(this, arguments);\n    } catch (e) {\n      if (!(e instanceof SwitchedToQuery)) throw e;\n    }\n  };\n};\n\nvar currentId = 0; // OplogObserveDriver is an alternative to PollingObserveDriver which follows\n// the Mongo operation log instead of just re-polling the query. It obeys the\n// same simple interface: constructing it starts sending observeChanges\n// callbacks (and a ready() invocation) to the ObserveMultiplexer, and you stop\n// it by calling the stop() method.\n\nOplogObserveDriver = function (options) {\n  var self = this;\n  self._usesOplog = true; // tests look at this\n\n  self._id = currentId;\n  currentId++;\n  self._cursorDescription = options.cursorDescription;\n  self._mongoHandle = options.mongoHandle;\n  self._multiplexer = options.multiplexer;\n\n  if (options.ordered) {\n    throw Error(\"OplogObserveDriver only supports unordered observeChanges\");\n  }\n\n  var sorter = options.sorter; // We don't support $near and other geo-queries so it's OK to initialize the\n  // comparator only once in the constructor.\n\n  var comparator = sorter && sorter.getComparator();\n\n  if (options.cursorDescription.options.limit) {\n    // There are several properties ordered driver implements:\n    // - _limit is a positive number\n    // - _comparator is a function-comparator by which the query is ordered\n    // - _unpublishedBuffer is non-null Min/Max Heap,\n    //                      the empty buffer in STEADY phase implies that the\n    //                      everything that matches the queries selector fits\n    //                      into published set.\n    // - _published - Min Heap (also implements IdMap methods)\n    var heapOptions = {\n      IdMap: LocalCollection._IdMap\n    };\n    self._limit = self._cursorDescription.options.limit;\n    self._comparator = comparator;\n    self._sorter = sorter;\n    self._unpublishedBuffer = new MinMaxHeap(comparator, heapOptions); // We need something that can find Max value in addition to IdMap interface\n\n    self._published = new MaxHeap(comparator, heapOptions);\n  } else {\n    self._limit = 0;\n    self._comparator = null;\n    self._sorter = null;\n    self._unpublishedBuffer = null;\n    self._published = new LocalCollection._IdMap();\n  } // Indicates if it is safe to insert a new document at the end of the buffer\n  // for this query. i.e. it is known that there are no documents matching the\n  // selector those are not in published or buffer.\n\n\n  self._safeAppendToBuffer = false;\n  self._stopped = false;\n  self._stopHandles = [];\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-drivers-oplog\", 1);\n\n  self._registerPhaseChange(PHASE.QUERYING);\n\n  self._matcher = options.matcher;\n  var projection = self._cursorDescription.options.fields || {};\n  self._projectionFn = LocalCollection._compileProjection(projection); // Projection function, result of combining important fields for selector and\n  // existing fields projection\n\n  self._sharedProjection = self._matcher.combineIntoProjection(projection);\n  if (sorter) self._sharedProjection = sorter.combineIntoProjection(self._sharedProjection);\n  self._sharedProjectionFn = LocalCollection._compileProjection(self._sharedProjection);\n  self._needToFetch = new LocalCollection._IdMap();\n  self._currentlyFetching = null;\n  self._fetchGeneration = 0;\n  self._requeryWhenDoneThisQuery = false;\n  self._writesToCommitWhenWeReachSteady = []; // If the oplog handle tells us that it skipped some entries (because it got\n  // behind, say), re-poll.\n\n  self._stopHandles.push(self._mongoHandle._oplogHandle.onSkippedEntries(finishIfNeedToPollQuery(function () {\n    self._needToPollQuery();\n  })));\n\n  forEachTrigger(self._cursorDescription, function (trigger) {\n    self._stopHandles.push(self._mongoHandle._oplogHandle.onOplogEntry(trigger, function (notification) {\n      Meteor._noYieldsAllowed(finishIfNeedToPollQuery(function () {\n        var op = notification.op;\n\n        if (notification.dropCollection || notification.dropDatabase) {\n          // Note: this call is not allowed to block on anything (especially\n          // on waiting for oplog entries to catch up) because that will block\n          // onOplogEntry!\n          self._needToPollQuery();\n        } else {\n          // All other operators should be handled depending on phase\n          if (self._phase === PHASE.QUERYING) {\n            self._handleOplogEntryQuerying(op);\n          } else {\n            self._handleOplogEntrySteadyOrFetching(op);\n          }\n        }\n      }));\n    }));\n  }); // XXX ordering w.r.t. everything else?\n\n  self._stopHandles.push(listenAll(self._cursorDescription, function (notification) {\n    // If we're not in a pre-fire write fence, we don't have to do anything.\n    var fence = DDPServer._CurrentWriteFence.get();\n\n    if (!fence || fence.fired) return;\n\n    if (fence._oplogObserveDrivers) {\n      fence._oplogObserveDrivers[self._id] = self;\n      return;\n    }\n\n    fence._oplogObserveDrivers = {};\n    fence._oplogObserveDrivers[self._id] = self;\n    fence.onBeforeFire(function () {\n      var drivers = fence._oplogObserveDrivers;\n      delete fence._oplogObserveDrivers; // This fence cannot fire until we've caught up to \"this point\" in the\n      // oplog, and all observers made it back to the steady state.\n\n      self._mongoHandle._oplogHandle.waitUntilCaughtUp();\n\n      _.each(drivers, function (driver) {\n        if (driver._stopped) return;\n        var write = fence.beginWrite();\n\n        if (driver._phase === PHASE.STEADY) {\n          // Make sure that all of the callbacks have made it through the\n          // multiplexer and been delivered to ObserveHandles before committing\n          // writes.\n          driver._multiplexer.onFlush(function () {\n            write.committed();\n          });\n        } else {\n          driver._writesToCommitWhenWeReachSteady.push(write);\n        }\n      });\n    });\n  })); // When Mongo fails over, we need to repoll the query, in case we processed an\n  // oplog entry that got rolled back.\n\n\n  self._stopHandles.push(self._mongoHandle._onFailover(finishIfNeedToPollQuery(function () {\n    self._needToPollQuery();\n  }))); // Give _observeChanges a chance to add the new ObserveHandle to our\n  // multiplexer, so that the added calls get streamed.\n\n\n  Meteor.defer(finishIfNeedToPollQuery(function () {\n    self._runInitialQuery();\n  }));\n};\n\n_.extend(OplogObserveDriver.prototype, {\n  _addPublished: function (id, doc) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      var fields = _.clone(doc);\n\n      delete fields._id;\n\n      self._published.set(id, self._sharedProjectionFn(doc));\n\n      self._multiplexer.added(id, self._projectionFn(fields)); // After adding this document, the published set might be overflowed\n      // (exceeding capacity specified by limit). If so, push the maximum\n      // element to the buffer, we might want to save it in memory to reduce the\n      // amount of Mongo lookups in the future.\n\n\n      if (self._limit && self._published.size() > self._limit) {\n        // XXX in theory the size of published is no more than limit+1\n        if (self._published.size() !== self._limit + 1) {\n          throw new Error(\"After adding to published, \" + (self._published.size() - self._limit) + \" documents are overflowing the set\");\n        }\n\n        var overflowingDocId = self._published.maxElementId();\n\n        var overflowingDoc = self._published.get(overflowingDocId);\n\n        if (EJSON.equals(overflowingDocId, id)) {\n          throw new Error(\"The document just added is overflowing the published set\");\n        }\n\n        self._published.remove(overflowingDocId);\n\n        self._multiplexer.removed(overflowingDocId);\n\n        self._addBuffered(overflowingDocId, overflowingDoc);\n      }\n    });\n  },\n  _removePublished: function (id) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._published.remove(id);\n\n      self._multiplexer.removed(id);\n\n      if (!self._limit || self._published.size() === self._limit) return;\n      if (self._published.size() > self._limit) throw Error(\"self._published got too big\"); // OK, we are publishing less than the limit. Maybe we should look in the\n      // buffer to find the next element past what we were publishing before.\n\n      if (!self._unpublishedBuffer.empty()) {\n        // There's something in the buffer; move the first thing in it to\n        // _published.\n        var newDocId = self._unpublishedBuffer.minElementId();\n\n        var newDoc = self._unpublishedBuffer.get(newDocId);\n\n        self._removeBuffered(newDocId);\n\n        self._addPublished(newDocId, newDoc);\n\n        return;\n      } // There's nothing in the buffer.  This could mean one of a few things.\n      // (a) We could be in the middle of re-running the query (specifically, we\n      // could be in _publishNewResults). In that case, _unpublishedBuffer is\n      // empty because we clear it at the beginning of _publishNewResults. In\n      // this case, our caller already knows the entire answer to the query and\n      // we don't need to do anything fancy here.  Just return.\n\n\n      if (self._phase === PHASE.QUERYING) return; // (b) We're pretty confident that the union of _published and\n      // _unpublishedBuffer contain all documents that match selector. Because\n      // _unpublishedBuffer is empty, that means we're confident that _published\n      // contains all documents that match selector. So we have nothing to do.\n\n      if (self._safeAppendToBuffer) return; // (c) Maybe there are other documents out there that should be in our\n      // buffer. But in that case, when we emptied _unpublishedBuffer in\n      // _removeBuffered, we should have called _needToPollQuery, which will\n      // either put something in _unpublishedBuffer or set _safeAppendToBuffer\n      // (or both), and it will put us in QUERYING for that whole time. So in\n      // fact, we shouldn't be able to get here.\n\n      throw new Error(\"Buffer inexplicably empty\");\n    });\n  },\n  _changePublished: function (id, oldDoc, newDoc) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._published.set(id, self._sharedProjectionFn(newDoc));\n\n      var projectedNew = self._projectionFn(newDoc);\n\n      var projectedOld = self._projectionFn(oldDoc);\n\n      var changed = DiffSequence.makeChangedFields(projectedNew, projectedOld);\n      if (!_.isEmpty(changed)) self._multiplexer.changed(id, changed);\n    });\n  },\n  _addBuffered: function (id, doc) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._unpublishedBuffer.set(id, self._sharedProjectionFn(doc)); // If something is overflowing the buffer, we just remove it from cache\n\n\n      if (self._unpublishedBuffer.size() > self._limit) {\n        var maxBufferedId = self._unpublishedBuffer.maxElementId();\n\n        self._unpublishedBuffer.remove(maxBufferedId); // Since something matching is removed from cache (both published set and\n        // buffer), set flag to false\n\n\n        self._safeAppendToBuffer = false;\n      }\n    });\n  },\n  // Is called either to remove the doc completely from matching set or to move\n  // it to the published set later.\n  _removeBuffered: function (id) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._unpublishedBuffer.remove(id); // To keep the contract \"buffer is never empty in STEADY phase unless the\n      // everything matching fits into published\" true, we poll everything as\n      // soon as we see the buffer becoming empty.\n\n\n      if (!self._unpublishedBuffer.size() && !self._safeAppendToBuffer) self._needToPollQuery();\n    });\n  },\n  // Called when a document has joined the \"Matching\" results set.\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\n  // and the effect of limit enforced.\n  _addMatching: function (doc) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      var id = doc._id;\n      if (self._published.has(id)) throw Error(\"tried to add something already published \" + id);\n      if (self._limit && self._unpublishedBuffer.has(id)) throw Error(\"tried to add something already existed in buffer \" + id);\n      var limit = self._limit;\n      var comparator = self._comparator;\n      var maxPublished = limit && self._published.size() > 0 ? self._published.get(self._published.maxElementId()) : null;\n      var maxBuffered = limit && self._unpublishedBuffer.size() > 0 ? self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId()) : null; // The query is unlimited or didn't publish enough documents yet or the\n      // new document would fit into published set pushing the maximum element\n      // out, then we need to publish the doc.\n\n      var toPublish = !limit || self._published.size() < limit || comparator(doc, maxPublished) < 0; // Otherwise we might need to buffer it (only in case of limited query).\n      // Buffering is allowed if the buffer is not filled up yet and all\n      // matching docs are either in the published set or in the buffer.\n\n      var canAppendToBuffer = !toPublish && self._safeAppendToBuffer && self._unpublishedBuffer.size() < limit; // Or if it is small enough to be safely inserted to the middle or the\n      // beginning of the buffer.\n\n      var canInsertIntoBuffer = !toPublish && maxBuffered && comparator(doc, maxBuffered) <= 0;\n      var toBuffer = canAppendToBuffer || canInsertIntoBuffer;\n\n      if (toPublish) {\n        self._addPublished(id, doc);\n      } else if (toBuffer) {\n        self._addBuffered(id, doc);\n      } else {\n        // dropping it and not saving to the cache\n        self._safeAppendToBuffer = false;\n      }\n    });\n  },\n  // Called when a document leaves the \"Matching\" results set.\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\n  // and the effect of limit enforced.\n  _removeMatching: function (id) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      if (!self._published.has(id) && !self._limit) throw Error(\"tried to remove something matching but not cached \" + id);\n\n      if (self._published.has(id)) {\n        self._removePublished(id);\n      } else if (self._unpublishedBuffer.has(id)) {\n        self._removeBuffered(id);\n      }\n    });\n  },\n  _handleDoc: function (id, newDoc) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      var matchesNow = newDoc && self._matcher.documentMatches(newDoc).result;\n\n      var publishedBefore = self._published.has(id);\n\n      var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\n\n      var cachedBefore = publishedBefore || bufferedBefore;\n\n      if (matchesNow && !cachedBefore) {\n        self._addMatching(newDoc);\n      } else if (cachedBefore && !matchesNow) {\n        self._removeMatching(id);\n      } else if (cachedBefore && matchesNow) {\n        var oldDoc = self._published.get(id);\n\n        var comparator = self._comparator;\n\n        var minBuffered = self._limit && self._unpublishedBuffer.size() && self._unpublishedBuffer.get(self._unpublishedBuffer.minElementId());\n\n        var maxBuffered;\n\n        if (publishedBefore) {\n          // Unlimited case where the document stays in published once it\n          // matches or the case when we don't have enough matching docs to\n          // publish or the changed but matching doc will stay in published\n          // anyways.\n          //\n          // XXX: We rely on the emptiness of buffer. Be sure to maintain the\n          // fact that buffer can't be empty if there are matching documents not\n          // published. Notably, we don't want to schedule repoll and continue\n          // relying on this property.\n          var staysInPublished = !self._limit || self._unpublishedBuffer.size() === 0 || comparator(newDoc, minBuffered) <= 0;\n\n          if (staysInPublished) {\n            self._changePublished(id, oldDoc, newDoc);\n          } else {\n            // after the change doc doesn't stay in the published, remove it\n            self._removePublished(id); // but it can move into buffered now, check it\n\n\n            maxBuffered = self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId());\n            var toBuffer = self._safeAppendToBuffer || maxBuffered && comparator(newDoc, maxBuffered) <= 0;\n\n            if (toBuffer) {\n              self._addBuffered(id, newDoc);\n            } else {\n              // Throw away from both published set and buffer\n              self._safeAppendToBuffer = false;\n            }\n          }\n        } else if (bufferedBefore) {\n          oldDoc = self._unpublishedBuffer.get(id); // remove the old version manually instead of using _removeBuffered so\n          // we don't trigger the querying immediately.  if we end this block\n          // with the buffer empty, we will need to trigger the query poll\n          // manually too.\n\n          self._unpublishedBuffer.remove(id);\n\n          var maxPublished = self._published.get(self._published.maxElementId());\n\n          maxBuffered = self._unpublishedBuffer.size() && self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId()); // the buffered doc was updated, it could move to published\n\n          var toPublish = comparator(newDoc, maxPublished) < 0; // or stays in buffer even after the change\n\n          var staysInBuffer = !toPublish && self._safeAppendToBuffer || !toPublish && maxBuffered && comparator(newDoc, maxBuffered) <= 0;\n\n          if (toPublish) {\n            self._addPublished(id, newDoc);\n          } else if (staysInBuffer) {\n            // stays in buffer but changes\n            self._unpublishedBuffer.set(id, newDoc);\n          } else {\n            // Throw away from both published set and buffer\n            self._safeAppendToBuffer = false; // Normally this check would have been done in _removeBuffered but\n            // we didn't use it, so we need to do it ourself now.\n\n            if (!self._unpublishedBuffer.size()) {\n              self._needToPollQuery();\n            }\n          }\n        } else {\n          throw new Error(\"cachedBefore implies either of publishedBefore or bufferedBefore is true.\");\n        }\n      }\n    });\n  },\n  _fetchModifiedDocuments: function () {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._registerPhaseChange(PHASE.FETCHING); // Defer, because nothing called from the oplog entry handler may yield,\n      // but fetch() yields.\n\n\n      Meteor.defer(finishIfNeedToPollQuery(function () {\n        while (!self._stopped && !self._needToFetch.empty()) {\n          if (self._phase === PHASE.QUERYING) {\n            // While fetching, we decided to go into QUERYING mode, and then we\n            // saw another oplog entry, so _needToFetch is not empty. But we\n            // shouldn't fetch these documents until AFTER the query is done.\n            break;\n          } // Being in steady phase here would be surprising.\n\n\n          if (self._phase !== PHASE.FETCHING) throw new Error(\"phase in fetchModifiedDocuments: \" + self._phase);\n          self._currentlyFetching = self._needToFetch;\n          var thisGeneration = ++self._fetchGeneration;\n          self._needToFetch = new LocalCollection._IdMap();\n          var waiting = 0;\n          var fut = new Future(); // This loop is safe, because _currentlyFetching will not be updated\n          // during this loop (in fact, it is never mutated).\n\n          self._currentlyFetching.forEach(function (cacheKey, id) {\n            waiting++;\n\n            self._mongoHandle._docFetcher.fetch(self._cursorDescription.collectionName, id, cacheKey, finishIfNeedToPollQuery(function (err, doc) {\n              try {\n                if (err) {\n                  Meteor._debug(\"Got exception while fetching documents\", err); // If we get an error from the fetcher (eg, trouble\n                  // connecting to Mongo), let's just abandon the fetch phase\n                  // altogether and fall back to polling. It's not like we're\n                  // getting live updates anyway.\n\n\n                  if (self._phase !== PHASE.QUERYING) {\n                    self._needToPollQuery();\n                  }\n                } else if (!self._stopped && self._phase === PHASE.FETCHING && self._fetchGeneration === thisGeneration) {\n                  // We re-check the generation in case we've had an explicit\n                  // _pollQuery call (eg, in another fiber) which should\n                  // effectively cancel this round of fetches.  (_pollQuery\n                  // increments the generation.)\n                  self._handleDoc(id, doc);\n                }\n              } finally {\n                waiting--; // Because fetch() never calls its callback synchronously,\n                // this is safe (ie, we won't call fut.return() before the\n                // forEach is done).\n\n                if (waiting === 0) fut.return();\n              }\n            }));\n          });\n\n          fut.wait(); // Exit now if we've had a _pollQuery call (here or in another fiber).\n\n          if (self._phase === PHASE.QUERYING) return;\n          self._currentlyFetching = null;\n        } // We're done fetching, so we can be steady, unless we've had a\n        // _pollQuery call (here or in another fiber).\n\n\n        if (self._phase !== PHASE.QUERYING) self._beSteady();\n      }));\n    });\n  },\n  _beSteady: function () {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._registerPhaseChange(PHASE.STEADY);\n\n      var writes = self._writesToCommitWhenWeReachSteady;\n      self._writesToCommitWhenWeReachSteady = [];\n\n      self._multiplexer.onFlush(function () {\n        _.each(writes, function (w) {\n          w.committed();\n        });\n      });\n    });\n  },\n  _handleOplogEntryQuerying: function (op) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      self._needToFetch.set(idForOp(op), op.ts.toString());\n    });\n  },\n  _handleOplogEntrySteadyOrFetching: function (op) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      var id = idForOp(op); // If we're already fetching this one, or about to, we can't optimize;\n      // make sure that we fetch it again if necessary.\n\n      if (self._phase === PHASE.FETCHING && (self._currentlyFetching && self._currentlyFetching.has(id) || self._needToFetch.has(id))) {\n        self._needToFetch.set(id, op.ts.toString());\n\n        return;\n      }\n\n      if (op.op === 'd') {\n        if (self._published.has(id) || self._limit && self._unpublishedBuffer.has(id)) self._removeMatching(id);\n      } else if (op.op === 'i') {\n        if (self._published.has(id)) throw new Error(\"insert found for already-existing ID in published\");\n        if (self._unpublishedBuffer && self._unpublishedBuffer.has(id)) throw new Error(\"insert found for already-existing ID in buffer\"); // XXX what if selector yields?  for now it can't but later it could\n        // have $where\n\n        if (self._matcher.documentMatches(op.o).result) self._addMatching(op.o);\n      } else if (op.op === 'u') {\n        // Is this a modifier ($set/$unset, which may require us to poll the\n        // database to figure out if the whole document matches the selector) or\n        // a replacement (in which case we can just directly re-evaluate the\n        // selector)?\n        var isReplace = !_.has(op.o, '$set') && !_.has(op.o, '$unset'); // If this modifier modifies something inside an EJSON custom type (ie,\n        // anything with EJSON$), then we can't try to use\n        // LocalCollection._modify, since that just mutates the EJSON encoding,\n        // not the actual object.\n\n        var canDirectlyModifyDoc = !isReplace && modifierCanBeDirectlyApplied(op.o);\n\n        var publishedBefore = self._published.has(id);\n\n        var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\n\n        if (isReplace) {\n          self._handleDoc(id, _.extend({\n            _id: id\n          }, op.o));\n        } else if ((publishedBefore || bufferedBefore) && canDirectlyModifyDoc) {\n          // Oh great, we actually know what the document is, so we can apply\n          // this directly.\n          var newDoc = self._published.has(id) ? self._published.get(id) : self._unpublishedBuffer.get(id);\n          newDoc = EJSON.clone(newDoc);\n          newDoc._id = id;\n\n          try {\n            LocalCollection._modify(newDoc, op.o);\n          } catch (e) {\n            if (e.name !== \"MinimongoError\") throw e; // We didn't understand the modifier.  Re-fetch.\n\n            self._needToFetch.set(id, op.ts.toString());\n\n            if (self._phase === PHASE.STEADY) {\n              self._fetchModifiedDocuments();\n            }\n\n            return;\n          }\n\n          self._handleDoc(id, self._sharedProjectionFn(newDoc));\n        } else if (!canDirectlyModifyDoc || self._matcher.canBecomeTrueByModifier(op.o) || self._sorter && self._sorter.affectedByModifier(op.o)) {\n          self._needToFetch.set(id, op.ts.toString());\n\n          if (self._phase === PHASE.STEADY) self._fetchModifiedDocuments();\n        }\n      } else {\n        throw Error(\"XXX SURPRISING OPERATION: \" + op);\n      }\n    });\n  },\n  // Yields!\n  _runInitialQuery: function () {\n    var self = this;\n    if (self._stopped) throw new Error(\"oplog stopped surprisingly early\");\n\n    self._runQuery({\n      initial: true\n    }); // yields\n\n\n    if (self._stopped) return; // can happen on queryError\n    // Allow observeChanges calls to return. (After this, it's possible for\n    // stop() to be called.)\n\n    self._multiplexer.ready();\n\n    self._doneQuerying(); // yields\n\n  },\n  // In various circumstances, we may just want to stop processing the oplog and\n  // re-run the initial query, just as if we were a PollingObserveDriver.\n  //\n  // This function may not block, because it is called from an oplog entry\n  // handler.\n  //\n  // XXX We should call this when we detect that we've been in FETCHING for \"too\n  // long\".\n  //\n  // XXX We should call this when we detect Mongo failover (since that might\n  // mean that some of the oplog entries we have processed have been rolled\n  // back). The Node Mongo driver is in the middle of a bunch of huge\n  // refactorings, including the way that it notifies you when primary\n  // changes. Will put off implementing this until driver 1.4 is out.\n  _pollQuery: function () {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      if (self._stopped) return; // Yay, we get to forget about all the things we thought we had to fetch.\n\n      self._needToFetch = new LocalCollection._IdMap();\n      self._currentlyFetching = null;\n      ++self._fetchGeneration; // ignore any in-flight fetches\n\n      self._registerPhaseChange(PHASE.QUERYING); // Defer so that we don't yield.  We don't need finishIfNeedToPollQuery\n      // here because SwitchedToQuery is not thrown in QUERYING mode.\n\n\n      Meteor.defer(function () {\n        self._runQuery();\n\n        self._doneQuerying();\n      });\n    });\n  },\n  // Yields!\n  _runQuery: function (options) {\n    var self = this;\n    options = options || {};\n    var newResults, newBuffer; // This while loop is just to retry failures.\n\n    while (true) {\n      // If we've been stopped, we don't have to run anything any more.\n      if (self._stopped) return;\n      newResults = new LocalCollection._IdMap();\n      newBuffer = new LocalCollection._IdMap(); // Query 2x documents as the half excluded from the original query will go\n      // into unpublished buffer to reduce additional Mongo lookups in cases\n      // when documents are removed from the published set and need a\n      // replacement.\n      // XXX needs more thought on non-zero skip\n      // XXX 2 is a \"magic number\" meaning there is an extra chunk of docs for\n      // buffer if such is needed.\n\n      var cursor = self._cursorForQuery({\n        limit: self._limit * 2\n      });\n\n      try {\n        cursor.forEach(function (doc, i) {\n          // yields\n          if (!self._limit || i < self._limit) {\n            newResults.set(doc._id, doc);\n          } else {\n            newBuffer.set(doc._id, doc);\n          }\n        });\n        break;\n      } catch (e) {\n        if (options.initial && typeof e.code === 'number') {\n          // This is an error document sent to us by mongod, not a connection\n          // error generated by the client. And we've never seen this query work\n          // successfully. Probably it's a bad selector or something, so we\n          // should NOT retry. Instead, we should halt the observe (which ends\n          // up calling `stop` on us).\n          self._multiplexer.queryError(e);\n\n          return;\n        } // During failover (eg) if we get an exception we should log and retry\n        // instead of crashing.\n\n\n        Meteor._debug(\"Got exception while polling query\", e);\n\n        Meteor._sleepForMs(100);\n      }\n    }\n\n    if (self._stopped) return;\n\n    self._publishNewResults(newResults, newBuffer);\n  },\n  // Transitions to QUERYING and runs another query, or (if already in QUERYING)\n  // ensures that we will query again later.\n  //\n  // This function may not block, because it is called from an oplog entry\n  // handler. However, if we were not already in the QUERYING phase, it throws\n  // an exception that is caught by the closest surrounding\n  // finishIfNeedToPollQuery call; this ensures that we don't continue running\n  // close that was designed for another phase inside PHASE.QUERYING.\n  //\n  // (It's also necessary whenever logic in this file yields to check that other\n  // phases haven't put us into QUERYING mode, though; eg,\n  // _fetchModifiedDocuments does this.)\n  _needToPollQuery: function () {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      if (self._stopped) return; // If we're not already in the middle of a query, we can query now\n      // (possibly pausing FETCHING).\n\n      if (self._phase !== PHASE.QUERYING) {\n        self._pollQuery();\n\n        throw new SwitchedToQuery();\n      } // We're currently in QUERYING. Set a flag to ensure that we run another\n      // query when we're done.\n\n\n      self._requeryWhenDoneThisQuery = true;\n    });\n  },\n  // Yields!\n  _doneQuerying: function () {\n    var self = this;\n    if (self._stopped) return;\n\n    self._mongoHandle._oplogHandle.waitUntilCaughtUp(); // yields\n\n\n    if (self._stopped) return;\n    if (self._phase !== PHASE.QUERYING) throw Error(\"Phase unexpectedly \" + self._phase);\n\n    Meteor._noYieldsAllowed(function () {\n      if (self._requeryWhenDoneThisQuery) {\n        self._requeryWhenDoneThisQuery = false;\n\n        self._pollQuery();\n      } else if (self._needToFetch.empty()) {\n        self._beSteady();\n      } else {\n        self._fetchModifiedDocuments();\n      }\n    });\n  },\n  _cursorForQuery: function (optionsOverwrite) {\n    var self = this;\n    return Meteor._noYieldsAllowed(function () {\n      // The query we run is almost the same as the cursor we are observing,\n      // with a few changes. We need to read all the fields that are relevant to\n      // the selector, not just the fields we are going to publish (that's the\n      // \"shared\" projection). And we don't want to apply any transform in the\n      // cursor, because observeChanges shouldn't use the transform.\n      var options = _.clone(self._cursorDescription.options); // Allow the caller to modify the options. Useful to specify different\n      // skip and limit values.\n\n\n      _.extend(options, optionsOverwrite);\n\n      options.fields = self._sharedProjection;\n      delete options.transform; // We are NOT deep cloning fields or selector here, which should be OK.\n\n      var description = new CursorDescription(self._cursorDescription.collectionName, self._cursorDescription.selector, options);\n      return new Cursor(self._mongoHandle, description);\n    });\n  },\n  // Replace self._published with newResults (both are IdMaps), invoking observe\n  // callbacks on the multiplexer.\n  // Replace self._unpublishedBuffer with newBuffer.\n  //\n  // XXX This is very similar to LocalCollection._diffQueryUnorderedChanges. We\n  // should really: (a) Unify IdMap and OrderedDict into Unordered/OrderedDict\n  // (b) Rewrite diff.js to use these classes instead of arrays and objects.\n  _publishNewResults: function (newResults, newBuffer) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      // If the query is limited and there is a buffer, shut down so it doesn't\n      // stay in a way.\n      if (self._limit) {\n        self._unpublishedBuffer.clear();\n      } // First remove anything that's gone. Be careful not to modify\n      // self._published while iterating over it.\n\n\n      var idsToRemove = [];\n\n      self._published.forEach(function (doc, id) {\n        if (!newResults.has(id)) idsToRemove.push(id);\n      });\n\n      _.each(idsToRemove, function (id) {\n        self._removePublished(id);\n      }); // Now do adds and changes.\n      // If self has a buffer and limit, the new fetched result will be\n      // limited correctly as the query has sort specifier.\n\n\n      newResults.forEach(function (doc, id) {\n        self._handleDoc(id, doc);\n      }); // Sanity-check that everything we tried to put into _published ended up\n      // there.\n      // XXX if this is slow, remove it later\n\n      if (self._published.size() !== newResults.size()) {\n        throw Error(\"The Mongo server and the Meteor query disagree on how \" + \"many documents match your query. Maybe it is hitting a Mongo \" + \"edge case? The query is: \" + EJSON.stringify(self._cursorDescription.selector));\n      }\n\n      self._published.forEach(function (doc, id) {\n        if (!newResults.has(id)) throw Error(\"_published has a doc that newResults doesn't; \" + id);\n      }); // Finally, replace the buffer\n\n\n      newBuffer.forEach(function (doc, id) {\n        self._addBuffered(id, doc);\n      });\n      self._safeAppendToBuffer = newBuffer.size() < self._limit;\n    });\n  },\n  // This stop function is invoked from the onStop of the ObserveMultiplexer, so\n  // it shouldn't actually be possible to call it until the multiplexer is\n  // ready.\n  //\n  // It's important to check self._stopped after every call in this file that\n  // can yield!\n  stop: function () {\n    var self = this;\n    if (self._stopped) return;\n    self._stopped = true;\n\n    _.each(self._stopHandles, function (handle) {\n      handle.stop();\n    }); // Note: we *don't* use multiplexer.onFlush here because this stop\n    // callback is actually invoked by the multiplexer itself when it has\n    // determined that there are no handles left. So nothing is actually going\n    // to get flushed (and it's probably not valid to call methods on the\n    // dying multiplexer).\n\n\n    _.each(self._writesToCommitWhenWeReachSteady, function (w) {\n      w.committed(); // maybe yields?\n    });\n\n    self._writesToCommitWhenWeReachSteady = null; // Proactively drop references to potentially big things.\n\n    self._published = null;\n    self._unpublishedBuffer = null;\n    self._needToFetch = null;\n    self._currentlyFetching = null;\n    self._oplogEntryHandle = null;\n    self._listenersHandle = null;\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"observe-drivers-oplog\", -1);\n  },\n  _registerPhaseChange: function (phase) {\n    var self = this;\n\n    Meteor._noYieldsAllowed(function () {\n      var now = new Date();\n\n      if (self._phase) {\n        var timeDiff = now - self._phaseStartTime;\n        Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\"mongo-livedata\", \"time-spent-in-\" + self._phase + \"-phase\", timeDiff);\n      }\n\n      self._phase = phase;\n      self._phaseStartTime = now;\n    });\n  }\n}); // Does our oplog tailing code support this cursor? For now, we are being very\n// conservative and allowing only simple queries with simple options.\n// (This is a \"static method\".)\n\n\nOplogObserveDriver.cursorSupported = function (cursorDescription, matcher) {\n  // First, check the options.\n  var options = cursorDescription.options; // Did the user say no explicitly?\n  // underscored version of the option is COMPAT with 1.2\n\n  if (options.disableOplog || options._disableOplog) return false; // skip is not supported: to support it we would need to keep track of all\n  // \"skipped\" documents or at least their ids.\n  // limit w/o a sort specifier is not supported: current implementation needs a\n  // deterministic way to order documents.\n\n  if (options.skip || options.limit && !options.sort) return false; // If a fields projection option is given check if it is supported by\n  // minimongo (some operators are not supported).\n\n  if (options.fields) {\n    try {\n      LocalCollection._checkSupportedProjection(options.fields);\n    } catch (e) {\n      if (e.name === \"MinimongoError\") {\n        return false;\n      } else {\n        throw e;\n      }\n    }\n  } // We don't allow the following selectors:\n  //   - $where (not confident that we provide the same JS environment\n  //             as Mongo, and can yield!)\n  //   - $near (has \"interesting\" properties in MongoDB, like the possibility\n  //            of returning an ID multiple times, though even polling maybe\n  //            have a bug there)\n  //           XXX: once we support it, we would need to think more on how we\n  //           initialize the comparators when we create the driver.\n\n\n  return !matcher.hasWhere() && !matcher.hasGeoQuery();\n};\n\nvar modifierCanBeDirectlyApplied = function (modifier) {\n  return _.all(modifier, function (fields, operation) {\n    return _.all(fields, function (value, field) {\n      return !/EJSON\\$/.test(field);\n    });\n  });\n};\n\nMongoInternals.OplogObserveDriver = OplogObserveDriver;\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"local_collection_driver.js\":function(require,exports,module){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/local_collection_driver.js                                                                           //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nmodule.export({\n  LocalCollectionDriver: () => LocalCollectionDriver\n});\nconst LocalCollectionDriver = new class LocalCollectionDriver {\n  constructor() {\n    this.noConnCollections = Object.create(null);\n  }\n\n  open(name, conn) {\n    if (!name) {\n      return new LocalCollection();\n    }\n\n    if (!conn) {\n      return ensureCollection(name, this.noConnCollections);\n    }\n\n    if (!conn._mongo_livedata_collections) {\n      conn._mongo_livedata_collections = Object.create(null);\n    } // XXX is there a way to keep track of a connection's collections without\n    // dangling it off the connection object?\n\n\n    return ensureCollection(name, conn._mongo_livedata_collections);\n  }\n\n}();\n\nfunction ensureCollection(name, collections) {\n  return name in collections ? collections[name] : collections[name] = new LocalCollection(name);\n}\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"remote_collection_driver.js\":function(require){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/remote_collection_driver.js                                                                          //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nMongoInternals.RemoteCollectionDriver = function (mongo_url, options) {\n  var self = this;\n  self.mongo = new MongoConnection(mongo_url, options);\n};\n\n_.extend(MongoInternals.RemoteCollectionDriver.prototype, {\n  open: function (name) {\n    var self = this;\n    var ret = {};\n\n    _.each(['find', 'findOne', 'insert', 'update', 'upsert', 'remove', '_ensureIndex', '_dropIndex', '_createCappedCollection', 'dropCollection', 'rawCollection'], function (m) {\n      ret[m] = _.bind(self.mongo[m], self.mongo, name);\n    });\n\n    return ret;\n  }\n}); // Create the singleton RemoteCollectionDriver only on demand, so we\n// only require Mongo configuration if it's actually used (eg, not if\n// you're only trying to receive data from a remote DDP server.)\n\n\nMongoInternals.defaultRemoteCollectionDriver = _.once(function () {\n  var connectionOptions = {};\n  var mongoUrl = process.env.MONGO_URL;\n\n  if (process.env.MONGO_OPLOG_URL) {\n    connectionOptions.oplogUrl = process.env.MONGO_OPLOG_URL;\n  }\n\n  if (!mongoUrl) throw new Error(\"MONGO_URL must be set in environment\");\n  return new MongoInternals.RemoteCollectionDriver(mongoUrl, connectionOptions);\n});\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"collection.js\":function(require,exports,module){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/collection.js                                                                                        //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/builtin/interopRequireDefault\");\n\nvar _objectSpread2 = _interopRequireDefault(require(\"@babel/runtime/helpers/builtin/objectSpread\"));\n\n// options.connection, if given, is a LivedataClient or LivedataServer\n// XXX presently there is no way to destroy/clean up a Collection\n\n/**\n * @summary Namespace for MongoDB-related items\n * @namespace\n */\nMongo = {};\n/**\n * @summary Constructor for a Collection\n * @locus Anywhere\n * @instancename collection\n * @class\n * @param {String} name The name of the collection.  If null, creates an unmanaged (unsynchronized) local collection.\n * @param {Object} [options]\n * @param {Object} options.connection The server connection that will manage this collection. Uses the default connection if not specified.  Pass the return value of calling [`DDP.connect`](#ddp_connect) to specify a different server. Pass `null` to specify no connection. Unmanaged (`name` is null) collections cannot specify a connection.\n * @param {String} options.idGeneration The method of generating the `_id` fields of new documents in this collection.  Possible values:\n\n - **`'STRING'`**: random strings\n - **`'MONGO'`**:  random [`Mongo.ObjectID`](#mongo_object_id) values\n\nThe default id generation technique is `'STRING'`.\n * @param {Function} options.transform An optional transformation function. Documents will be passed through this function before being returned from `fetch` or `findOne`, and before being passed to callbacks of `observe`, `map`, `forEach`, `allow`, and `deny`. Transforms are *not* applied for the callbacks of `observeChanges` or to cursors returned from publish functions.\n * @param {Boolean} options.defineMutationMethods Set to `false` to skip setting up the mutation methods that enable insert/update/remove from client code. Default `true`.\n */\n\nMongo.Collection = function Collection(name, options) {\n  if (!name && name !== null) {\n    Meteor._debug(\"Warning: creating anonymous collection. It will not be \" + \"saved or synchronized over the network. (Pass null for \" + \"the collection name to turn off this warning.)\");\n\n    name = null;\n  }\n\n  if (name !== null && typeof name !== \"string\") {\n    throw new Error(\"First argument to new Mongo.Collection must be a string or null\");\n  }\n\n  if (options && options.methods) {\n    // Backwards compatibility hack with original signature (which passed\n    // \"connection\" directly instead of in options. (Connections must have a \"methods\"\n    // method.)\n    // XXX remove before 1.0\n    options = {\n      connection: options\n    };\n  } // Backwards compatibility: \"connection\" used to be called \"manager\".\n\n\n  if (options && options.manager && !options.connection) {\n    options.connection = options.manager;\n  }\n\n  options = (0, _objectSpread2.default)({\n    connection: undefined,\n    idGeneration: 'STRING',\n    transform: null,\n    _driver: undefined,\n    _preventAutopublish: false\n  }, options);\n\n  switch (options.idGeneration) {\n    case 'MONGO':\n      this._makeNewID = function () {\n        var src = name ? DDP.randomStream('/collection/' + name) : Random.insecure;\n        return new Mongo.ObjectID(src.hexString(24));\n      };\n\n      break;\n\n    case 'STRING':\n    default:\n      this._makeNewID = function () {\n        var src = name ? DDP.randomStream('/collection/' + name) : Random.insecure;\n        return src.id();\n      };\n\n      break;\n  }\n\n  this._transform = LocalCollection.wrapTransform(options.transform);\n  if (!name || options.connection === null) // note: nameless collections never have a connection\n    this._connection = null;else if (options.connection) this._connection = options.connection;else if (Meteor.isClient) this._connection = Meteor.connection;else this._connection = Meteor.server;\n\n  if (!options._driver) {\n    // XXX This check assumes that webapp is loaded so that Meteor.server !==\n    // null. We should fully support the case of \"want to use a Mongo-backed\n    // collection from Node code without webapp\", but we don't yet.\n    // #MeteorServerNull\n    if (name && this._connection === Meteor.server && typeof MongoInternals !== \"undefined\" && MongoInternals.defaultRemoteCollectionDriver) {\n      options._driver = MongoInternals.defaultRemoteCollectionDriver();\n    } else {\n      const {\n        LocalCollectionDriver\n      } = require(\"./local_collection_driver.js\");\n\n      options._driver = LocalCollectionDriver;\n    }\n  }\n\n  this._collection = options._driver.open(name, this._connection);\n  this._name = name;\n  this._driver = options._driver;\n\n  this._maybeSetUpReplication(name, options); // XXX don't define these until allow or deny is actually used for this\n  // collection. Could be hard if the security rules are only defined on the\n  // server.\n\n\n  if (options.defineMutationMethods !== false) {\n    try {\n      this._defineMutationMethods({\n        useExisting: options._suppressSameNameError === true\n      });\n    } catch (error) {\n      // Throw a more understandable error on the server for same collection name\n      if (error.message === `A method named '/${name}/insert' is already defined`) throw new Error(`There is already a collection named \"${name}\"`);\n      throw error;\n    }\n  } // autopublish\n\n\n  if (Package.autopublish && !options._preventAutopublish && this._connection && this._connection.publish) {\n    this._connection.publish(null, () => this.find(), {\n      is_auto: true\n    });\n  }\n};\n\nObject.assign(Mongo.Collection.prototype, {\n  _maybeSetUpReplication(name, {\n    _suppressSameNameError = false\n  }) {\n    const self = this;\n\n    if (!(self._connection && self._connection.registerStore)) {\n      return;\n    } // OK, we're going to be a slave, replicating some remote\n    // database, except possibly with some temporary divergence while\n    // we have unacknowledged RPC's.\n\n\n    const ok = self._connection.registerStore(name, {\n      // Called at the beginning of a batch of updates. batchSize is the number\n      // of update calls to expect.\n      //\n      // XXX This interface is pretty janky. reset probably ought to go back to\n      // being its own function, and callers shouldn't have to calculate\n      // batchSize. The optimization of not calling pause/remove should be\n      // delayed until later: the first call to update() should buffer its\n      // message, and then we can either directly apply it at endUpdate time if\n      // it was the only update, or do pauseObservers/apply/apply at the next\n      // update() if there's another one.\n      beginUpdate(batchSize, reset) {\n        // pause observers so users don't see flicker when updating several\n        // objects at once (including the post-reconnect reset-and-reapply\n        // stage), and so that a re-sorting of a query can take advantage of the\n        // full _diffQuery moved calculation instead of applying change one at a\n        // time.\n        if (batchSize > 1 || reset) self._collection.pauseObservers();\n        if (reset) self._collection.remove({});\n      },\n\n      // Apply an update.\n      // XXX better specify this interface (not in terms of a wire message)?\n      update(msg) {\n        var mongoId = MongoID.idParse(msg.id);\n\n        var doc = self._collection.findOne(mongoId); // Is this a \"replace the whole doc\" message coming from the quiescence\n        // of method writes to an object? (Note that 'undefined' is a valid\n        // value meaning \"remove it\".)\n\n\n        if (msg.msg === 'replace') {\n          var replace = msg.replace;\n\n          if (!replace) {\n            if (doc) self._collection.remove(mongoId);\n          } else if (!doc) {\n            self._collection.insert(replace);\n          } else {\n            // XXX check that replace has no $ ops\n            self._collection.update(mongoId, replace);\n          }\n\n          return;\n        } else if (msg.msg === 'added') {\n          if (doc) {\n            throw new Error(\"Expected not to find a document already present for an add\");\n          }\n\n          self._collection.insert((0, _objectSpread2.default)({\n            _id: mongoId\n          }, msg.fields));\n        } else if (msg.msg === 'removed') {\n          if (!doc) throw new Error(\"Expected to find a document already present for removed\");\n\n          self._collection.remove(mongoId);\n        } else if (msg.msg === 'changed') {\n          if (!doc) throw new Error(\"Expected to find a document to change\");\n          const keys = Object.keys(msg.fields);\n\n          if (keys.length > 0) {\n            var modifier = {};\n            keys.forEach(key => {\n              const value = msg.fields[key];\n\n              if (typeof value === \"undefined\") {\n                if (!modifier.$unset) {\n                  modifier.$unset = {};\n                }\n\n                modifier.$unset[key] = 1;\n              } else {\n                if (!modifier.$set) {\n                  modifier.$set = {};\n                }\n\n                modifier.$set[key] = value;\n              }\n            });\n\n            self._collection.update(mongoId, modifier);\n          }\n        } else {\n          throw new Error(\"I don't know how to deal with this message\");\n        }\n      },\n\n      // Called at the end of a batch of updates.\n      endUpdate() {\n        self._collection.resumeObservers();\n      },\n\n      // Called around method stub invocations to capture the original versions\n      // of modified documents.\n      saveOriginals() {\n        self._collection.saveOriginals();\n      },\n\n      retrieveOriginals() {\n        return self._collection.retrieveOriginals();\n      },\n\n      // Used to preserve current versions of documents across a store reset.\n      getDoc(id) {\n        return self.findOne(id);\n      },\n\n      // To be able to get back to the collection from the store.\n      _getCollection() {\n        return self;\n      }\n\n    });\n\n    if (!ok) {\n      const message = `There is already a collection named \"${name}\"`;\n\n      if (_suppressSameNameError === true) {\n        // XXX In theory we do not have to throw when `ok` is falsy. The\n        // store is already defined for this collection name, but this\n        // will simply be another reference to it and everything should\n        // work. However, we have historically thrown an error here, so\n        // for now we will skip the error only when _suppressSameNameError\n        // is `true`, allowing people to opt in and give this some real\n        // world testing.\n        console.warn ? console.warn(message) : console.log(message);\n      } else {\n        throw new Error(message);\n      }\n    }\n  },\n\n  ///\n  /// Main collection API\n  ///\n  _getFindSelector(args) {\n    if (args.length == 0) return {};else return args[0];\n  },\n\n  _getFindOptions(args) {\n    var self = this;\n\n    if (args.length < 2) {\n      return {\n        transform: self._transform\n      };\n    } else {\n      check(args[1], Match.Optional(Match.ObjectIncluding({\n        fields: Match.Optional(Match.OneOf(Object, undefined)),\n        sort: Match.Optional(Match.OneOf(Object, Array, Function, undefined)),\n        limit: Match.Optional(Match.OneOf(Number, undefined)),\n        skip: Match.Optional(Match.OneOf(Number, undefined))\n      })));\n      return (0, _objectSpread2.default)({\n        transform: self._transform\n      }, args[1]);\n    }\n  },\n\n  /**\n   * @summary Find the documents in a collection that match the selector.\n   * @locus Anywhere\n   * @method find\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} [selector] A query describing the documents to find\n   * @param {Object} [options]\n   * @param {MongoSortSpecifier} options.sort Sort order (default: natural order)\n   * @param {Number} options.skip Number of results to skip at the beginning\n   * @param {Number} options.limit Maximum number of results to return\n   * @param {MongoFieldSpecifier} options.fields Dictionary of fields to return or exclude.\n   * @param {Boolean} options.reactive (Client only) Default `true`; pass `false` to disable reactivity\n   * @param {Function} options.transform Overrides `transform` on the  [`Collection`](#collections) for this cursor.  Pass `null` to disable transformation.\n   * @param {Boolean} options.disableOplog (Server only) Pass true to disable oplog-tailing on this query. This affects the way server processes calls to `observe` on this query. Disabling the oplog can be useful when working with data that updates in large batches.\n   * @param {Number} options.pollingIntervalMs (Server only) When oplog is disabled (through the use of `disableOplog` or when otherwise not available), the frequency (in milliseconds) of how often to poll this query when observing on the server. Defaults to 10000ms (10 seconds).\n   * @param {Number} options.pollingThrottleMs (Server only) When oplog is disabled (through the use of `disableOplog` or when otherwise not available), the minimum time (in milliseconds) to allow between re-polling when observing on the server. Increasing this will save CPU and mongo load at the expense of slower updates to users. Decreasing this is not recommended. Defaults to 50ms.\n   * @param {Number} options.maxTimeMs (Server only) If set, instructs MongoDB to set a time limit for this cursor's operations. If the operation reaches the specified time limit (in milliseconds) without the having been completed, an exception will be thrown. Useful to prevent an (accidental or malicious) unoptimized query from causing a full collection scan that would disrupt other database users, at the expense of needing to handle the resulting error.\n   * @param {String|Object} options.hint (Server only) Overrides MongoDB's default index selection and query optimization process. Specify an index to force its use, either by its name or index specification. You can also specify `{ $natural : 1 }` to force a forwards collection scan, or `{ $natural : -1 }` for a reverse collection scan. Setting this is only recommended for advanced users.\n   * @returns {Mongo.Cursor}\n   */\n  find(...args) {\n    // Collection.find() (return all docs) behaves differently\n    // from Collection.find(undefined) (return 0 docs).  so be\n    // careful about the length of arguments.\n    return this._collection.find(this._getFindSelector(args), this._getFindOptions(args));\n  },\n\n  /**\n   * @summary Finds the first document that matches the selector, as ordered by sort and skip options. Returns `undefined` if no matching document is found.\n   * @locus Anywhere\n   * @method findOne\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} [selector] A query describing the documents to find\n   * @param {Object} [options]\n   * @param {MongoSortSpecifier} options.sort Sort order (default: natural order)\n   * @param {Number} options.skip Number of results to skip at the beginning\n   * @param {MongoFieldSpecifier} options.fields Dictionary of fields to return or exclude.\n   * @param {Boolean} options.reactive (Client only) Default true; pass false to disable reactivity\n   * @param {Function} options.transform Overrides `transform` on the [`Collection`](#collections) for this cursor.  Pass `null` to disable transformation.\n   * @returns {Object}\n   */\n  findOne(...args) {\n    return this._collection.findOne(this._getFindSelector(args), this._getFindOptions(args));\n  }\n\n});\nObject.assign(Mongo.Collection, {\n  _publishCursor(cursor, sub, collection) {\n    var observeHandle = cursor.observeChanges({\n      added: function (id, fields) {\n        sub.added(collection, id, fields);\n      },\n      changed: function (id, fields) {\n        sub.changed(collection, id, fields);\n      },\n      removed: function (id) {\n        sub.removed(collection, id);\n      }\n    }); // We don't call sub.ready() here: it gets called in livedata_server, after\n    // possibly calling _publishCursor on multiple returned cursors.\n    // register stop callback (expects lambda w/ no args).\n\n    sub.onStop(function () {\n      observeHandle.stop();\n    }); // return the observeHandle in case it needs to be stopped early\n\n    return observeHandle;\n  },\n\n  // protect against dangerous selectors.  falsey and {_id: falsey} are both\n  // likely programmer error, and not what you want, particularly for destructive\n  // operations. If a falsey _id is sent in, a new string _id will be\n  // generated and returned; if a fallbackId is provided, it will be returned\n  // instead.\n  _rewriteSelector(selector, {\n    fallbackId\n  } = {}) {\n    // shorthand -- scalars match _id\n    if (LocalCollection._selectorIsId(selector)) selector = {\n      _id: selector\n    };\n\n    if (Array.isArray(selector)) {\n      // This is consistent with the Mongo console itself; if we don't do this\n      // check passing an empty array ends up selecting all items\n      throw new Error(\"Mongo selector can't be an array.\");\n    }\n\n    if (!selector || '_id' in selector && !selector._id) {\n      // can't match anything\n      return {\n        _id: fallbackId || Random.id()\n      };\n    }\n\n    return selector;\n  }\n\n});\nObject.assign(Mongo.Collection.prototype, {\n  // 'insert' immediately returns the inserted document's new _id.\n  // The others return values immediately if you are in a stub, an in-memory\n  // unmanaged collection, or a mongo-backed collection and you don't pass a\n  // callback. 'update' and 'remove' return the number of affected\n  // documents. 'upsert' returns an object with keys 'numberAffected' and, if an\n  // insert happened, 'insertedId'.\n  //\n  // Otherwise, the semantics are exactly like other methods: they take\n  // a callback as an optional last argument; if no callback is\n  // provided, they block until the operation is complete, and throw an\n  // exception if it fails; if a callback is provided, then they don't\n  // necessarily block, and they call the callback when they finish with error and\n  // result arguments.  (The insert method provides the document ID as its result;\n  // update and remove provide the number of affected docs as the result; upsert\n  // provides an object with numberAffected and maybe insertedId.)\n  //\n  // On the client, blocking is impossible, so if a callback\n  // isn't provided, they just return immediately and any error\n  // information is lost.\n  //\n  // There's one more tweak. On the client, if you don't provide a\n  // callback, then if there is an error, a message will be logged with\n  // Meteor._debug.\n  //\n  // The intent (though this is actually determined by the underlying\n  // drivers) is that the operations should be done synchronously, not\n  // generating their result until the database has acknowledged\n  // them. In the future maybe we should provide a flag to turn this\n  // off.\n\n  /**\n   * @summary Insert a document in the collection.  Returns its unique _id.\n   * @locus Anywhere\n   * @method  insert\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {Object} doc The document to insert. May not yet have an _id attribute, in which case Meteor will generate one for you.\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the _id as the second.\n   */\n  insert(doc, callback) {\n    // Make sure we were passed a document to insert\n    if (!doc) {\n      throw new Error(\"insert requires an argument\");\n    } // Make a shallow clone of the document, preserving its prototype.\n\n\n    doc = Object.create(Object.getPrototypeOf(doc), Object.getOwnPropertyDescriptors(doc));\n\n    if ('_id' in doc) {\n      if (!doc._id || !(typeof doc._id === 'string' || doc._id instanceof Mongo.ObjectID)) {\n        throw new Error(\"Meteor requires document _id fields to be non-empty strings or ObjectIDs\");\n      }\n    } else {\n      let generateId = true; // Don't generate the id if we're the client and the 'outermost' call\n      // This optimization saves us passing both the randomSeed and the id\n      // Passing both is redundant.\n\n      if (this._isRemoteCollection()) {\n        const enclosing = DDP._CurrentMethodInvocation.get();\n\n        if (!enclosing) {\n          generateId = false;\n        }\n      }\n\n      if (generateId) {\n        doc._id = this._makeNewID();\n      }\n    } // On inserts, always return the id that we generated; on all other\n    // operations, just return the result from the collection.\n\n\n    var chooseReturnValueFromCollectionResult = function (result) {\n      if (doc._id) {\n        return doc._id;\n      } // XXX what is this for??\n      // It's some iteraction between the callback to _callMutatorMethod and\n      // the return value conversion\n\n\n      doc._id = result;\n      return result;\n    };\n\n    const wrappedCallback = wrapCallback(callback, chooseReturnValueFromCollectionResult);\n\n    if (this._isRemoteCollection()) {\n      const result = this._callMutatorMethod(\"insert\", [doc], wrappedCallback);\n\n      return chooseReturnValueFromCollectionResult(result);\n    } // it's my collection.  descend into the collection object\n    // and propagate any exception.\n\n\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      const result = this._collection.insert(doc, wrappedCallback);\n\n      return chooseReturnValueFromCollectionResult(result);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n\n      throw e;\n    }\n  },\n\n  /**\n   * @summary Modify one or more documents in the collection. Returns the number of matched documents.\n   * @locus Anywhere\n   * @method update\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to modify\n   * @param {MongoModifier} modifier Specifies how to modify the documents\n   * @param {Object} [options]\n   * @param {Boolean} options.multi True to modify all matching documents; false to only modify one of the matching documents (the default).\n   * @param {Boolean} options.upsert True to insert a document if no matching documents are found.\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the number of affected documents as the second.\n   */\n  update(selector, modifier, ...optionsAndCallback) {\n    const callback = popCallbackFromArgs(optionsAndCallback); // We've already popped off the callback, so we are left with an array\n    // of one or zero items\n\n    const options = (0, _objectSpread2.default)({}, optionsAndCallback[0] || null);\n    let insertedId;\n\n    if (options && options.upsert) {\n      // set `insertedId` if absent.  `insertedId` is a Meteor extension.\n      if (options.insertedId) {\n        if (!(typeof options.insertedId === 'string' || options.insertedId instanceof Mongo.ObjectID)) throw new Error(\"insertedId must be string or ObjectID\");\n        insertedId = options.insertedId;\n      } else if (!selector || !selector._id) {\n        insertedId = this._makeNewID();\n        options.generatedId = true;\n        options.insertedId = insertedId;\n      }\n    }\n\n    selector = Mongo.Collection._rewriteSelector(selector, {\n      fallbackId: insertedId\n    });\n    const wrappedCallback = wrapCallback(callback);\n\n    if (this._isRemoteCollection()) {\n      const args = [selector, modifier, options];\n      return this._callMutatorMethod(\"update\", args, wrappedCallback);\n    } // it's my collection.  descend into the collection object\n    // and propagate any exception.\n\n\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      return this._collection.update(selector, modifier, options, wrappedCallback);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n\n      throw e;\n    }\n  },\n\n  /**\n   * @summary Remove documents from the collection\n   * @locus Anywhere\n   * @method remove\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to remove\n   * @param {Function} [callback] Optional.  If present, called with an error object as its argument.\n   */\n  remove(selector, callback) {\n    selector = Mongo.Collection._rewriteSelector(selector);\n    const wrappedCallback = wrapCallback(callback);\n\n    if (this._isRemoteCollection()) {\n      return this._callMutatorMethod(\"remove\", [selector], wrappedCallback);\n    } // it's my collection.  descend into the collection object\n    // and propagate any exception.\n\n\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      return this._collection.remove(selector, wrappedCallback);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n\n      throw e;\n    }\n  },\n\n  // Determine if this collection is simply a minimongo representation of a real\n  // database on another server\n  _isRemoteCollection() {\n    // XXX see #MeteorServerNull\n    return this._connection && this._connection !== Meteor.server;\n  },\n\n  /**\n   * @summary Modify one or more documents in the collection, or insert one if no matching documents were found. Returns an object with keys `numberAffected` (the number of documents modified)  and `insertedId` (the unique _id of the document that was inserted, if any).\n   * @locus Anywhere\n   * @method upsert\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to modify\n   * @param {MongoModifier} modifier Specifies how to modify the documents\n   * @param {Object} [options]\n   * @param {Boolean} options.multi True to modify all matching documents; false to only modify one of the matching documents (the default).\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the number of affected documents as the second.\n   */\n  upsert(selector, modifier, options, callback) {\n    if (!callback && typeof options === \"function\") {\n      callback = options;\n      options = {};\n    }\n\n    return this.update(selector, modifier, (0, _objectSpread2.default)({}, options, {\n      _returnObject: true,\n      upsert: true\n    }), callback);\n  },\n\n  // We'll actually design an index API later. For now, we just pass through to\n  // Mongo's, but make it synchronous.\n  _ensureIndex(index, options) {\n    var self = this;\n    if (!self._collection._ensureIndex) throw new Error(\"Can only call _ensureIndex on server collections\");\n\n    self._collection._ensureIndex(index, options);\n  },\n\n  _dropIndex(index) {\n    var self = this;\n    if (!self._collection._dropIndex) throw new Error(\"Can only call _dropIndex on server collections\");\n\n    self._collection._dropIndex(index);\n  },\n\n  _dropCollection() {\n    var self = this;\n    if (!self._collection.dropCollection) throw new Error(\"Can only call _dropCollection on server collections\");\n\n    self._collection.dropCollection();\n  },\n\n  _createCappedCollection(byteSize, maxDocuments) {\n    var self = this;\n    if (!self._collection._createCappedCollection) throw new Error(\"Can only call _createCappedCollection on server collections\");\n\n    self._collection._createCappedCollection(byteSize, maxDocuments);\n  },\n\n  /**\n   * @summary Returns the [`Collection`](http://mongodb.github.io/node-mongodb-native/2.2/api/Collection.html) object corresponding to this collection from the [npm `mongodb` driver module](https://www.npmjs.com/package/mongodb) which is wrapped by `Mongo.Collection`.\n   * @locus Server\n   */\n  rawCollection() {\n    var self = this;\n\n    if (!self._collection.rawCollection) {\n      throw new Error(\"Can only call rawCollection on server collections\");\n    }\n\n    return self._collection.rawCollection();\n  },\n\n  /**\n   * @summary Returns the [`Db`](http://mongodb.github.io/node-mongodb-native/2.2/api/Db.html) object corresponding to this collection's database connection from the [npm `mongodb` driver module](https://www.npmjs.com/package/mongodb) which is wrapped by `Mongo.Collection`.\n   * @locus Server\n   */\n  rawDatabase() {\n    var self = this;\n\n    if (!(self._driver.mongo && self._driver.mongo.db)) {\n      throw new Error(\"Can only call rawDatabase on server collections\");\n    }\n\n    return self._driver.mongo.db;\n  }\n\n}); // Convert the callback to not return a result if there is an error\n\nfunction wrapCallback(callback, convertResult) {\n  return callback && function (error, result) {\n    if (error) {\n      callback(error);\n    } else if (typeof convertResult === \"function\") {\n      callback(null, convertResult(result));\n    } else {\n      callback(null, result);\n    }\n  };\n}\n/**\n * @summary Create a Mongo-style `ObjectID`.  If you don't specify a `hexString`, the `ObjectID` will generated randomly (not using MongoDB's ID construction rules).\n * @locus Anywhere\n * @class\n * @param {String} [hexString] Optional.  The 24-character hexadecimal contents of the ObjectID to create\n */\n\n\nMongo.ObjectID = MongoID.ObjectID;\n/**\n * @summary To create a cursor, use find. To access the documents in a cursor, use forEach, map, or fetch.\n * @class\n * @instanceName cursor\n */\n\nMongo.Cursor = LocalCollection.Cursor;\n/**\n * @deprecated in 0.9.1\n */\n\nMongo.Collection.Cursor = Mongo.Cursor;\n/**\n * @deprecated in 0.9.1\n */\n\nMongo.Collection.ObjectID = Mongo.ObjectID;\n/**\n * @deprecated in 0.9.1\n */\n\nMeteor.Collection = Mongo.Collection; // Allow deny stuff is now in the allow-deny package\n\nObject.assign(Meteor.Collection.prototype, AllowDeny.CollectionPrototype);\n\nfunction popCallbackFromArgs(args) {\n  // Pull off any callback (or perhaps a 'callback' variable that was passed\n  // in undefined, like how 'upsert' does it).\n  if (args.length && (args[args.length - 1] === undefined || args[args.length - 1] instanceof Function)) {\n    return args.pop();\n  }\n}\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n},\"connection_options.js\":function(){\n\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//                                                                                                                     //\n// packages/mongo/connection_options.js                                                                                //\n//                                                                                                                     //\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n                                                                                                                       //\n/**\n * @summary Allows for user specified connection options\n * @example http://mongodb.github.io/node-mongodb-native/2.2/reference/connecting/connection-settings/\n * @locus Server\n * @param {Object} options User specified Mongo connection options\n */\nMongo.setConnectionOptions = function setConnectionOptions(options) {\n  check(options, Object);\n  Mongo._connectionOptions = options;\n};\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n}}}}},{\n  \"extensions\": [\n    \".js\",\n    \".json\"\n  ]\n});\nrequire(\"/node_modules/meteor/mongo/mongo_driver.js\");\nrequire(\"/node_modules/meteor/mongo/oplog_tailing.js\");\nrequire(\"/node_modules/meteor/mongo/observe_multiplex.js\");\nrequire(\"/node_modules/meteor/mongo/doc_fetcher.js\");\nrequire(\"/node_modules/meteor/mongo/polling_observe_driver.js\");\nrequire(\"/node_modules/meteor/mongo/oplog_observe_driver.js\");\nrequire(\"/node_modules/meteor/mongo/local_collection_driver.js\");\nrequire(\"/node_modules/meteor/mongo/remote_collection_driver.js\");\nrequire(\"/node_modules/meteor/mongo/collection.js\");\nrequire(\"/node_modules/meteor/mongo/connection_options.js\");\n\n/* Exports */\nPackage._define(\"mongo\", {\n  MongoInternals: MongoInternals,\n  MongoTest: MongoTest,\n  Mongo: Mongo\n});\n\n})();\n","servePath":"/packages/mongo.js","sourceMap":{"version":3,"sources":["packages/mongo/mongo_driver.js","packages/mongo/oplog_tailing.js","packages/mongo/observe_multiplex.js","packages/mongo/doc_fetcher.js","packages/mongo/polling_observe_driver.js","packages/mongo/oplog_observe_driver.js","packages/mongo/local_collection_driver.js","packages/mongo/remote_collection_driver.js","packages/mongo/collection.js","packages/mongo/connection_options.js"],"names":["MongoDB","NpmModuleMongodb","Future","Npm","require","MongoInternals","MongoTest","NpmModules","mongodb","version","NpmModuleMongodbVersion","module","NpmModule","replaceNames","filter","thing","_","isArray","map","bind","ret","each","value","key","Timestamp","prototype","clone","makeMongoLegal","name","unmakeMongoLegal","substr","replaceMongoAtomWithMeteor","document","Binary","buffer","Uint8Array","ObjectID","Mongo","toHexString","size","EJSON","fromJSONValue","undefined","replaceMeteorAtomWithMongo","isBinary","Buffer","from","_isCustomType","toJSONValue","replaceTypes","atomTransformer","replacedTopLevelAtom","val","valReplaced","MongoConnection","url","options","self","_observeMultiplexers","_onFailoverHook","Hook","mongoOptions","Object","assign","autoReconnect","reconnectTries","Infinity","ignoreUndefined","_connectionOptions","test","native_parser","has","poolSize","db","_primary","_oplogHandle","_docFetcher","connectFuture","connect","Meteor","bindEnvironment","err","serverConfig","isMasterDoc","primary","on","kind","doc","callback","me","resolver","wait","oplogUrl","Package","OplogHandle","databaseName","DocFetcher","close","Error","oplogHandle","stop","wrap","rawCollection","collectionName","future","collection","_createCappedCollection","byteSize","maxDocuments","createCollection","capped","max","_maybeBeginWrite","fence","DDPServer","_CurrentWriteFence","get","beginWrite","committed","_onFailover","register","writeCallback","write","refresh","result","refreshErr","bindEnvironmentForWrite","_insert","collection_name","sendError","e","_expectedByTest","LocalCollection","_isPlainObject","id","_id","insert","safe","_refresh","selector","refreshKey","specificIds","_idsMatchedBySelector","extend","_remove","wrappedCallback","driverResult","transformResult","numberAffected","remove","_dropCollection","cb","dropCollection","drop","_dropDatabase","dropDatabase","_update","mod","Function","mongoOpts","upsert","multi","fullResult","mongoSelector","mongoMod","isModify","_isModificationMod","_forbidReplace","knownId","newDoc","_createUpsertDocument","insertedId","generatedId","simulateUpsertWithInsertedId","error","_returnObject","hasOwnProperty","$setOnInsert","update","meteorResult","mongoResult","upserted","length","n","NUM_OPTIMISTIC_TRIES","_isCannotChangeIdError","errmsg","indexOf","mongoOptsForUpdate","mongoOptsForInsert","replacementWithId","tries","doUpdate","doConditionalInsert","method","wrapAsync","apply","arguments","find","Cursor","CursorDescription","findOne","limit","fetch","_ensureIndex","index","indexName","ensureIndex","_dropIndex","dropIndex","Collection","_rewriteSelector","mongo","cursorDescription","_mongo","_cursorDescription","_synchronousCursor","Symbol","iterator","tailable","_createSynchronousCursor","selfForIteration","useTransform","rewind","getTransform","transform","_publishCursor","sub","_getCollectionName","observe","callbacks","_observeFromObserveChanges","observeChanges","methods","ordered","_observeChangesCallbacksAreOrdered","exceptionName","forEach","_observeChanges","pick","cursorOptions","sort","skip","awaitdata","numberOfRetries","OPLOG_COLLECTION","ts","oplogReplay","dbCursor","fields","maxTimeMs","maxTimeMS","hint","SynchronousCursor","_dbCursor","_selfForIteration","_transform","wrapTransform","_synchronousNextObject","nextObject","_synchronousCount","count","_visitedIds","_IdMap","_nextObject","set","thisArg","_rewind","call","res","push","identity","applySkipLimit","getRawObjects","results","next","done","tail","docCallback","cursor","stopped","lastTS","loop","newSelector","$gt","setTimeout","defer","_observeChangesTailable","observeKey","stringify","multiplexer","observeDriver","firstHandle","_noYieldsAllowed","ObserveMultiplexer","onStop","observeHandle","ObserveHandle","matcher","sorter","canUseOplog","all","_testOnlyPollCallback","Minimongo","Matcher","OplogObserveDriver","cursorSupported","Sorter","f","driverClass","PollingObserveDriver","mongoHandle","_observeDriver","addHandleAndSendInitialAdds","listenAll","listenCallback","listeners","forEachTrigger","trigger","_InvalidationCrossbar","listen","listener","triggerCallback","addedBefore","added","MongoTimestamp","Connection","TOO_FAR_BEHIND","process","env","METEOR_OPLOG_TOO_FAR_BEHIND","showTS","getHighBits","getLowBits","idForOp","op","o","o2","dbName","_oplogUrl","_dbName","_oplogLastEntryConnection","_oplogTailConnection","_stopped","_tailHandle","_readyFuture","_crossbar","_Crossbar","factPackage","factName","_baseOplogSelector","ns","RegExp","_escapeRegExp","$or","$in","$exists","_catchingUpFutures","_lastProcessedTS","_onSkippedEntriesHook","debugPrintExceptions","_entryQueue","_DoubleEndedQueue","_workerActive","_startTailing","onOplogEntry","originalCallback","notification","_debug","listenHandle","onSkippedEntries","waitUntilCaughtUp","lastEntry","$natural","_sleepForMs","lessThanOrEqual","insertAfter","greaterThan","splice","mongodbUri","parse","database","admin","command","ismaster","setName","lastOplogEntry","oplogSelector","_maybeStartWorker","return","isEmpty","pop","clear","_setLastProcessedTS","shift","JSON","fire","sequencer","_defineTooFarBehind","_resetTooFarBehind","Facts","incrementServerFact","_ordered","_onStop","_queue","_SynchronousQueue","_handles","_cache","_CachingChangeObserver","_addHandleTasksScheduledButNotPerformed","callbackNames","callbackName","_applyCallback","toArray","handle","safeToRunTask","runTask","_sendAdds","removeHandle","_ready","_stop","fromQueryError","ready","queueTask","queryError","throw","onFlush","isResolved","args","applyChange","keys","handleId","add","_addedBefore","_added","docs","nextObserveHandleId","_multiplexer","before","Fiber","mongoConnection","_mongoConnection","_callbacksForCacheKey","cacheKey","check","String","clonedDoc","run","_mongoHandle","_stopCallbacks","_results","_pollsScheduledButNotStarted","_pendingWrites","_ensurePollIsScheduled","throttle","_unthrottledEnsurePollIsScheduled","pollingThrottleMs","_taskQueue","listenersHandle","pollingInterval","pollingIntervalMs","_pollingInterval","intervalHandle","setInterval","clearInterval","_pollMongo","_suspendPolling","_resumePolling","first","newResults","oldResults","writesForCycle","code","message","Array","_diffQueryChanges","w","c","PHASE","QUERYING","FETCHING","STEADY","SwitchedToQuery","finishIfNeedToPollQuery","currentId","_usesOplog","comparator","getComparator","heapOptions","IdMap","_limit","_comparator","_sorter","_unpublishedBuffer","MinMaxHeap","_published","MaxHeap","_safeAppendToBuffer","_stopHandles","_registerPhaseChange","_matcher","projection","_projectionFn","_compileProjection","_sharedProjection","combineIntoProjection","_sharedProjectionFn","_needToFetch","_currentlyFetching","_fetchGeneration","_requeryWhenDoneThisQuery","_writesToCommitWhenWeReachSteady","_needToPollQuery","_phase","_handleOplogEntryQuerying","_handleOplogEntrySteadyOrFetching","fired","_oplogObserveDrivers","onBeforeFire","drivers","driver","_runInitialQuery","_addPublished","overflowingDocId","maxElementId","overflowingDoc","equals","removed","_addBuffered","_removePublished","empty","newDocId","minElementId","_removeBuffered","_changePublished","oldDoc","projectedNew","projectedOld","changed","DiffSequence","makeChangedFields","maxBufferedId","_addMatching","maxPublished","maxBuffered","toPublish","canAppendToBuffer","canInsertIntoBuffer","toBuffer","_removeMatching","_handleDoc","matchesNow","documentMatches","publishedBefore","bufferedBefore","cachedBefore","minBuffered","staysInPublished","staysInBuffer","_fetchModifiedDocuments","thisGeneration","waiting","fut","_beSteady","writes","toString","isReplace","canDirectlyModifyDoc","modifierCanBeDirectlyApplied","_modify","canBecomeTrueByModifier","affectedByModifier","_runQuery","initial","_doneQuerying","_pollQuery","newBuffer","_cursorForQuery","i","_publishNewResults","optionsOverwrite","description","idsToRemove","_oplogEntryHandle","_listenersHandle","phase","now","Date","timeDiff","_phaseStartTime","disableOplog","_disableOplog","_checkSupportedProjection","hasWhere","hasGeoQuery","modifier","operation","field","export","LocalCollectionDriver","constructor","noConnCollections","create","open","conn","ensureCollection","_mongo_livedata_collections","collections","RemoteCollectionDriver","mongo_url","m","defaultRemoteCollectionDriver","once","connectionOptions","mongoUrl","MONGO_URL","MONGO_OPLOG_URL","connection","manager","idGeneration","_driver","_preventAutopublish","_makeNewID","src","DDP","randomStream","Random","insecure","hexString","_connection","isClient","server","_collection","_name","_maybeSetUpReplication","defineMutationMethods","_defineMutationMethods","useExisting","_suppressSameNameError","autopublish","publish","is_auto","registerStore","ok","beginUpdate","batchSize","reset","pauseObservers","msg","mongoId","MongoID","idParse","replace","$unset","$set","endUpdate","resumeObservers","saveOriginals","retrieveOriginals","getDoc","_getCollection","console","warn","log","_getFindSelector","_getFindOptions","Match","Optional","ObjectIncluding","OneOf","Number","fallbackId","_selectorIsId","getPrototypeOf","getOwnPropertyDescriptors","generateId","_isRemoteCollection","enclosing","_CurrentMethodInvocation","chooseReturnValueFromCollectionResult","wrapCallback","_callMutatorMethod","optionsAndCallback","popCallbackFromArgs","rawDatabase","convertResult","AllowDeny","CollectionPrototype","setConnectionOptions"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;AASA,IAAIA,UAAUC,gBAAd;;AACA,IAAIC,SAASC,IAAIC,OAAJ,CAAY,eAAZ,CAAb;;AAEAC,iBAAiB,EAAjB;AACAC,YAAY,EAAZ;AAEAD,eAAeE,UAAf,GAA4B;AAC1BC,WAAS;AACPC,aAASC,uBADF;AAEPC,YAAQX;AAFD;AADiB,CAA5B,C,CAOA;AACA;AACA;AACA;;AACAK,eAAeO,SAAf,GAA2BZ,OAA3B,C,CAEA;AACA;;AACA,IAAIa,eAAe,UAAUC,MAAV,EAAkBC,KAAlB,EAAyB;AAC1C,MAAI,OAAOA,KAAP,KAAiB,QAAjB,IAA6BA,UAAU,IAA3C,EAAiD;AAC/C,QAAIC,EAAEC,OAAF,CAAUF,KAAV,CAAJ,EAAsB;AACpB,aAAOC,EAAEE,GAAF,CAAMH,KAAN,EAAaC,EAAEG,IAAF,CAAON,YAAP,EAAqB,IAArB,EAA2BC,MAA3B,CAAb,CAAP;AACD;;AACD,QAAIM,MAAM,EAAV;;AACAJ,MAAEK,IAAF,CAAON,KAAP,EAAc,UAAUO,KAAV,EAAiBC,GAAjB,EAAsB;AAClCH,UAAIN,OAAOS,GAAP,CAAJ,IAAmBV,aAAaC,MAAb,EAAqBQ,KAArB,CAAnB;AACD,KAFD;;AAGA,WAAOF,GAAP;AACD;;AACD,SAAOL,KAAP;AACD,CAZD,C,CAcA;AACA;AACA;;;AACAf,QAAQwB,SAAR,CAAkBC,SAAlB,CAA4BC,KAA5B,GAAoC,YAAY;AAC9C;AACA,SAAO,IAAP;AACD,CAHD;;AAKA,IAAIC,iBAAiB,UAAUC,IAAV,EAAgB;AAAE,SAAO,UAAUA,IAAjB;AAAwB,CAA/D;;AACA,IAAIC,mBAAmB,UAAUD,IAAV,EAAgB;AAAE,SAAOA,KAAKE,MAAL,CAAY,CAAZ,CAAP;AAAwB,CAAjE;;AAEA,IAAIC,6BAA6B,UAAUC,QAAV,EAAoB;AACnD,MAAIA,oBAAoBhC,QAAQiC,MAAhC,EAAwC;AACtC,QAAIC,SAASF,SAASV,KAAT,CAAe,IAAf,CAAb;AACA,WAAO,IAAIa,UAAJ,CAAeD,MAAf,CAAP;AACD;;AACD,MAAIF,oBAAoBhC,QAAQoC,QAAhC,EAA0C;AACxC,WAAO,IAAIC,MAAMD,QAAV,CAAmBJ,SAASM,WAAT,EAAnB,CAAP;AACD;;AACD,MAAIN,SAAS,YAAT,KAA0BA,SAAS,aAAT,CAA1B,IAAqDhB,EAAEuB,IAAF,CAAOP,QAAP,MAAqB,CAA9E,EAAiF;AAC/E,WAAOQ,MAAMC,aAAN,CAAoB5B,aAAagB,gBAAb,EAA+BG,QAA/B,CAApB,CAAP;AACD;;AACD,MAAIA,oBAAoBhC,QAAQwB,SAAhC,EAA2C;AACzC;AACA;AACA;AACA;AACA,WAAOQ,QAAP;AACD;;AACD,SAAOU,SAAP;AACD,CAnBD;;AAqBA,IAAIC,6BAA6B,UAAUX,QAAV,EAAoB;AACnD,MAAIQ,MAAMI,QAAN,CAAeZ,QAAf,CAAJ,EAA8B;AAC5B;AACA;AACA;AACA,WAAO,IAAIhC,QAAQiC,MAAZ,CAAmBY,OAAOC,IAAP,CAAYd,QAAZ,CAAnB,CAAP;AACD;;AACD,MAAIA,oBAAoBK,MAAMD,QAA9B,EAAwC;AACtC,WAAO,IAAIpC,QAAQoC,QAAZ,CAAqBJ,SAASM,WAAT,EAArB,CAAP;AACD;;AACD,MAAIN,oBAAoBhC,QAAQwB,SAAhC,EAA2C;AACzC;AACA;AACA;AACA;AACA,WAAOQ,QAAP;AACD;;AACD,MAAIQ,MAAMO,aAAN,CAAoBf,QAApB,CAAJ,EAAmC;AACjC,WAAOnB,aAAac,cAAb,EAA6Ba,MAAMQ,WAAN,CAAkBhB,QAAlB,CAA7B,CAAP;AACD,GAnBkD,CAoBnD;AACA;;;AACA,SAAOU,SAAP;AACD,CAvBD;;AAyBA,IAAIO,eAAe,UAAUjB,QAAV,EAAoBkB,eAApB,EAAqC;AACtD,MAAI,OAAOlB,QAAP,KAAoB,QAApB,IAAgCA,aAAa,IAAjD,EACE,OAAOA,QAAP;AAEF,MAAImB,uBAAuBD,gBAAgBlB,QAAhB,CAA3B;AACA,MAAImB,yBAAyBT,SAA7B,EACE,OAAOS,oBAAP;AAEF,MAAI/B,MAAMY,QAAV;;AACAhB,IAAEK,IAAF,CAAOW,QAAP,EAAiB,UAAUoB,GAAV,EAAe7B,GAAf,EAAoB;AACnC,QAAI8B,cAAcJ,aAAaG,GAAb,EAAkBF,eAAlB,CAAlB;;AACA,QAAIE,QAAQC,WAAZ,EAAyB;AACvB;AACA,UAAIjC,QAAQY,QAAZ,EACEZ,MAAMJ,EAAEU,KAAF,CAAQM,QAAR,CAAN;AACFZ,UAAIG,GAAJ,IAAW8B,WAAX;AACD;AACF,GARD;;AASA,SAAOjC,GAAP;AACD,CAnBD;;AAsBAkC,kBAAkB,UAAUC,GAAV,EAAeC,OAAf,EAAwB;AACxC,MAAIC,OAAO,IAAX;AACAD,YAAUA,WAAW,EAArB;AACAC,OAAKC,oBAAL,GAA4B,EAA5B;AACAD,OAAKE,eAAL,GAAuB,IAAIC,IAAJ,EAAvB;AAEA,MAAIC,eAAeC,OAAOC,MAAP,CAAc;AAC/B;AACAC,mBAAe,IAFgB;AAG/B;AACA;AACAC,oBAAgBC,QALe;AAM/BC,qBAAiB;AANc,GAAd,EAOhB9B,MAAM+B,kBAPU,CAAnB,CANwC,CAexC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAI,CAAE,0BAA0BC,IAA1B,CAA+Bd,GAA/B,CAAN,EAA4C;AAC1CM,iBAAaS,aAAb,GAA6B,KAA7B;AACD,GAzBuC,CA2BxC;AACA;;;AACA,MAAItD,EAAEuD,GAAF,CAAMf,OAAN,EAAe,UAAf,CAAJ,EAAgC;AAC9B;AACA;AACAK,iBAAaW,QAAb,GAAwBhB,QAAQgB,QAAhC;AACD;;AAEDf,OAAKgB,EAAL,GAAU,IAAV,CAnCwC,CAoCxC;AACA;AACA;;AACAhB,OAAKiB,QAAL,GAAgB,IAAhB;AACAjB,OAAKkB,YAAL,GAAoB,IAApB;AACAlB,OAAKmB,WAAL,GAAmB,IAAnB;AAGA,MAAIC,gBAAgB,IAAI3E,MAAJ,EAApB;AACAF,UAAQ8E,OAAR,CACEvB,GADF,EAEEM,YAFF,EAGEkB,OAAOC,eAAP,CACE,UAAUC,GAAV,EAAeR,EAAf,EAAmB;AACjB,QAAIQ,GAAJ,EAAS;AACP,YAAMA,GAAN;AACD,KAHgB,CAKjB;;;AACA,QAAIR,GAAGS,YAAH,CAAgBC,WAApB,EAAiC;AAC/B1B,WAAKiB,QAAL,GAAgBD,GAAGS,YAAH,CAAgBC,WAAhB,CAA4BC,OAA5C;AACD;;AAEDX,OAAGS,YAAH,CAAgBG,EAAhB,CACE,QADF,EACYN,OAAOC,eAAP,CAAuB,UAAUM,IAAV,EAAgBC,GAAhB,EAAqB;AACpD,UAAID,SAAS,SAAb,EAAwB;AACtB,YAAIC,IAAIH,OAAJ,KAAgB3B,KAAKiB,QAAzB,EAAmC;AACjCjB,eAAKiB,QAAL,GAAgBa,IAAIH,OAApB;;AACA3B,eAAKE,eAAL,CAAqBtC,IAArB,CAA0B,UAAUmE,QAAV,EAAoB;AAC5CA;AACA,mBAAO,IAAP;AACD,WAHD;AAID;AACF,OARD,MAQO,IAAID,IAAIE,EAAJ,KAAWhC,KAAKiB,QAApB,EAA8B;AACnC;AACA;AACA;AACA;AACA;AACAjB,aAAKiB,QAAL,GAAgB,IAAhB;AACD;AACF,KAjBS,CADZ,EAViB,CA8BjB;;AACAG,kBAAc,QAAd,EAAwBJ,EAAxB;AACD,GAjCH,EAkCEI,cAAca,QAAd,EAlCF,CAkC4B;AAlC5B,GAHF,EA7CwC,CAsFxC;;AACAjC,OAAKgB,EAAL,GAAUI,cAAcc,IAAd,EAAV;;AAEA,MAAInC,QAAQoC,QAAR,IAAoB,CAAEC,QAAQ,eAAR,CAA1B,EAAoD;AAClDpC,SAAKkB,YAAL,GAAoB,IAAImB,WAAJ,CAAgBtC,QAAQoC,QAAxB,EAAkCnC,KAAKgB,EAAL,CAAQsB,YAA1C,CAApB;AACAtC,SAAKmB,WAAL,GAAmB,IAAIoB,UAAJ,CAAevC,IAAf,CAAnB;AACD;AACF,CA7FD;;AA+FAH,gBAAgB7B,SAAhB,CAA0BwE,KAA1B,GAAkC,YAAW;AAC3C,MAAIxC,OAAO,IAAX;AAEA,MAAI,CAAEA,KAAKgB,EAAX,EACE,MAAMyB,MAAM,yCAAN,CAAN,CAJyC,CAM3C;;AACA,MAAIC,cAAc1C,KAAKkB,YAAvB;AACAlB,OAAKkB,YAAL,GAAoB,IAApB;AACA,MAAIwB,WAAJ,EACEA,YAAYC,IAAZ,GAVyC,CAY3C;AACA;AACA;;AACAlG,SAAOmG,IAAP,CAAYrF,EAAEG,IAAF,CAAOsC,KAAKgB,EAAL,CAAQwB,KAAf,EAAsBxC,KAAKgB,EAA3B,CAAZ,EAA4C,IAA5C,EAAkDkB,IAAlD;AACD,CAhBD,C,CAkBA;;;AACArC,gBAAgB7B,SAAhB,CAA0B6E,aAA1B,GAA0C,UAAUC,cAAV,EAA0B;AAClE,MAAI9C,OAAO,IAAX;AAEA,MAAI,CAAEA,KAAKgB,EAAX,EACE,MAAMyB,MAAM,iDAAN,CAAN;AAEF,MAAIM,SAAS,IAAItG,MAAJ,EAAb;AACAuD,OAAKgB,EAAL,CAAQgC,UAAR,CAAmBF,cAAnB,EAAmCC,OAAOd,QAAP,EAAnC;AACA,SAAOc,OAAOb,IAAP,EAAP;AACD,CATD;;AAWArC,gBAAgB7B,SAAhB,CAA0BiF,uBAA1B,GAAoD,UAChDH,cADgD,EAChCI,QADgC,EACtBC,YADsB,EACR;AAC1C,MAAInD,OAAO,IAAX;AAEA,MAAI,CAAEA,KAAKgB,EAAX,EACE,MAAMyB,MAAM,2DAAN,CAAN;AAEF,MAAIM,SAAS,IAAItG,MAAJ,EAAb;AACAuD,OAAKgB,EAAL,CAAQoC,gBAAR,CACEN,cADF,EAEE;AAAEO,YAAQ,IAAV;AAAgBvE,UAAMoE,QAAtB;AAAgCI,SAAKH;AAArC,GAFF,EAGEJ,OAAOd,QAAP,EAHF;AAIAc,SAAOb,IAAP;AACD,CAbD,C,CAeA;AACA;AACA;AACA;AACA;;;AACArC,gBAAgB7B,SAAhB,CAA0BuF,gBAA1B,GAA6C,YAAY;AACvD,MAAIC,QAAQC,UAAUC,kBAAV,CAA6BC,GAA7B,EAAZ;;AACA,MAAIH,KAAJ,EAAW;AACT,WAAOA,MAAMI,UAAN,EAAP;AACD,GAFD,MAEO;AACL,WAAO;AAACC,iBAAW,YAAY,CAAE;AAA1B,KAAP;AACD;AACF,CAPD,C,CASA;AACA;;;AACAhE,gBAAgB7B,SAAhB,CAA0B8F,WAA1B,GAAwC,UAAU/B,QAAV,EAAoB;AAC1D,SAAO,KAAK7B,eAAL,CAAqB6D,QAArB,CAA8BhC,QAA9B,CAAP;AACD,CAFD,C,CAKA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,IAAIiC,gBAAgB,UAAUC,KAAV,EAAiBC,OAAjB,EAA0BnC,QAA1B,EAAoC;AACtD,SAAO,UAAUP,GAAV,EAAe2C,MAAf,EAAuB;AAC5B,QAAI,CAAE3C,GAAN,EAAW;AACT;AACA,UAAI;AACF0C;AACD,OAFD,CAEE,OAAOE,UAAP,EAAmB;AACnB,YAAIrC,QAAJ,EAAc;AACZA,mBAASqC,UAAT;AACA;AACD,SAHD,MAGO;AACL,gBAAMA,UAAN;AACD;AACF;AACF;;AACDH,UAAMJ,SAAN;;AACA,QAAI9B,QAAJ,EAAc;AACZA,eAASP,GAAT,EAAc2C,MAAd;AACD,KAFD,MAEO,IAAI3C,GAAJ,EAAS;AACd,YAAMA,GAAN;AACD;AACF,GApBD;AAqBD,CAtBD;;AAwBA,IAAI6C,0BAA0B,UAAUtC,QAAV,EAAoB;AAChD,SAAOT,OAAOC,eAAP,CAAuBQ,QAAvB,EAAiC,aAAjC,CAAP;AACD,CAFD;;AAIAlC,gBAAgB7B,SAAhB,CAA0BsG,OAA1B,GAAoC,UAAUC,eAAV,EAA2BhG,QAA3B,EACUwD,QADV,EACoB;AACtD,MAAI/B,OAAO,IAAX;;AAEA,MAAIwE,YAAY,UAAUC,CAAV,EAAa;AAC3B,QAAI1C,QAAJ,EACE,OAAOA,SAAS0C,CAAT,CAAP;AACF,UAAMA,CAAN;AACD,GAJD;;AAMA,MAAIF,oBAAoB,mCAAxB,EAA6D;AAC3D,QAAIE,IAAI,IAAIhC,KAAJ,CAAU,cAAV,CAAR;AACAgC,MAAEC,eAAF,GAAoB,IAApB;AACAF,cAAUC,CAAV;AACA;AACD;;AAED,MAAI,EAAEE,gBAAgBC,cAAhB,CAA+BrG,QAA/B,KACA,CAACQ,MAAMO,aAAN,CAAoBf,QAApB,CADH,CAAJ,EACuC;AACrCiG,cAAU,IAAI/B,KAAJ,CACR,iDADQ,CAAV;AAEA;AACD;;AAED,MAAIwB,QAAQjE,KAAKuD,gBAAL,EAAZ;;AACA,MAAIW,UAAU,YAAY;AACxB5C,WAAO4C,OAAP,CAAe;AAAClB,kBAAYuB,eAAb;AAA8BM,UAAItG,SAASuG;AAA3C,KAAf;AACD,GAFD;;AAGA/C,aAAWsC,wBAAwBL,cAAcC,KAAd,EAAqBC,OAArB,EAA8BnC,QAA9B,CAAxB,CAAX;;AACA,MAAI;AACF,QAAIiB,aAAahD,KAAK6C,aAAL,CAAmB0B,eAAnB,CAAjB;AACAvB,eAAW+B,MAAX,CAAkBvF,aAAajB,QAAb,EAAuBW,0BAAvB,CAAlB,EACkB;AAAC8F,YAAM;AAAP,KADlB,EACgCjD,QADhC;AAED,GAJD,CAIE,OAAOP,GAAP,EAAY;AACZyC,UAAMJ,SAAN;AACA,UAAMrC,GAAN;AACD;AACF,CArCD,C,CAuCA;AACA;;;AACA3B,gBAAgB7B,SAAhB,CAA0BiH,QAA1B,GAAqC,UAAUnC,cAAV,EAA0BoC,QAA1B,EAAoC;AACvE,MAAIC,aAAa;AAACnC,gBAAYF;AAAb,GAAjB,CADuE,CAEvE;AACA;AACA;AACA;;AACA,MAAIsC,cAAcT,gBAAgBU,qBAAhB,CAAsCH,QAAtC,CAAlB;;AACA,MAAIE,WAAJ,EAAiB;AACf7H,MAAEK,IAAF,CAAOwH,WAAP,EAAoB,UAAUP,EAAV,EAAc;AAChCvD,aAAO4C,OAAP,CAAe3G,EAAE+H,MAAF,CAAS;AAACT,YAAIA;AAAL,OAAT,EAAmBM,UAAnB,CAAf;AACD,KAFD;AAGD,GAJD,MAIO;AACL7D,WAAO4C,OAAP,CAAeiB,UAAf;AACD;AACF,CAdD;;AAgBAtF,gBAAgB7B,SAAhB,CAA0BuH,OAA1B,GAAoC,UAAUhB,eAAV,EAA2BW,QAA3B,EACUnD,QADV,EACoB;AACtD,MAAI/B,OAAO,IAAX;;AAEA,MAAIuE,oBAAoB,mCAAxB,EAA6D;AAC3D,QAAIE,IAAI,IAAIhC,KAAJ,CAAU,cAAV,CAAR;AACAgC,MAAEC,eAAF,GAAoB,IAApB;;AACA,QAAI3C,QAAJ,EAAc;AACZ,aAAOA,SAAS0C,CAAT,CAAP;AACD,KAFD,MAEO;AACL,YAAMA,CAAN;AACD;AACF;;AAED,MAAIR,QAAQjE,KAAKuD,gBAAL,EAAZ;;AACA,MAAIW,UAAU,YAAY;AACxBlE,SAAKiF,QAAL,CAAcV,eAAd,EAA+BW,QAA/B;AACD,GAFD;;AAGAnD,aAAWsC,wBAAwBL,cAAcC,KAAd,EAAqBC,OAArB,EAA8BnC,QAA9B,CAAxB,CAAX;;AAEA,MAAI;AACF,QAAIiB,aAAahD,KAAK6C,aAAL,CAAmB0B,eAAnB,CAAjB;;AACA,QAAIiB,kBAAkB,UAAShE,GAAT,EAAciE,YAAd,EAA4B;AAChD1D,eAASP,GAAT,EAAckE,gBAAgBD,YAAhB,EAA8BE,cAA5C;AACD,KAFD;;AAGA3C,eAAW4C,MAAX,CAAkBpG,aAAa0F,QAAb,EAAuBhG,0BAAvB,CAAlB,EACmB;AAAC8F,YAAM;AAAP,KADnB,EACiCQ,eADjC;AAED,GAPD,CAOE,OAAOhE,GAAP,EAAY;AACZyC,UAAMJ,SAAN;AACA,UAAMrC,GAAN;AACD;AACF,CA/BD;;AAiCA3B,gBAAgB7B,SAAhB,CAA0B6H,eAA1B,GAA4C,UAAU/C,cAAV,EAA0BgD,EAA1B,EAA8B;AACxE,MAAI9F,OAAO,IAAX;;AAEA,MAAIiE,QAAQjE,KAAKuD,gBAAL,EAAZ;;AACA,MAAIW,UAAU,YAAY;AACxB5C,WAAO4C,OAAP,CAAe;AAAClB,kBAAYF,cAAb;AAA6B+B,UAAI,IAAjC;AACCkB,sBAAgB;AADjB,KAAf;AAED,GAHD;;AAIAD,OAAKzB,wBAAwBL,cAAcC,KAAd,EAAqBC,OAArB,EAA8B4B,EAA9B,CAAxB,CAAL;;AAEA,MAAI;AACF,QAAI9C,aAAahD,KAAK6C,aAAL,CAAmBC,cAAnB,CAAjB;AACAE,eAAWgD,IAAX,CAAgBF,EAAhB;AACD,GAHD,CAGE,OAAOrB,CAAP,EAAU;AACVR,UAAMJ,SAAN;AACA,UAAMY,CAAN;AACD;AACF,CAjBD,C,CAmBA;AACA;;;AACA5E,gBAAgB7B,SAAhB,CAA0BiI,aAA1B,GAA0C,UAAUH,EAAV,EAAc;AACtD,MAAI9F,OAAO,IAAX;;AAEA,MAAIiE,QAAQjE,KAAKuD,gBAAL,EAAZ;;AACA,MAAIW,UAAU,YAAY;AACxB5C,WAAO4C,OAAP,CAAe;AAAEgC,oBAAc;AAAhB,KAAf;AACD,GAFD;;AAGAJ,OAAKzB,wBAAwBL,cAAcC,KAAd,EAAqBC,OAArB,EAA8B4B,EAA9B,CAAxB,CAAL;;AAEA,MAAI;AACF9F,SAAKgB,EAAL,CAAQkF,YAAR,CAAqBJ,EAArB;AACD,GAFD,CAEE,OAAOrB,CAAP,EAAU;AACVR,UAAMJ,SAAN;AACA,UAAMY,CAAN;AACD;AACF,CAfD;;AAiBA5E,gBAAgB7B,SAAhB,CAA0BmI,OAA1B,GAAoC,UAAU5B,eAAV,EAA2BW,QAA3B,EAAqCkB,GAArC,EACUrG,OADV,EACmBgC,QADnB,EAC6B;AAC/D,MAAI/B,OAAO,IAAX;;AAEA,MAAI,CAAE+B,QAAF,IAAchC,mBAAmBsG,QAArC,EAA+C;AAC7CtE,eAAWhC,OAAX;AACAA,cAAU,IAAV;AACD;;AAED,MAAIwE,oBAAoB,mCAAxB,EAA6D;AAC3D,QAAIE,IAAI,IAAIhC,KAAJ,CAAU,cAAV,CAAR;AACAgC,MAAEC,eAAF,GAAoB,IAApB;;AACA,QAAI3C,QAAJ,EAAc;AACZ,aAAOA,SAAS0C,CAAT,CAAP;AACD,KAFD,MAEO;AACL,YAAMA,CAAN;AACD;AACF,GAhB8D,CAkB/D;AACA;AACA;AACA;AACA;;;AACA,MAAI,CAAC2B,GAAD,IAAQ,OAAOA,GAAP,KAAe,QAA3B,EACE,MAAM,IAAI3D,KAAJ,CAAU,+CAAV,CAAN;;AAEF,MAAI,EAAEkC,gBAAgBC,cAAhB,CAA+BwB,GAA/B,KACA,CAACrH,MAAMO,aAAN,CAAoB8G,GAApB,CADH,CAAJ,EACkC;AAChC,UAAM,IAAI3D,KAAJ,CACJ,kDACE,uBAFE,CAAN;AAGD;;AAED,MAAI,CAAC1C,OAAL,EAAcA,UAAU,EAAV;;AAEd,MAAIkE,QAAQjE,KAAKuD,gBAAL,EAAZ;;AACA,MAAIW,UAAU,YAAY;AACxBlE,SAAKiF,QAAL,CAAcV,eAAd,EAA+BW,QAA/B;AACD,GAFD;;AAGAnD,aAAWiC,cAAcC,KAAd,EAAqBC,OAArB,EAA8BnC,QAA9B,CAAX;;AACA,MAAI;AACF,QAAIiB,aAAahD,KAAK6C,aAAL,CAAmB0B,eAAnB,CAAjB;AACA,QAAI+B,YAAY;AAACtB,YAAM;AAAP,KAAhB,CAFE,CAGF;;AACA,QAAIjF,QAAQwG,MAAZ,EAAoBD,UAAUC,MAAV,GAAmB,IAAnB;AACpB,QAAIxG,QAAQyG,KAAZ,EAAmBF,UAAUE,KAAV,GAAkB,IAAlB,CALjB,CAMF;AACA;AACA;;AACA,QAAIzG,QAAQ0G,UAAZ,EAAwBH,UAAUG,UAAV,GAAuB,IAAvB;AAExB,QAAIC,gBAAgBlH,aAAa0F,QAAb,EAAuBhG,0BAAvB,CAApB;AACA,QAAIyH,WAAWnH,aAAa4G,GAAb,EAAkBlH,0BAAlB,CAAf;;AAEA,QAAI0H,WAAWjC,gBAAgBkC,kBAAhB,CAAmCF,QAAnC,CAAf;;AAEA,QAAI5G,QAAQ+G,cAAR,IAA0B,CAACF,QAA/B,EAAyC;AACvC,UAAIpF,MAAM,IAAIiB,KAAJ,CAAU,+CAAV,CAAV;;AACA,UAAIV,QAAJ,EAAc;AACZ,eAAOA,SAASP,GAAT,CAAP;AACD,OAFD,MAEO;AACL,cAAMA,GAAN;AACD;AACF,KAvBC,CAyBF;AACA;AACA;AACA;AAEA;AACA;;;AACA,QAAIuF,OAAJ;;AACA,QAAIhH,QAAQwG,MAAZ,EAAoB;AAClB,UAAI;AACF,YAAIS,SAASrC,gBAAgBsC,qBAAhB,CAAsC/B,QAAtC,EAAgDkB,GAAhD,CAAb;;AACAW,kBAAUC,OAAOlC,GAAjB;AACD,OAHD,CAGE,OAAOtD,GAAP,EAAY;AACZ,YAAIO,QAAJ,EAAc;AACZ,iBAAOA,SAASP,GAAT,CAAP;AACD,SAFD,MAEO;AACL,gBAAMA,GAAN;AACD;AACF;AACF;;AAED,QAAIzB,QAAQwG,MAAR,IACA,CAAEK,QADF,IAEA,CAAEG,OAFF,IAGAhH,QAAQmH,UAHR,IAIA,EAAGnH,QAAQmH,UAAR,YAA8BtI,MAAMD,QAApC,IACAoB,QAAQoH,WADX,CAJJ,EAK6B;AAC3B;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEAC,mCACEpE,UADF,EACc0D,aADd,EAC6BC,QAD7B,EACuC5G,OADvC,EAEE;AACA;AACA;AACA,gBAAUsH,KAAV,EAAiBlD,MAAjB,EAAyB;AACvB;AACA;AACA;AACA,YAAIA,UAAU,CAAEpE,QAAQuH,aAAxB,EAAuC;AACrCvF,mBAASsF,KAAT,EAAgBlD,OAAOwB,cAAvB;AACD,SAFD,MAEO;AACL5D,mBAASsF,KAAT,EAAgBlD,MAAhB;AACD;AACF,OAdH;AAgBD,KAhCD,MAgCO;AAEL,UAAIpE,QAAQwG,MAAR,IAAkB,CAACQ,OAAnB,IAA8BhH,QAAQmH,UAAtC,IAAoDN,QAAxD,EAAkE;AAChE,YAAI,CAACD,SAASY,cAAT,CAAwB,cAAxB,CAAL,EAA8C;AAC5CZ,mBAASa,YAAT,GAAwB,EAAxB;AACD;;AACDT,kBAAUhH,QAAQmH,UAAlB;AACA7G,eAAOC,MAAP,CAAcqG,SAASa,YAAvB,EAAqChI,aAAa;AAACsF,eAAK/E,QAAQmH;AAAd,SAAb,EAAwChI,0BAAxC,CAArC;AACD;;AAED8D,iBAAWyE,MAAX,CACEf,aADF,EACiBC,QADjB,EAC2BL,SAD3B,EAEEjC,wBAAwB,UAAU7C,GAAV,EAAe2C,MAAf,EAAuB;AAC7C,YAAI,CAAE3C,GAAN,EAAW;AACT,cAAIkG,eAAehC,gBAAgBvB,MAAhB,CAAnB;;AACA,cAAIuD,gBAAgB3H,QAAQuH,aAA5B,EAA2C;AACzC;AACA;AACA;AACA,gBAAIvH,QAAQwG,MAAR,IAAkBmB,aAAaR,UAAnC,EAA+C;AAC7C,kBAAIH,OAAJ,EAAa;AACXW,6BAAaR,UAAb,GAA0BH,OAA1B;AACD,eAFD,MAEO,IAAIW,aAAaR,UAAb,YAAmC3K,QAAQoC,QAA/C,EAAyD;AAC9D+I,6BAAaR,UAAb,GAA0B,IAAItI,MAAMD,QAAV,CAAmB+I,aAAaR,UAAb,CAAwBrI,WAAxB,EAAnB,CAA1B;AACD;AACF;;AAEDkD,qBAASP,GAAT,EAAckG,YAAd;AACD,WAbD,MAaO;AACL3F,qBAASP,GAAT,EAAckG,aAAa/B,cAA3B;AACD;AACF,SAlBD,MAkBO;AACL5D,mBAASP,GAAT;AACD;AACF,OAtBD,CAFF;AAyBD;AACF,GAlHD,CAkHE,OAAOiD,CAAP,EAAU;AACVR,UAAMJ,SAAN;AACA,UAAMY,CAAN;AACD;AACF,CA/JD;;AAiKA,IAAIiB,kBAAkB,UAAUD,YAAV,EAAwB;AAC5C,MAAIiC,eAAe;AAAE/B,oBAAgB;AAAlB,GAAnB;;AACA,MAAIF,YAAJ,EAAkB;AAChB,QAAIkC,cAAclC,aAAatB,MAA/B,CADgB,CAGhB;AACA;AACA;;AACA,QAAIwD,YAAYC,QAAhB,EAA0B;AACxBF,mBAAa/B,cAAb,IAA+BgC,YAAYC,QAAZ,CAAqBC,MAApD;;AAEA,UAAIF,YAAYC,QAAZ,CAAqBC,MAArB,IAA+B,CAAnC,EAAsC;AACpCH,qBAAaR,UAAb,GAA0BS,YAAYC,QAAZ,CAAqB,CAArB,EAAwB9C,GAAlD;AACD;AACF,KAND,MAMO;AACL4C,mBAAa/B,cAAb,GAA8BgC,YAAYG,CAA1C;AACD;AACF;;AAED,SAAOJ,YAAP;AACD,CApBD;;AAuBA,IAAIK,uBAAuB,CAA3B,C,CAEA;;AACAlI,gBAAgBmI,sBAAhB,GAAyC,UAAUxG,GAAV,EAAe;AAEtD;AACA;AACA;AACA;AACA,MAAI6F,QAAQ7F,IAAIyG,MAAJ,IAAczG,IAAIA,GAA9B,CANsD,CAQtD;AACA;AACA;;AACA,MAAI6F,MAAMa,OAAN,CAAc,iCAAd,MAAqD,CAArD,IACCb,MAAMa,OAAN,CAAc,mEAAd,MAAuF,CAAC,CAD7F,EACgG;AAC9F,WAAO,IAAP;AACD;;AAED,SAAO,KAAP;AACD,CAjBD;;AAmBA,IAAId,+BAA+B,UAAUpE,UAAV,EAAsBkC,QAAtB,EAAgCkB,GAAhC,EACUrG,OADV,EACmBgC,QADnB,EAC6B;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,MAAImF,aAAanH,QAAQmH,UAAzB,CAd8D,CAczB;;AACrC,MAAIiB,qBAAqB;AACvBnD,UAAM,IADiB;AAEvBwB,WAAOzG,QAAQyG;AAFQ,GAAzB;AAIA,MAAI4B,qBAAqB;AACvBpD,UAAM,IADiB;AAEvBuB,YAAQ;AAFe,GAAzB;AAKA,MAAI8B,oBAAoBhI,OAAOC,MAAP,CACtBd,aAAa;AAACsF,SAAKoC;AAAN,GAAb,EAAgChI,0BAAhC,CADsB,EAEtBkH,GAFsB,CAAxB;AAIA,MAAIkC,QAAQP,oBAAZ;;AAEA,MAAIQ,WAAW,YAAY;AACzBD;;AACA,QAAI,CAAEA,KAAN,EAAa;AACXvG,eAAS,IAAIU,KAAJ,CAAU,yBAAyBsF,oBAAzB,GAAgD,SAA1D,CAAT;AACD,KAFD,MAEO;AACL/E,iBAAWyE,MAAX,CAAkBvC,QAAlB,EAA4BkB,GAA5B,EAAiC+B,kBAAjC,EACkB9D,wBAAwB,UAAU7C,GAAV,EAAe2C,MAAf,EAAuB;AAC7C,YAAI3C,GAAJ,EAAS;AACPO,mBAASP,GAAT;AACD,SAFD,MAEO,IAAI2C,UAAUA,OAAOA,MAAP,CAAc2D,CAAd,IAAmB,CAAjC,EAAoC;AACzC/F,mBAAS,IAAT,EAAe;AACb4D,4BAAgBxB,OAAOA,MAAP,CAAc2D;AADjB,WAAf;AAGD,SAJM,MAIA;AACLU;AACD;AACF,OAVD,CADlB;AAYD;AACF,GAlBD;;AAoBA,MAAIA,sBAAsB,YAAY;AACpCxF,eAAWyE,MAAX,CAAkBvC,QAAlB,EAA4BmD,iBAA5B,EAA+CD,kBAA/C,EACkB/D,wBAAwB,UAAU7C,GAAV,EAAe2C,MAAf,EAAuB;AAC7C,UAAI3C,GAAJ,EAAS;AACP;AACA;AACA;AACA,YAAI3B,gBAAgBmI,sBAAhB,CAAuCxG,GAAvC,CAAJ,EAAiD;AAC/C+G;AACD,SAFD,MAEO;AACLxG,mBAASP,GAAT;AACD;AACF,OATD,MASO;AACLO,iBAAS,IAAT,EAAe;AACb4D,0BAAgBxB,OAAOA,MAAP,CAAcyD,QAAd,CAAuBC,MAD1B;AAEbX,sBAAYA;AAFC,SAAf;AAID;AACF,KAhBD,CADlB;AAkBD,GAnBD;;AAqBAqB;AACD,CAzED;;AA2EAhL,EAAEK,IAAF,CAAO,CAAC,QAAD,EAAW,QAAX,EAAqB,QAArB,EAA+B,gBAA/B,EAAiD,cAAjD,CAAP,EAAyE,UAAU6K,MAAV,EAAkB;AACzF5I,kBAAgB7B,SAAhB,CAA0ByK,MAA1B,IAAoC;AAAU;AAAiB;AAC7D,QAAIzI,OAAO,IAAX;AACA,WAAOsB,OAAOoH,SAAP,CAAiB1I,KAAK,MAAMyI,MAAX,CAAjB,EAAqCE,KAArC,CAA2C3I,IAA3C,EAAiD4I,SAAjD,CAAP;AACD,GAHD;AAID,CALD,E,CAOA;AACA;AACA;;;AACA/I,gBAAgB7B,SAAhB,CAA0BuI,MAA1B,GAAmC,UAAUzD,cAAV,EAA0BoC,QAA1B,EAAoCkB,GAApC,EACUrG,OADV,EACmBgC,QADnB,EAC6B;AAC9D,MAAI/B,OAAO,IAAX;;AACA,MAAI,OAAOD,OAAP,KAAmB,UAAnB,IAAiC,CAAEgC,QAAvC,EAAiD;AAC/CA,eAAWhC,OAAX;AACAA,cAAU,EAAV;AACD;;AAED,SAAOC,KAAKyH,MAAL,CAAY3E,cAAZ,EAA4BoC,QAA5B,EAAsCkB,GAAtC,EACY7I,EAAE+H,MAAF,CAAS,EAAT,EAAavF,OAAb,EAAsB;AACpBwG,YAAQ,IADY;AAEpBe,mBAAe;AAFK,GAAtB,CADZ,EAIgBvF,QAJhB,CAAP;AAKD,CAbD;;AAeAlC,gBAAgB7B,SAAhB,CAA0B6K,IAA1B,GAAiC,UAAU/F,cAAV,EAA0BoC,QAA1B,EAAoCnF,OAApC,EAA6C;AAC5E,MAAIC,OAAO,IAAX;AAEA,MAAI4I,UAAUf,MAAV,KAAqB,CAAzB,EACE3C,WAAW,EAAX;AAEF,SAAO,IAAI4D,MAAJ,CACL9I,IADK,EACC,IAAI+I,iBAAJ,CAAsBjG,cAAtB,EAAsCoC,QAAtC,EAAgDnF,OAAhD,CADD,CAAP;AAED,CARD;;AAUAF,gBAAgB7B,SAAhB,CAA0BgL,OAA1B,GAAoC,UAAUzE,eAAV,EAA2BW,QAA3B,EACUnF,OADV,EACmB;AACrD,MAAIC,OAAO,IAAX;AACA,MAAI4I,UAAUf,MAAV,KAAqB,CAAzB,EACE3C,WAAW,EAAX;AAEFnF,YAAUA,WAAW,EAArB;AACAA,UAAQkJ,KAAR,GAAgB,CAAhB;AACA,SAAOjJ,KAAK6I,IAAL,CAAUtE,eAAV,EAA2BW,QAA3B,EAAqCnF,OAArC,EAA8CmJ,KAA9C,GAAsD,CAAtD,CAAP;AACD,CATD,C,CAWA;AACA;;;AACArJ,gBAAgB7B,SAAhB,CAA0BmL,YAA1B,GAAyC,UAAUrG,cAAV,EAA0BsG,KAA1B,EACUrJ,OADV,EACmB;AAC1D,MAAIC,OAAO,IAAX,CAD0D,CAG1D;AACA;;AACA,MAAIgD,aAAahD,KAAK6C,aAAL,CAAmBC,cAAnB,CAAjB;AACA,MAAIC,SAAS,IAAItG,MAAJ,EAAb;AACA,MAAI4M,YAAYrG,WAAWsG,WAAX,CAAuBF,KAAvB,EAA8BrJ,OAA9B,EAAuCgD,OAAOd,QAAP,EAAvC,CAAhB;AACAc,SAAOb,IAAP;AACD,CAVD;;AAWArC,gBAAgB7B,SAAhB,CAA0BuL,UAA1B,GAAuC,UAAUzG,cAAV,EAA0BsG,KAA1B,EAAiC;AACtE,MAAIpJ,OAAO,IAAX,CADsE,CAGtE;AACA;;AACA,MAAIgD,aAAahD,KAAK6C,aAAL,CAAmBC,cAAnB,CAAjB;AACA,MAAIC,SAAS,IAAItG,MAAJ,EAAb;AACA,MAAI4M,YAAYrG,WAAWwG,SAAX,CAAqBJ,KAArB,EAA4BrG,OAAOd,QAAP,EAA5B,CAAhB;AACAc,SAAOb,IAAP;AACD,CATD,C,CAWA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA6G,oBAAoB,UAAUjG,cAAV,EAA0BoC,QAA1B,EAAoCnF,OAApC,EAA6C;AAC/D,MAAIC,OAAO,IAAX;AACAA,OAAK8C,cAAL,GAAsBA,cAAtB;AACA9C,OAAKkF,QAAL,GAAgBtG,MAAM6K,UAAN,CAAiBC,gBAAjB,CAAkCxE,QAAlC,CAAhB;AACAlF,OAAKD,OAAL,GAAeA,WAAW,EAA1B;AACD,CALD;;AAOA+I,SAAS,UAAUa,KAAV,EAAiBC,iBAAjB,EAAoC;AAC3C,MAAI5J,OAAO,IAAX;AAEAA,OAAK6J,MAAL,GAAcF,KAAd;AACA3J,OAAK8J,kBAAL,GAA0BF,iBAA1B;AACA5J,OAAK+J,kBAAL,GAA0B,IAA1B;AACD,CAND;;AAQAxM,EAAEK,IAAF,CAAO,CAAC,SAAD,EAAY,KAAZ,EAAmB,OAAnB,EAA4B,OAA5B,EAAqCoM,OAAOC,QAA5C,CAAP,EAA8D,UAAUxB,MAAV,EAAkB;AAC9EK,SAAO9K,SAAP,CAAiByK,MAAjB,IAA2B,YAAY;AACrC,QAAIzI,OAAO,IAAX,CADqC,CAGrC;;AACA,QAAIA,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCmK,QAApC,EACE,MAAM,IAAIzH,KAAJ,CAAU,iBAAiBgG,MAAjB,GAA0B,uBAApC,CAAN;;AAEF,QAAI,CAACzI,KAAK+J,kBAAV,EAA8B;AAC5B/J,WAAK+J,kBAAL,GAA0B/J,KAAK6J,MAAL,CAAYM,wBAAZ,CACxBnK,KAAK8J,kBADmB,EACC;AACvB;AACA;AACAM,0BAAkBpK,IAHK;AAIvBqK,sBAAc;AAJS,OADD,CAA1B;AAOD;;AAED,WAAOrK,KAAK+J,kBAAL,CAAwBtB,MAAxB,EAAgCE,KAAhC,CACL3I,KAAK+J,kBADA,EACoBnB,SADpB,CAAP;AAED,GAnBD;AAoBD,CArBD,E,CAuBA;AACA;AACA;AACA;;;AACAE,OAAO9K,SAAP,CAAiBsM,MAAjB,GAA0B,YAAY,CACrC,CADD;;AAGAxB,OAAO9K,SAAP,CAAiBuM,YAAjB,GAAgC,YAAY;AAC1C,SAAO,KAAKT,kBAAL,CAAwB/J,OAAxB,CAAgCyK,SAAvC;AACD,CAFD,C,CAIA;AACA;AACA;;;AAEA1B,OAAO9K,SAAP,CAAiByM,cAAjB,GAAkC,UAAUC,GAAV,EAAe;AAC/C,MAAI1K,OAAO,IAAX;AACA,MAAIgD,aAAahD,KAAK8J,kBAAL,CAAwBhH,cAAzC;AACA,SAAOlE,MAAM6K,UAAN,CAAiBgB,cAAjB,CAAgCzK,IAAhC,EAAsC0K,GAAtC,EAA2C1H,UAA3C,CAAP;AACD,CAJD,C,CAMA;AACA;AACA;;;AACA8F,OAAO9K,SAAP,CAAiB2M,kBAAjB,GAAsC,YAAY;AAChD,MAAI3K,OAAO,IAAX;AACA,SAAOA,KAAK8J,kBAAL,CAAwBhH,cAA/B;AACD,CAHD;;AAKAgG,OAAO9K,SAAP,CAAiB4M,OAAjB,GAA2B,UAAUC,SAAV,EAAqB;AAC9C,MAAI7K,OAAO,IAAX;AACA,SAAO2E,gBAAgBmG,0BAAhB,CAA2C9K,IAA3C,EAAiD6K,SAAjD,CAAP;AACD,CAHD;;AAKA/B,OAAO9K,SAAP,CAAiB+M,cAAjB,GAAkC,UAAUF,SAAV,EAAqB;AACrD,MAAI7K,OAAO,IAAX;AACA,MAAIgL,UAAU,CACZ,SADY,EAEZ,OAFY,EAGZ,WAHY,EAIZ,SAJY,EAKZ,WALY,EAMZ,SANY,EAOZ,SAPY,CAAd;;AASA,MAAIC,UAAUtG,gBAAgBuG,kCAAhB,CAAmDL,SAAnD,CAAd,CAXqD,CAarD;;;AACA,MAAIM,gBAAgB,kCAApB;AACAH,UAAQI,OAAR,CAAgB,UAAU3C,MAAV,EAAkB;AAChC,QAAIoC,UAAUpC,MAAV,KAAqB,OAAOoC,UAAUpC,MAAV,CAAP,IAA4B,UAArD,EAAiE;AAC/DoC,gBAAUpC,MAAV,IAAoBnH,OAAOC,eAAP,CAAuBsJ,UAAUpC,MAAV,CAAvB,EAA0CA,SAAS0C,aAAnD,CAApB;AACD;AACF,GAJD;AAMA,SAAOnL,KAAK6J,MAAL,CAAYwB,eAAZ,CACLrL,KAAK8J,kBADA,EACoBmB,OADpB,EAC6BJ,SAD7B,CAAP;AAED,CAvBD;;AAyBAhL,gBAAgB7B,SAAhB,CAA0BmM,wBAA1B,GAAqD,UACjDP,iBADiD,EAC9B7J,OAD8B,EACrB;AAC9B,MAAIC,OAAO,IAAX;AACAD,YAAUxC,EAAE+N,IAAF,CAAOvL,WAAW,EAAlB,EAAsB,kBAAtB,EAA0C,cAA1C,CAAV;AAEA,MAAIiD,aAAahD,KAAK6C,aAAL,CAAmB+G,kBAAkB9G,cAArC,CAAjB;AACA,MAAIyI,gBAAgB3B,kBAAkB7J,OAAtC;AACA,MAAIK,eAAe;AACjBoL,UAAMD,cAAcC,IADH;AAEjBvC,WAAOsC,cAActC,KAFJ;AAGjBwC,UAAMF,cAAcE;AAHH,GAAnB,CAN8B,CAY9B;;AACA,MAAIF,cAAcrB,QAAlB,EAA4B;AAC1B;AACA9J,iBAAa8J,QAAb,GAAwB,IAAxB,CAF0B,CAG1B;AACA;;AACA9J,iBAAasL,SAAb,GAAyB,IAAzB,CAL0B,CAM1B;AACA;;AACAtL,iBAAauL,eAAb,GAA+B,CAAC,CAAhC,CAR0B,CAS1B;AACA;AACA;AACA;AACA;;AACA,QAAI/B,kBAAkB9G,cAAlB,KAAqC8I,gBAArC,IACAhC,kBAAkB1E,QAAlB,CAA2B2G,EAD/B,EACmC;AACjCzL,mBAAa0L,WAAb,GAA2B,IAA3B;AACD;AACF;;AAED,MAAIC,WAAW/I,WAAW6F,IAAX,CACbrJ,aAAaoK,kBAAkB1E,QAA/B,EAAyChG,0BAAzC,CADa,EAEbqM,cAAcS,MAFD,EAES5L,YAFT,CAAf;;AAIA,MAAI,OAAOmL,cAAcU,SAArB,KAAmC,WAAvC,EAAoD;AAClDF,eAAWA,SAASG,SAAT,CAAmBX,cAAcU,SAAjC,CAAX;AACD;;AACD,MAAI,OAAOV,cAAcY,IAArB,KAA8B,WAAlC,EAA+C;AAC7CJ,eAAWA,SAASI,IAAT,CAAcZ,cAAcY,IAA5B,CAAX;AACD;;AAED,SAAO,IAAIC,iBAAJ,CAAsBL,QAAtB,EAAgCnC,iBAAhC,EAAmD7J,OAAnD,CAAP;AACD,CA9CD;;AAgDA,IAAIqM,oBAAoB,UAAUL,QAAV,EAAoBnC,iBAApB,EAAuC7J,OAAvC,EAAgD;AACtE,MAAIC,OAAO,IAAX;AACAD,YAAUxC,EAAE+N,IAAF,CAAOvL,WAAW,EAAlB,EAAsB,kBAAtB,EAA0C,cAA1C,CAAV;AAEAC,OAAKqM,SAAL,GAAiBN,QAAjB;AACA/L,OAAK8J,kBAAL,GAA0BF,iBAA1B,CALsE,CAMtE;AACA;;AACA5J,OAAKsM,iBAAL,GAAyBvM,QAAQqK,gBAAR,IAA4BpK,IAArD;;AACA,MAAID,QAAQsK,YAAR,IAAwBT,kBAAkB7J,OAAlB,CAA0ByK,SAAtD,EAAiE;AAC/DxK,SAAKuM,UAAL,GAAkB5H,gBAAgB6H,aAAhB,CAChB5C,kBAAkB7J,OAAlB,CAA0ByK,SADV,CAAlB;AAED,GAHD,MAGO;AACLxK,SAAKuM,UAAL,GAAkB,IAAlB;AACD,GAdqE,CAgBtE;AACA;AACA;;;AACAvM,OAAKyM,sBAAL,GAA8BhQ,OAAOmG,IAAP,CAC5BmJ,SAASW,UAAT,CAAoBhP,IAApB,CAAyBqO,QAAzB,CAD4B,EACQ,CADR,CAA9B;AAEA/L,OAAK2M,iBAAL,GAAyBlQ,OAAOmG,IAAP,CAAYmJ,SAASa,KAAT,CAAelP,IAAf,CAAoBqO,QAApB,CAAZ,CAAzB;AACA/L,OAAK6M,WAAL,GAAmB,IAAIlI,gBAAgBmI,MAApB,EAAnB;AACD,CAvBD;;AAyBAvP,EAAE+H,MAAF,CAAS8G,kBAAkBpO,SAA3B,EAAsC;AACpC+O,eAAa,YAAY;AACvB,QAAI/M,OAAO,IAAX;;AAEA,WAAO,IAAP,EAAa;AACX,UAAI8B,MAAM9B,KAAKyM,sBAAL,GAA8BvK,IAA9B,EAAV;;AAEA,UAAI,CAACJ,GAAL,EAAU,OAAO,IAAP;AACVA,YAAMtC,aAAasC,GAAb,EAAkBxD,0BAAlB,CAAN;;AAEA,UAAI,CAAC0B,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCmK,QAAjC,IAA6C3M,EAAEuD,GAAF,CAAMgB,GAAN,EAAW,KAAX,CAAjD,EAAoE;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,YAAI9B,KAAK6M,WAAL,CAAiB/L,GAAjB,CAAqBgB,IAAIgD,GAAzB,CAAJ,EAAmC;;AACnC9E,aAAK6M,WAAL,CAAiBG,GAAjB,CAAqBlL,IAAIgD,GAAzB,EAA8B,IAA9B;AACD;;AAED,UAAI9E,KAAKuM,UAAT,EACEzK,MAAM9B,KAAKuM,UAAL,CAAgBzK,GAAhB,CAAN;AAEF,aAAOA,GAAP;AACD;AACF,GA1BmC;AA4BpCsJ,WAAS,UAAUrJ,QAAV,EAAoBkL,OAApB,EAA6B;AACpC,QAAIjN,OAAO,IAAX,CADoC,CAGpC;;AACAA,SAAKkN,OAAL,GAJoC,CAMpC;AACA;AACA;;;AACA,QAAI9D,QAAQ,CAAZ;;AACA,WAAO,IAAP,EAAa;AACX,UAAItH,MAAM9B,KAAK+M,WAAL,EAAV;;AACA,UAAI,CAACjL,GAAL,EAAU;AACVC,eAASoL,IAAT,CAAcF,OAAd,EAAuBnL,GAAvB,EAA4BsH,OAA5B,EAAqCpJ,KAAKsM,iBAA1C;AACD;AACF,GA3CmC;AA6CpC;AACA7O,OAAK,UAAUsE,QAAV,EAAoBkL,OAApB,EAA6B;AAChC,QAAIjN,OAAO,IAAX;AACA,QAAIoN,MAAM,EAAV;AACApN,SAAKoL,OAAL,CAAa,UAAUtJ,GAAV,EAAesH,KAAf,EAAsB;AACjCgE,UAAIC,IAAJ,CAAStL,SAASoL,IAAT,CAAcF,OAAd,EAAuBnL,GAAvB,EAA4BsH,KAA5B,EAAmCpJ,KAAKsM,iBAAxC,CAAT;AACD,KAFD;AAGA,WAAOc,GAAP;AACD,GArDmC;AAuDpCF,WAAS,YAAY;AACnB,QAAIlN,OAAO,IAAX,CADmB,CAGnB;;AACAA,SAAKqM,SAAL,CAAe/B,MAAf;;AAEAtK,SAAK6M,WAAL,GAAmB,IAAIlI,gBAAgBmI,MAApB,EAAnB;AACD,GA9DmC;AAgEpC;AACAtK,SAAO,YAAY;AACjB,QAAIxC,OAAO,IAAX;;AAEAA,SAAKqM,SAAL,CAAe7J,KAAf;AACD,GArEmC;AAuEpC0G,SAAO,YAAY;AACjB,QAAIlJ,OAAO,IAAX;AACA,WAAOA,KAAKvC,GAAL,CAASF,EAAE+P,QAAX,CAAP;AACD,GA1EmC;AA4EpCV,SAAO,UAAUW,iBAAiB,KAA3B,EAAkC;AACvC,QAAIvN,OAAO,IAAX;AACA,WAAOA,KAAK2M,iBAAL,CAAuBY,cAAvB,EAAuCrL,IAAvC,EAAP;AACD,GA/EmC;AAiFpC;AACAsL,iBAAe,UAAUvC,OAAV,EAAmB;AAChC,QAAIjL,OAAO,IAAX;;AACA,QAAIiL,OAAJ,EAAa;AACX,aAAOjL,KAAKkJ,KAAL,EAAP;AACD,KAFD,MAEO;AACL,UAAIuE,UAAU,IAAI9I,gBAAgBmI,MAApB,EAAd;AACA9M,WAAKoL,OAAL,CAAa,UAAUtJ,GAAV,EAAe;AAC1B2L,gBAAQT,GAAR,CAAYlL,IAAIgD,GAAhB,EAAqBhD,GAArB;AACD,OAFD;AAGA,aAAO2L,OAAP;AACD;AACF;AA7FmC,CAAtC;;AAgGArB,kBAAkBpO,SAAlB,CAA4BgM,OAAOC,QAAnC,IAA+C,YAAY;AACzD,MAAIjK,OAAO,IAAX,CADyD,CAGzD;;AACAA,OAAKkN,OAAL;;AAEA,SAAO;AACLQ,WAAO;AACL,YAAM5L,MAAM9B,KAAK+M,WAAL,EAAZ;;AACA,aAAOjL,MAAM;AACXjE,eAAOiE;AADI,OAAN,GAEH;AACF6L,cAAM;AADJ,OAFJ;AAKD;;AARI,GAAP;AAUD,CAhBD;;AAkBA9N,gBAAgB7B,SAAhB,CAA0B4P,IAA1B,GAAiC,UAAUhE,iBAAV,EAA6BiE,WAA7B,EAA0C;AACzE,MAAI7N,OAAO,IAAX;AACA,MAAI,CAAC4J,kBAAkB7J,OAAlB,CAA0BmK,QAA/B,EACE,MAAM,IAAIzH,KAAJ,CAAU,iCAAV,CAAN;;AAEF,MAAIqL,SAAS9N,KAAKmK,wBAAL,CAA8BP,iBAA9B,CAAb;;AAEA,MAAImE,UAAU,KAAd;AACA,MAAIC,MAAJ;;AACA,MAAIC,OAAO,YAAY;AACrB,QAAInM,MAAM,IAAV;;AACA,WAAO,IAAP,EAAa;AACX,UAAIiM,OAAJ,EACE;;AACF,UAAI;AACFjM,cAAMgM,OAAOf,WAAP,EAAN;AACD,OAFD,CAEE,OAAOvL,GAAP,EAAY;AACZ;AACA;AACA;AACAM,cAAM,IAAN;AACD,OAVU,CAWX;AACA;;;AACA,UAAIiM,OAAJ,EACE;;AACF,UAAIjM,GAAJ,EAAS;AACP;AACA;AACA;AACA;AACAkM,iBAASlM,IAAI+J,EAAb;AACAgC,oBAAY/L,GAAZ;AACD,OAPD,MAOO;AACL,YAAIoM,cAAc3Q,EAAEU,KAAF,CAAQ2L,kBAAkB1E,QAA1B,CAAlB;;AACA,YAAI8I,MAAJ,EAAY;AACVE,sBAAYrC,EAAZ,GAAiB;AAACsC,iBAAKH;AAAN,WAAjB;AACD;;AACDF,iBAAS9N,KAAKmK,wBAAL,CAA8B,IAAIpB,iBAAJ,CACrCa,kBAAkB9G,cADmB,EAErCoL,WAFqC,EAGrCtE,kBAAkB7J,OAHmB,CAA9B,CAAT,CALK,CASL;AACA;AACA;;AACAuB,eAAO8M,UAAP,CAAkBH,IAAlB,EAAwB,GAAxB;AACA;AACD;AACF;AACF,GAxCD;;AA0CA3M,SAAO+M,KAAP,CAAaJ,IAAb;AAEA,SAAO;AACLtL,UAAM,YAAY;AAChBoL,gBAAU,IAAV;AACAD,aAAOtL,KAAP;AACD;AAJI,GAAP;AAMD,CA3DD;;AA6DA3C,gBAAgB7B,SAAhB,CAA0BqN,eAA1B,GAA4C,UACxCzB,iBADwC,EACrBqB,OADqB,EACZJ,SADY,EACD;AACzC,MAAI7K,OAAO,IAAX;;AAEA,MAAI4J,kBAAkB7J,OAAlB,CAA0BmK,QAA9B,EAAwC;AACtC,WAAOlK,KAAKsO,uBAAL,CAA6B1E,iBAA7B,EAAgDqB,OAAhD,EAAyDJ,SAAzD,CAAP;AACD,GALwC,CAOzC;AACA;;;AACA,MAAIjB,kBAAkB7J,OAAlB,CAA0BiM,MAA1B,KACCpC,kBAAkB7J,OAAlB,CAA0BiM,MAA1B,CAAiClH,GAAjC,KAAyC,CAAzC,IACA8E,kBAAkB7J,OAAlB,CAA0BiM,MAA1B,CAAiClH,GAAjC,KAAyC,KAF1C,CAAJ,EAEsD;AACpD,UAAMrC,MAAM,sDAAN,CAAN;AACD;;AAED,MAAI8L,aAAaxP,MAAMyP,SAAN,CACfjR,EAAE+H,MAAF,CAAS;AAAC2F,aAASA;AAAV,GAAT,EAA6BrB,iBAA7B,CADe,CAAjB;AAGA,MAAI6E,WAAJ,EAAiBC,aAAjB;AACA,MAAIC,cAAc,KAAlB,CAnByC,CAqBzC;AACA;AACA;;AACArN,SAAOsN,gBAAP,CAAwB,YAAY;AAClC,QAAIrR,EAAEuD,GAAF,CAAMd,KAAKC,oBAAX,EAAiCsO,UAAjC,CAAJ,EAAkD;AAChDE,oBAAczO,KAAKC,oBAAL,CAA0BsO,UAA1B,CAAd;AACD,KAFD,MAEO;AACLI,oBAAc,IAAd,CADK,CAEL;;AACAF,oBAAc,IAAII,kBAAJ,CAAuB;AACnC5D,iBAASA,OAD0B;AAEnC6D,gBAAQ,YAAY;AAClB,iBAAO9O,KAAKC,oBAAL,CAA0BsO,UAA1B,CAAP;AACAG,wBAAc/L,IAAd;AACD;AALkC,OAAvB,CAAd;AAOA3C,WAAKC,oBAAL,CAA0BsO,UAA1B,IAAwCE,WAAxC;AACD;AACF,GAfD;;AAiBA,MAAIM,gBAAgB,IAAIC,aAAJ,CAAkBP,WAAlB,EAA+B5D,SAA/B,CAApB;;AAEA,MAAI8D,WAAJ,EAAiB;AACf,QAAIM,OAAJ,EAAaC,MAAb;;AACA,QAAIC,cAAc5R,EAAE6R,GAAF,CAAM,CACtB,YAAY;AACV;AACA;AACA;AACA,aAAOpP,KAAKkB,YAAL,IAAqB,CAAC+J,OAAtB,IACL,CAACJ,UAAUwE,qBADb;AAED,KAPqB,EAOnB,YAAY;AACb;AACA;AACA,UAAI;AACFJ,kBAAU,IAAIK,UAAUC,OAAd,CAAsB3F,kBAAkB1E,QAAxC,CAAV;AACA,eAAO,IAAP;AACD,OAHD,CAGE,OAAOT,CAAP,EAAU;AACV;AACA;AACA,eAAO,KAAP;AACD;AACF,KAlBqB,EAkBnB,YAAY;AACb;AACA,aAAO+K,mBAAmBC,eAAnB,CAAmC7F,iBAAnC,EAAsDqF,OAAtD,CAAP;AACD,KArBqB,EAqBnB,YAAY;AACb;AACA;AACA,UAAI,CAACrF,kBAAkB7J,OAAlB,CAA0ByL,IAA/B,EACE,OAAO,IAAP;;AACF,UAAI;AACF0D,iBAAS,IAAII,UAAUI,MAAd,CAAqB9F,kBAAkB7J,OAAlB,CAA0ByL,IAA/C,EACqB;AAAEyD,mBAASA;AAAX,SADrB,CAAT;AAEA,eAAO,IAAP;AACD,OAJD,CAIE,OAAOxK,CAAP,EAAU;AACV;AACA;AACA,eAAO,KAAP;AACD;AACF,KAnCqB,CAAN,EAmCZ,UAAUkL,CAAV,EAAa;AAAE,aAAOA,GAAP;AAAa,KAnChB,CAAlB,CAFe,CAqCuB;;;AAEtC,QAAIC,cAAcT,cAAcK,kBAAd,GAAmCK,oBAArD;AACAnB,oBAAgB,IAAIkB,WAAJ,CAAgB;AAC9BhG,yBAAmBA,iBADW;AAE9BkG,mBAAa9P,IAFiB;AAG9ByO,mBAAaA,WAHiB;AAI9BxD,eAASA,OAJqB;AAK9BgE,eAASA,OALqB;AAKX;AACnBC,cAAQA,MANsB;AAMb;AACjBG,6BAAuBxE,UAAUwE;AAPH,KAAhB,CAAhB,CAxCe,CAkDf;;AACAZ,gBAAYsB,cAAZ,GAA6BrB,aAA7B;AACD,GA/FwC,CAiGzC;;;AACAD,cAAYuB,2BAAZ,CAAwCjB,aAAxC;AAEA,SAAOA,aAAP;AACD,CAtGD,C,CAwGA;AACA;AACA;AACA;AACA;;;AAEAkB,YAAY,UAAUrG,iBAAV,EAA6BsG,cAA7B,EAA6C;AACvD,MAAIC,YAAY,EAAhB;AACAC,iBAAexG,iBAAf,EAAkC,UAAUyG,OAAV,EAAmB;AACnDF,cAAU9C,IAAV,CAAe5J,UAAU6M,qBAAV,CAAgCC,MAAhC,CACbF,OADa,EACJH,cADI,CAAf;AAED,GAHD;AAKA,SAAO;AACLvN,UAAM,YAAY;AAChBpF,QAAEK,IAAF,CAAOuS,SAAP,EAAkB,UAAUK,QAAV,EAAoB;AACpCA,iBAAS7N,IAAT;AACD,OAFD;AAGD;AALI,GAAP;AAOD,CAdD;;AAgBAyN,iBAAiB,UAAUxG,iBAAV,EAA6B6G,eAA7B,EAA8C;AAC7D,MAAI3S,MAAM;AAACkF,gBAAY4G,kBAAkB9G;AAA/B,GAAV;;AACA,MAAIsC,cAAcT,gBAAgBU,qBAAhB,CAChBuE,kBAAkB1E,QADF,CAAlB;;AAEA,MAAIE,WAAJ,EAAiB;AACf7H,MAAEK,IAAF,CAAOwH,WAAP,EAAoB,UAAUP,EAAV,EAAc;AAChC4L,sBAAgBlT,EAAE+H,MAAF,CAAS;AAACT,YAAIA;AAAL,OAAT,EAAmB/G,GAAnB,CAAhB;AACD,KAFD;;AAGA2S,oBAAgBlT,EAAE+H,MAAF,CAAS;AAACS,sBAAgB,IAAjB;AAAuBlB,UAAI;AAA3B,KAAT,EAA2C/G,GAA3C,CAAhB;AACD,GALD,MAKO;AACL2S,oBAAgB3S,GAAhB;AACD,GAX4D,CAY7D;;;AACA2S,kBAAgB;AAAEvK,kBAAc;AAAhB,GAAhB;AACD,CAdD,C,CAgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACArG,gBAAgB7B,SAAhB,CAA0BsQ,uBAA1B,GAAoD,UAChD1E,iBADgD,EAC7BqB,OAD6B,EACpBJ,SADoB,EACT;AACzC,MAAI7K,OAAO,IAAX,CADyC,CAGzC;AACA;;AACA,MAAKiL,WAAW,CAACJ,UAAU6F,WAAvB,IACC,CAACzF,OAAD,IAAY,CAACJ,UAAU8F,KAD5B,EACoC;AAClC,UAAM,IAAIlO,KAAJ,CAAU,uBAAuBwI,UAAU,SAAV,GAAsB,WAA7C,IACE,6BADF,IAEGA,UAAU,aAAV,GAA0B,OAF7B,IAEwC,WAFlD,CAAN;AAGD;;AAED,SAAOjL,KAAK4N,IAAL,CAAUhE,iBAAV,EAA6B,UAAU9H,GAAV,EAAe;AACjD,QAAI+C,KAAK/C,IAAIgD,GAAb;AACA,WAAOhD,IAAIgD,GAAX,CAFiD,CAGjD;;AACA,WAAOhD,IAAI+J,EAAX;;AACA,QAAIZ,OAAJ,EAAa;AACXJ,gBAAU6F,WAAV,CAAsB7L,EAAtB,EAA0B/C,GAA1B,EAA+B,IAA/B;AACD,KAFD,MAEO;AACL+I,gBAAU8F,KAAV,CAAgB9L,EAAhB,EAAoB/C,GAApB;AACD;AACF,GAVM,CAAP;AAWD,CAxBD,C,CA0BA;AACA;AACA;;;AACAlF,eAAegU,cAAf,GAAgCrU,QAAQwB,SAAxC;AAEAnB,eAAeiU,UAAf,GAA4BhR,eAA5B,C;;;;;;;;;;;AC52CA,IAAIpD,SAASC,IAAIC,OAAJ,CAAY,eAAZ,CAAb;;AAEAiP,mBAAmB,UAAnB;AAEA,IAAIkF,iBAAiBC,QAAQC,GAAR,CAAYC,2BAAZ,IAA2C,IAAhE;;AAEA,IAAIC,SAAS,UAAUrF,EAAV,EAAc;AACzB,SAAO,eAAeA,GAAGsF,WAAH,EAAf,GAAkC,IAAlC,GAAyCtF,GAAGuF,UAAH,EAAzC,GAA2D,GAAlE;AACD,CAFD;;AAIAC,UAAU,UAAUC,EAAV,EAAc;AACtB,MAAIA,GAAGA,EAAH,KAAU,GAAd,EACE,OAAOA,GAAGC,CAAH,CAAKzM,GAAZ,CADF,KAEK,IAAIwM,GAAGA,EAAH,KAAU,GAAd,EACH,OAAOA,GAAGC,CAAH,CAAKzM,GAAZ,CADG,KAEA,IAAIwM,GAAGA,EAAH,KAAU,GAAd,EACH,OAAOA,GAAGE,EAAH,CAAM1M,GAAb,CADG,KAEA,IAAIwM,GAAGA,EAAH,KAAU,GAAd,EACH,MAAM7O,MAAM,oDACA1D,MAAMyP,SAAN,CAAgB8C,EAAhB,CADN,CAAN,CADG,KAIH,MAAM7O,MAAM,iBAAiB1D,MAAMyP,SAAN,CAAgB8C,EAAhB,CAAvB,CAAN;AACH,CAZD;;AAcAjP,cAAc,UAAUF,QAAV,EAAoBsP,MAApB,EAA4B;AACxC,MAAIzR,OAAO,IAAX;AACAA,OAAK0R,SAAL,GAAiBvP,QAAjB;AACAnC,OAAK2R,OAAL,GAAeF,MAAf;AAEAzR,OAAK4R,yBAAL,GAAiC,IAAjC;AACA5R,OAAK6R,oBAAL,GAA4B,IAA5B;AACA7R,OAAK8R,QAAL,GAAgB,KAAhB;AACA9R,OAAK+R,WAAL,GAAmB,IAAnB;AACA/R,OAAKgS,YAAL,GAAoB,IAAIvV,MAAJ,EAApB;AACAuD,OAAKiS,SAAL,GAAiB,IAAIxO,UAAUyO,SAAd,CAAwB;AACvCC,iBAAa,gBAD0B;AACRC,cAAU;AADF,GAAxB,CAAjB;AAGApS,OAAKqS,kBAAL,GAA0B;AACxBC,QAAI,IAAIC,MAAJ,CAAW,MAAMjR,OAAOkR,aAAP,CAAqBxS,KAAK2R,OAA1B,CAAN,GAA2C,KAAtD,CADoB;AAExBc,SAAK,CACH;AAAEnB,UAAI;AAACoB,aAAK,CAAC,GAAD,EAAM,GAAN,EAAW,GAAX;AAAN;AAAN,KADG,EAEH;AACA;AAAEpB,UAAI,GAAN;AAAW,gBAAU;AAAEqB,iBAAS;AAAX;AAArB,KAHG,EAIH;AAAErB,UAAI,GAAN;AAAW,wBAAkB;AAA7B,KAJG;AAFmB,GAA1B,CAbwC,CAuBxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAtR,OAAK4S,kBAAL,GAA0B,EAA1B;AACA5S,OAAK6S,gBAAL,GAAwB,IAAxB;AAEA7S,OAAK8S,qBAAL,GAA6B,IAAI3S,IAAJ,CAAS;AACpC4S,0BAAsB;AADc,GAAT,CAA7B;AAIA/S,OAAKgT,WAAL,GAAmB,IAAI1R,OAAO2R,iBAAX,EAAnB;AACAjT,OAAKkT,aAAL,GAAqB,KAArB;;AAEAlT,OAAKmT,aAAL;AACD,CApDD;;AAsDA5V,EAAE+H,MAAF,CAASjD,YAAYrE,SAArB,EAAgC;AAC9B2E,QAAM,YAAY;AAChB,QAAI3C,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE;AACF9R,SAAK8R,QAAL,GAAgB,IAAhB;AACA,QAAI9R,KAAK+R,WAAT,EACE/R,KAAK+R,WAAL,CAAiBpP,IAAjB,GANc,CAOhB;AACD,GAT6B;AAU9ByQ,gBAAc,UAAU/C,OAAV,EAAmBtO,QAAnB,EAA6B;AACzC,QAAI/B,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE,MAAM,IAAIrP,KAAJ,CAAU,wCAAV,CAAN,CAHuC,CAKzC;;AACAzC,SAAKgS,YAAL,CAAkB9P,IAAlB;;AAEA,QAAImR,mBAAmBtR,QAAvB;AACAA,eAAWT,OAAOC,eAAP,CAAuB,UAAU+R,YAAV,EAAwB;AACxD;AACAD,uBAAiBtU,MAAMd,KAAN,CAAYqV,YAAZ,CAAjB;AACD,KAHU,EAGR,UAAU9R,GAAV,EAAe;AAChBF,aAAOiS,MAAP,CAAc,yBAAd,EAAyC/R,GAAzC;AACD,KALU,CAAX;;AAMA,QAAIgS,eAAexT,KAAKiS,SAAL,CAAe1B,MAAf,CAAsBF,OAAtB,EAA+BtO,QAA/B,CAAnB;;AACA,WAAO;AACLY,YAAM,YAAY;AAChB6Q,qBAAa7Q,IAAb;AACD;AAHI,KAAP;AAKD,GA/B6B;AAgC9B;AACA;AACA8Q,oBAAkB,UAAU1R,QAAV,EAAoB;AACpC,QAAI/B,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE,MAAM,IAAIrP,KAAJ,CAAU,4CAAV,CAAN;AACF,WAAOzC,KAAK8S,qBAAL,CAA2B/O,QAA3B,CAAoChC,QAApC,CAAP;AACD,GAvC6B;AAwC9B;AACA;AACA;AACA;AACA;AACA2R,qBAAmB,YAAY;AAC7B,QAAI1T,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE,MAAM,IAAIrP,KAAJ,CAAU,6CAAV,CAAN,CAH2B,CAK7B;AACA;;AACAzC,SAAKgS,YAAL,CAAkB9P,IAAlB;;AACA,QAAIyR,SAAJ;;AAEA,WAAO,CAAC3T,KAAK8R,QAAb,EAAuB;AACrB;AACA;AACA;AACA,UAAI;AACF6B,oBAAY3T,KAAK4R,yBAAL,CAA+B5I,OAA/B,CACV4C,gBADU,EACQ5L,KAAKqS,kBADb,EAEV;AAACrG,kBAAQ;AAACH,gBAAI;AAAL,WAAT;AAAkBL,gBAAM;AAACoI,sBAAU,CAAC;AAAZ;AAAxB,SAFU,CAAZ;AAGA;AACD,OALD,CAKE,OAAOnP,CAAP,EAAU;AACV;AACA;AACAnD,eAAOiS,MAAP,CAAc,wCAAd,EAAwD9O,CAAxD;;AACAnD,eAAOuS,WAAP,CAAmB,GAAnB;AACD;AACF;;AAED,QAAI7T,KAAK8R,QAAT,EACE;;AAEF,QAAI,CAAC6B,SAAL,EAAgB;AACd;AACA;AACD;;AAED,QAAI9H,KAAK8H,UAAU9H,EAAnB;AACA,QAAI,CAACA,EAAL,EACE,MAAMpJ,MAAM,6BAA6B1D,MAAMyP,SAAN,CAAgBmF,SAAhB,CAAnC,CAAN;;AAEF,QAAI3T,KAAK6S,gBAAL,IAAyBhH,GAAGiI,eAAH,CAAmB9T,KAAK6S,gBAAxB,CAA7B,EAAwE;AACtE;AACA;AACD,KA1C4B,CA6C7B;AACA;AACA;;;AACA,QAAIkB,cAAc/T,KAAK4S,kBAAL,CAAwB/K,MAA1C;;AACA,WAAOkM,cAAc,CAAd,GAAkB,CAAlB,IAAuB/T,KAAK4S,kBAAL,CAAwBmB,cAAc,CAAtC,EAAyClI,EAAzC,CAA4CmI,WAA5C,CAAwDnI,EAAxD,CAA9B,EAA2F;AACzFkI;AACD;;AACD,QAAIpE,IAAI,IAAIlT,MAAJ,EAAR;;AACAuD,SAAK4S,kBAAL,CAAwBqB,MAAxB,CAA+BF,WAA/B,EAA4C,CAA5C,EAA+C;AAAClI,UAAIA,EAAL;AAAS9I,cAAQ4M;AAAjB,KAA/C;;AACAA,MAAEzN,IAAF;AACD,GApG6B;AAqG9BiR,iBAAe,YAAY;AACzB,QAAInT,OAAO,IAAX,CADyB,CAEzB;;AACA,QAAIkU,aAAaxX,IAAIC,OAAJ,CAAY,aAAZ,CAAjB;;AACA,QAAIuX,WAAWC,KAAX,CAAiBnU,KAAK0R,SAAtB,EAAiC0C,QAAjC,KAA8C,OAAlD,EAA2D;AACzD,YAAM3R,MAAM,6DACA,qBADN,CAAN;AAED,KAPwB,CASzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAzC,SAAK6R,oBAAL,GAA4B,IAAIhS,eAAJ,CAC1BG,KAAK0R,SADqB,EACV;AAAC3Q,gBAAU;AAAX,KADU,CAA5B,CApByB,CAsBzB;AACA;AACA;;AACAf,SAAK4R,yBAAL,GAAiC,IAAI/R,eAAJ,CAC/BG,KAAK0R,SAD0B,EACf;AAAC3Q,gBAAU;AAAX,KADe,CAAjC,CAzByB,CA4BzB;AACA;AACA;AACA;;AACA,QAAI4O,IAAI,IAAIlT,MAAJ,EAAR;;AACAuD,SAAK4R,yBAAL,CAA+B5Q,EAA/B,CAAkCqT,KAAlC,GAA0CC,OAA1C,CACE;AAAEC,gBAAU;AAAZ,KADF,EACmB5E,EAAE1N,QAAF,EADnB;;AAEA,QAAIP,cAAciO,EAAEzN,IAAF,EAAlB;;AAEA,QAAI,EAAER,eAAeA,YAAY8S,OAA7B,CAAJ,EAA2C;AACzC,YAAM/R,MAAM,6DACA,qBADN,CAAN;AAED,KAxCwB,CA0CzB;;;AACA,QAAIgS,iBAAiBzU,KAAK4R,yBAAL,CAA+B5I,OAA/B,CACnB4C,gBADmB,EACD,EADC,EACG;AAACJ,YAAM;AAACoI,kBAAU,CAAC;AAAZ,OAAP;AAAuB5H,cAAQ;AAACH,YAAI;AAAL;AAA/B,KADH,CAArB;;AAGA,QAAI6I,gBAAgBnX,EAAEU,KAAF,CAAQ+B,KAAKqS,kBAAb,CAApB;;AACA,QAAIoC,cAAJ,EAAoB;AAClB;AACAC,oBAAc7I,EAAd,GAAmB;AAACsC,aAAKsG,eAAe5I;AAArB,OAAnB,CAFkB,CAGlB;AACA;AACA;;AACA7L,WAAK6S,gBAAL,GAAwB4B,eAAe5I,EAAvC;AACD;;AAED,QAAIjC,oBAAoB,IAAIb,iBAAJ,CACtB6C,gBADsB,EACJ8I,aADI,EACW;AAACxK,gBAAU;AAAX,KADX,CAAxB;AAGAlK,SAAK+R,WAAL,GAAmB/R,KAAK6R,oBAAL,CAA0BjE,IAA1B,CACjBhE,iBADiB,EACE,UAAU9H,GAAV,EAAe;AAChC9B,WAAKgT,WAAL,CAAiB3F,IAAjB,CAAsBvL,GAAtB;;AACA9B,WAAK2U,iBAAL;AACD,KAJgB,CAAnB;;AAMA3U,SAAKgS,YAAL,CAAkB4C,MAAlB;AACD,GAvK6B;AAyK9BD,qBAAmB,YAAY;AAC7B,QAAI3U,OAAO,IAAX;AACA,QAAIA,KAAKkT,aAAT,EACE;AACFlT,SAAKkT,aAAL,GAAqB,IAArB;AACA5R,WAAO+M,KAAP,CAAa,YAAY;AACvB,UAAI;AACF,eAAO,CAAErO,KAAK8R,QAAP,IAAmB,CAAE9R,KAAKgT,WAAL,CAAiB6B,OAAjB,EAA5B,EAAwD;AACtD;AACA;AACA,cAAI7U,KAAKgT,WAAL,CAAiBnL,MAAjB,GAA0BiJ,cAA9B,EAA8C;AAC5C,gBAAI6C,YAAY3T,KAAKgT,WAAL,CAAiB8B,GAAjB,EAAhB;;AACA9U,iBAAKgT,WAAL,CAAiB+B,KAAjB;;AAEA/U,iBAAK8S,qBAAL,CAA2BlV,IAA3B,CAAgC,UAAUmE,QAAV,EAAoB;AAClDA;AACA,qBAAO,IAAP;AACD,aAHD,EAJ4C,CAS5C;AACA;;;AACA/B,iBAAKgV,mBAAL,CAAyBrB,UAAU9H,EAAnC;;AACA;AACD;;AAED,cAAI/J,MAAM9B,KAAKgT,WAAL,CAAiBiC,KAAjB,EAAV;;AAEA,cAAI,EAAEnT,IAAIwQ,EAAJ,IAAUxQ,IAAIwQ,EAAJ,CAAOzK,MAAP,GAAgB7H,KAAK2R,OAAL,CAAa9J,MAAb,GAAsB,CAAhD,IACA/F,IAAIwQ,EAAJ,CAAOjU,MAAP,CAAc,CAAd,EAAiB2B,KAAK2R,OAAL,CAAa9J,MAAb,GAAsB,CAAvC,MACC7H,KAAK2R,OAAL,GAAe,GAFlB,CAAJ,EAE6B;AAC3B,kBAAM,IAAIlP,KAAJ,CAAU,eAAV,CAAN;AACD;;AAED,cAAI4N,UAAU;AAACrN,wBAAYlB,IAAIwQ,EAAJ,CAAOjU,MAAP,CAAc2B,KAAK2R,OAAL,CAAa9J,MAAb,GAAsB,CAApC,CAAb;AACC9B,4BAAgB,KADjB;AAECG,0BAAc,KAFf;AAGCoL,gBAAIxP;AAHL,WAAd,CA1BsD,CA+BtD;AACA;;AACA,cAAIuO,QAAQrN,UAAR,KAAuB,MAA3B,EAAmC;AACjC,gBAAIlB,IAAIyP,CAAJ,CAAMrL,YAAV,EAAwB;AACtB,qBAAOmK,QAAQrN,UAAf;AACAqN,sBAAQnK,YAAR,GAAuB,IAAvB;AACD,aAHD,MAGO,IAAI3I,EAAEuD,GAAF,CAAMgB,IAAIyP,CAAV,EAAa,MAAb,CAAJ,EAA0B;AAC/BlB,sBAAQrN,UAAR,GAAqBlB,IAAIyP,CAAJ,CAAMvL,IAA3B;AACAqK,sBAAQtK,cAAR,GAAyB,IAAzB;AACAsK,sBAAQxL,EAAR,GAAa,IAAb;AACD,aAJM,MAIA;AACL,oBAAMpC,MAAM,qBAAqByS,KAAK1G,SAAL,CAAe1M,GAAf,CAA3B,CAAN;AACD;AACF,WAXD,MAWO;AACL;AACAuO,oBAAQxL,EAAR,GAAawM,QAAQvP,GAAR,CAAb;AACD;;AAED9B,eAAKiS,SAAL,CAAekD,IAAf,CAAoB9E,OAApB,EAjDsD,CAmDtD;AACA;;;AACA,cAAI,CAACvO,IAAI+J,EAAT,EACE,MAAMpJ,MAAM,6BAA6B1D,MAAMyP,SAAN,CAAgB1M,GAAhB,CAAnC,CAAN;;AACF9B,eAAKgV,mBAAL,CAAyBlT,IAAI+J,EAA7B;AACD;AACF,OA1DD,SA0DU;AACR7L,aAAKkT,aAAL,GAAqB,KAArB;AACD;AACF,KA9DD;AA+DD,GA7O6B;AA8O9B8B,uBAAqB,UAAUnJ,EAAV,EAAc;AACjC,QAAI7L,OAAO,IAAX;AACAA,SAAK6S,gBAAL,GAAwBhH,EAAxB;;AACA,WAAO,CAACtO,EAAEsX,OAAF,CAAU7U,KAAK4S,kBAAf,CAAD,IAAuC5S,KAAK4S,kBAAL,CAAwB,CAAxB,EAA2B/G,EAA3B,CAA8BiI,eAA9B,CAA8C9T,KAAK6S,gBAAnD,CAA9C,EAAoH;AAClH,UAAIuC,YAAYpV,KAAK4S,kBAAL,CAAwBqC,KAAxB,EAAhB;;AACAG,gBAAUrS,MAAV,CAAiB6R,MAAjB;AACD;AACF,GArP6B;AAuP9B;AACAS,uBAAqB,UAASxX,KAAT,EAAgB;AACnCiT,qBAAiBjT,KAAjB;AACD,GA1P6B;AA2P9ByX,sBAAoB,YAAW;AAC7BxE,qBAAiBC,QAAQC,GAAR,CAAYC,2BAAZ,IAA2C,IAA5D;AACD;AA7P6B,CAAhC,E;;;;;;;;;;;AC9EA,IAAIxU,SAASC,IAAIC,OAAJ,CAAY,eAAZ,CAAb;;AAEAkS,qBAAqB,UAAU9O,OAAV,EAAmB;AACtC,MAAIC,OAAO,IAAX;AAEA,MAAI,CAACD,OAAD,IAAY,CAACxC,EAAEuD,GAAF,CAAMf,OAAN,EAAe,SAAf,CAAjB,EACE,MAAM0C,MAAM,wBAAN,CAAN;AAEFL,UAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,sBADK,EACmB,CADnB,CAAzB;AAGAxV,OAAKyV,QAAL,GAAgB1V,QAAQkL,OAAxB;;AACAjL,OAAK0V,OAAL,GAAe3V,QAAQ+O,MAAR,IAAkB,YAAY,CAAE,CAA/C;;AACA9O,OAAK2V,MAAL,GAAc,IAAIrU,OAAOsU,iBAAX,EAAd;AACA5V,OAAK6V,QAAL,GAAgB,EAAhB;AACA7V,OAAKgS,YAAL,GAAoB,IAAIvV,MAAJ,EAApB;AACAuD,OAAK8V,MAAL,GAAc,IAAInR,gBAAgBoR,sBAApB,CAA2C;AACvD9K,aAASlL,QAAQkL;AADsC,GAA3C,CAAd,CAdsC,CAgBtC;AACA;AACA;;AACAjL,OAAKgW,uCAAL,GAA+C,CAA/C;;AAEAzY,IAAEK,IAAF,CAAOoC,KAAKiW,aAAL,EAAP,EAA6B,UAAUC,YAAV,EAAwB;AACnDlW,SAAKkW,YAAL,IAAqB;AAAU;AAAW;AACxClW,WAAKmW,cAAL,CAAoBD,YAApB,EAAkC3Y,EAAE6Y,OAAF,CAAUxN,SAAV,CAAlC;AACD,KAFD;AAGD,GAJD;AAKD,CA1BD;;AA4BArL,EAAE+H,MAAF,CAASuJ,mBAAmB7Q,SAA5B,EAAuC;AACrCgS,+BAA6B,UAAUqG,MAAV,EAAkB;AAC7C,QAAIrW,OAAO,IAAX,CAD6C,CAG7C;AACA;AACA;AACA;;AACA,QAAI,CAACA,KAAK2V,MAAL,CAAYW,aAAZ,EAAL,EACE,MAAM,IAAI7T,KAAJ,CAAU,sEAAV,CAAN;AACF,MAAEzC,KAAKgW,uCAAP;AAEA5T,YAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,iBADK,EACc,CADd,CAAzB;;AAGAxV,SAAK2V,MAAL,CAAYY,OAAZ,CAAoB,YAAY;AAC9BvW,WAAK6V,QAAL,CAAcQ,OAAOvR,GAArB,IAA4BuR,MAA5B,CAD8B,CAE9B;AACA;;AACArW,WAAKwW,SAAL,CAAeH,MAAf;;AACA,QAAErW,KAAKgW,uCAAP;AACD,KAND,EAd6C,CAqB7C;;;AACAhW,SAAKgS,YAAL,CAAkB9P,IAAlB;AACD,GAxBoC;AA0BrC;AACA;AACA;AACA;AACA;AACA;AACAuU,gBAAc,UAAU5R,EAAV,EAAc;AAC1B,QAAI7E,OAAO,IAAX,CAD0B,CAG1B;AACA;AACA;;AACA,QAAI,CAACA,KAAK0W,MAAL,EAAL,EACE,MAAM,IAAIjU,KAAJ,CAAU,mDAAV,CAAN;AAEF,WAAOzC,KAAK6V,QAAL,CAAchR,EAAd,CAAP;AAEAzC,YAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,iBADK,EACc,CAAC,CADf,CAAzB;;AAGA,QAAIjY,EAAEsX,OAAF,CAAU7U,KAAK6V,QAAf,KACA7V,KAAKgW,uCAAL,KAAiD,CADrD,EACwD;AACtDhW,WAAK2W,KAAL;AACD;AACF,GAlDoC;AAmDrCA,SAAO,UAAU5W,OAAV,EAAmB;AACxB,QAAIC,OAAO,IAAX;AACAD,cAAUA,WAAW,EAArB,CAFwB,CAIxB;AACA;;AACA,QAAI,CAAEC,KAAK0W,MAAL,EAAF,IAAmB,CAAE3W,QAAQ6W,cAAjC,EACE,MAAMnU,MAAM,6BAAN,CAAN,CAPsB,CASxB;AACA;;AACAzC,SAAK0V,OAAL;;AACAtT,YAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,sBADK,EACmB,CAAC,CADpB,CAAzB,CAZwB,CAexB;AACA;;AACAxV,SAAK6V,QAAL,GAAgB,IAAhB;AACD,GArEoC;AAuErC;AACA;AACAgB,SAAO,YAAY;AACjB,QAAI7W,OAAO,IAAX;;AACAA,SAAK2V,MAAL,CAAYmB,SAAZ,CAAsB,YAAY;AAChC,UAAI9W,KAAK0W,MAAL,EAAJ,EACE,MAAMjU,MAAM,0CAAN,CAAN;;AACFzC,WAAKgS,YAAL,CAAkB4C,MAAlB;AACD,KAJD;AAKD,GAhFoC;AAkFrC;AACA;AACA;AACA;AACA;AACA;AACAmC,cAAY,UAAUvV,GAAV,EAAe;AACzB,QAAIxB,OAAO,IAAX;;AACAA,SAAK2V,MAAL,CAAYY,OAAZ,CAAoB,YAAY;AAC9B,UAAIvW,KAAK0W,MAAL,EAAJ,EACE,MAAMjU,MAAM,iDAAN,CAAN;;AACFzC,WAAK2W,KAAL,CAAW;AAACC,wBAAgB;AAAjB,OAAX;;AACA5W,WAAKgS,YAAL,CAAkBgF,KAAlB,CAAwBxV,GAAxB;AACD,KALD;AAMD,GAhGoC;AAkGrC;AACA;AACA;AACAyV,WAAS,UAAUnR,EAAV,EAAc;AACrB,QAAI9F,OAAO,IAAX;;AACAA,SAAK2V,MAAL,CAAYmB,SAAZ,CAAsB,YAAY;AAChC,UAAI,CAAC9W,KAAK0W,MAAL,EAAL,EACE,MAAMjU,MAAM,uDAAN,CAAN;AACFqD;AACD,KAJD;AAKD,GA5GoC;AA6GrCmQ,iBAAe,YAAY;AACzB,QAAIjW,OAAO,IAAX;AACA,QAAIA,KAAKyV,QAAT,EACE,OAAO,CAAC,aAAD,EAAgB,SAAhB,EAA2B,aAA3B,EAA0C,SAA1C,CAAP,CADF,KAGE,OAAO,CAAC,OAAD,EAAU,SAAV,EAAqB,SAArB,CAAP;AACH,GAnHoC;AAoHrCiB,UAAQ,YAAY;AAClB,WAAO,KAAK1E,YAAL,CAAkBkF,UAAlB,EAAP;AACD,GAtHoC;AAuHrCf,kBAAgB,UAAUD,YAAV,EAAwBiB,IAAxB,EAA8B;AAC5C,QAAInX,OAAO,IAAX;;AACAA,SAAK2V,MAAL,CAAYmB,SAAZ,CAAsB,YAAY;AAChC;AACA,UAAI,CAAC9W,KAAK6V,QAAV,EACE,OAH8B,CAKhC;AACA;AACA;AACA;AACA;;AACA7V,WAAK8V,MAAL,CAAYsB,WAAZ,CAAwBlB,YAAxB,EAAsCvN,KAAtC,CAA4C,IAA5C,EAAkD5J,MAAMd,KAAN,CAAYkZ,IAAZ,CAAlD,EAVgC,CAYhC;AACA;;;AACA,UAAI,CAACnX,KAAK0W,MAAL,EAAD,IACCR,iBAAiB,OAAjB,IAA4BA,iBAAiB,aADlD,EACkE;AAChE,cAAM,IAAIzT,KAAJ,CAAU,SAASyT,YAAT,GAAwB,sBAAlC,CAAN;AACD,OAjB+B,CAmBhC;AACA;AACA;AACA;AACA;;;AACA3Y,QAAEK,IAAF,CAAOL,EAAE8Z,IAAF,CAAOrX,KAAK6V,QAAZ,CAAP,EAA8B,UAAUyB,QAAV,EAAoB;AAChD,YAAIjB,SAASrW,KAAK6V,QAAL,IAAiB7V,KAAK6V,QAAL,CAAcyB,QAAd,CAA9B;AACA,YAAI,CAACjB,MAAL,EACE;AACF,YAAItU,WAAWsU,OAAO,MAAMH,YAAb,CAAf,CAJgD,CAKhD;;AACAnU,oBAAYA,SAAS4G,KAAT,CAAe,IAAf,EAAqB5J,MAAMd,KAAN,CAAYkZ,IAAZ,CAArB,CAAZ;AACD,OAPD;AAQD,KAhCD;AAiCD,GA1JoC;AA4JrC;AACA;AACA;AACA;AACAX,aAAW,UAAUH,MAAV,EAAkB;AAC3B,QAAIrW,OAAO,IAAX;AACA,QAAIA,KAAK2V,MAAL,CAAYW,aAAZ,EAAJ,EACE,MAAM7T,MAAM,kDAAN,CAAN;AACF,QAAI8U,MAAMvX,KAAKyV,QAAL,GAAgBY,OAAOmB,YAAvB,GAAsCnB,OAAOoB,MAAvD;AACA,QAAI,CAACF,GAAL,EACE,OANyB,CAO3B;;AACAvX,SAAK8V,MAAL,CAAY4B,IAAZ,CAAiBtM,OAAjB,CAAyB,UAAUtJ,GAAV,EAAe+C,EAAf,EAAmB;AAC1C,UAAI,CAACtH,EAAEuD,GAAF,CAAMd,KAAK6V,QAAX,EAAqBQ,OAAOvR,GAA5B,CAAL,EACE,MAAMrC,MAAM,iDAAN,CAAN;AACF,UAAIuJ,SAASjN,MAAMd,KAAN,CAAY6D,GAAZ,CAAb;AACA,aAAOkK,OAAOlH,GAAd;AACA,UAAI9E,KAAKyV,QAAT,EACE8B,IAAI1S,EAAJ,EAAQmH,MAAR,EAAgB,IAAhB,EADF,CACyB;AADzB,WAGEuL,IAAI1S,EAAJ,EAAQmH,MAAR;AACH,KATD;AAUD;AAlLoC,CAAvC;;AAsLA,IAAI2L,sBAAsB,CAA1B;;AACA3I,gBAAgB,UAAUP,WAAV,EAAuB5D,SAAvB,EAAkC;AAChD,MAAI7K,OAAO,IAAX,CADgD,CAEhD;AACA;;AACAA,OAAK4X,YAAL,GAAoBnJ,WAApB;;AACAlR,IAAEK,IAAF,CAAO6Q,YAAYwH,aAAZ,EAAP,EAAoC,UAAU9X,IAAV,EAAgB;AAClD,QAAI0M,UAAU1M,IAAV,CAAJ,EAAqB;AACnB6B,WAAK,MAAM7B,IAAX,IAAmB0M,UAAU1M,IAAV,CAAnB;AACD,KAFD,MAEO,IAAIA,SAAS,aAAT,IAA0B0M,UAAU8F,KAAxC,EAA+C;AACpD;AACA;AACA;AACA;AACA3Q,WAAKwX,YAAL,GAAoB,UAAU3S,EAAV,EAAcmH,MAAd,EAAsB6L,MAAtB,EAA8B;AAChDhN,kBAAU8F,KAAV,CAAgB9L,EAAhB,EAAoBmH,MAApB;AACD,OAFD;AAGD;AACF,GAZD;;AAaAhM,OAAK8R,QAAL,GAAgB,KAAhB;AACA9R,OAAK8E,GAAL,GAAW6S,qBAAX;AACD,CApBD;;AAqBA3I,cAAchR,SAAd,CAAwB2E,IAAxB,GAA+B,YAAY;AACzC,MAAI3C,OAAO,IAAX;AACA,MAAIA,KAAK8R,QAAT,EACE;AACF9R,OAAK8R,QAAL,GAAgB,IAAhB;;AACA9R,OAAK4X,YAAL,CAAkBnB,YAAlB,CAA+BzW,KAAK8E,GAApC;AACD,CAND,C;;;;;;;;;;;AC1OA,IAAIgT,QAAQpb,IAAIC,OAAJ,CAAY,QAAZ,CAAZ;;AACA,IAAIF,SAASC,IAAIC,OAAJ,CAAY,eAAZ,CAAb;;AAEA4F,aAAa,UAAUwV,eAAV,EAA2B;AACtC,MAAI/X,OAAO,IAAX;AACAA,OAAKgY,gBAAL,GAAwBD,eAAxB,CAFsC,CAGtC;;AACA/X,OAAKiY,qBAAL,GAA6B,EAA7B;AACD,CALD;;AAOA1a,EAAE+H,MAAF,CAAS/C,WAAWvE,SAApB,EAA+B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAkL,SAAO,UAAUpG,cAAV,EAA0B+B,EAA1B,EAA8BqT,QAA9B,EAAwCnW,QAAxC,EAAkD;AACvD,QAAI/B,OAAO,IAAX;AAEAmY,UAAMrV,cAAN,EAAsBsV,MAAtB,EAHuD,CAIvD;;AACAD,UAAMD,QAAN,EAAgBE,MAAhB,EALuD,CAOvD;AACA;;AACA,QAAI7a,EAAEuD,GAAF,CAAMd,KAAKiY,qBAAX,EAAkCC,QAAlC,CAAJ,EAAiD;AAC/ClY,WAAKiY,qBAAL,CAA2BC,QAA3B,EAAqC7K,IAArC,CAA0CtL,QAA1C;;AACA;AACD;;AAED,QAAI8I,YAAY7K,KAAKiY,qBAAL,CAA2BC,QAA3B,IAAuC,CAACnW,QAAD,CAAvD;AAEA+V,UAAM,YAAY;AAChB,UAAI;AACF,YAAIhW,MAAM9B,KAAKgY,gBAAL,CAAsBhP,OAAtB,CACRlG,cADQ,EACQ;AAACgC,eAAKD;AAAN,SADR,KACsB,IADhC,CADE,CAGF;AACA;;AACA,eAAO,CAACtH,EAAEsX,OAAF,CAAUhK,SAAV,CAAR,EAA8B;AAC5B;AACA;AACA;AACA;AACA,cAAIwN,YAAYtZ,MAAMd,KAAN,CAAY6D,GAAZ,CAAhB;AACA+I,oBAAUiK,GAAV,GAAgB,IAAhB,EAAsBuD,SAAtB;AACD;AACF,OAbD,CAaE,OAAO5T,CAAP,EAAU;AACV,eAAO,CAAClH,EAAEsX,OAAF,CAAUhK,SAAV,CAAR,EAA8B;AAC5BA,oBAAUiK,GAAV,GAAgBrQ,CAAhB;AACD;AACF,OAjBD,SAiBU;AACR;AACA;AACA,eAAOzE,KAAKiY,qBAAL,CAA2BC,QAA3B,CAAP;AACD;AACF,KAvBD,EAuBGI,GAvBH;AAwBD;AAlD4B,CAA/B;;AAqDAzb,UAAU0F,UAAV,GAAuBA,UAAvB,C;;;;;;;;;;;AC/DAsN,uBAAuB,UAAU9P,OAAV,EAAmB;AACxC,MAAIC,OAAO,IAAX;AAEAA,OAAK8J,kBAAL,GAA0B/J,QAAQ6J,iBAAlC;AACA5J,OAAKuY,YAAL,GAAoBxY,QAAQ+P,WAA5B;AACA9P,OAAKyV,QAAL,GAAgB1V,QAAQkL,OAAxB;AACAjL,OAAK4X,YAAL,GAAoB7X,QAAQ0O,WAA5B;AACAzO,OAAKwY,cAAL,GAAsB,EAAtB;AACAxY,OAAK8R,QAAL,GAAgB,KAAhB;AAEA9R,OAAK+J,kBAAL,GAA0B/J,KAAKuY,YAAL,CAAkBpO,wBAAlB,CACxBnK,KAAK8J,kBADmB,CAA1B,CAVwC,CAaxC;AACA;;AACA9J,OAAKyY,QAAL,GAAgB,IAAhB,CAfwC,CAiBxC;AACA;AACA;AACA;AACA;AACA;AACA;;AACAzY,OAAK0Y,4BAAL,GAAoC,CAApC;AACA1Y,OAAK2Y,cAAL,GAAsB,EAAtB,CAzBwC,CAyBd;AAE1B;AACA;;AACA3Y,OAAK4Y,sBAAL,GAA8Brb,EAAEsb,QAAF,CAC5B7Y,KAAK8Y,iCADuB,EAE5B9Y,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCgZ,iBAAhC,IAAqD;AAAG;AAF5B,GAA9B,CA7BwC,CAiCxC;;AACA/Y,OAAKgZ,UAAL,GAAkB,IAAI1X,OAAOsU,iBAAX,EAAlB;AAEA,MAAIqD,kBAAkBhJ,UACpBjQ,KAAK8J,kBADe,EACK,UAAUwJ,YAAV,EAAwB;AAC/C;AACA;AACA;AACA,QAAI9P,QAAQC,UAAUC,kBAAV,CAA6BC,GAA7B,EAAZ;;AACA,QAAIH,KAAJ,EACExD,KAAK2Y,cAAL,CAAoBtL,IAApB,CAAyB7J,MAAMI,UAAN,EAAzB,EAN6C,CAO/C;AACA;AACA;;AACA,QAAI5D,KAAK0Y,4BAAL,KAAsC,CAA1C,EACE1Y,KAAK4Y,sBAAL;AACH,GAbmB,CAAtB;;AAeA5Y,OAAKwY,cAAL,CAAoBnL,IAApB,CAAyB,YAAY;AAAE4L,oBAAgBtW,IAAhB;AAAyB,GAAhE,EAnDwC,CAqDxC;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAI5C,QAAQsP,qBAAZ,EAAmC;AACjCrP,SAAKqP,qBAAL,GAA6BtP,QAAQsP,qBAArC;AACD,GAFD,MAEO;AACL,QAAI6J,kBACElZ,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCoZ,iBAAhC,IACAnZ,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCqZ,gBADhC,IACoD;AACpD,SAAK,IAHX;AAIA,QAAIC,iBAAiB/X,OAAOgY,WAAP,CACnB/b,EAAEG,IAAF,CAAOsC,KAAK4Y,sBAAZ,EAAoC5Y,IAApC,CADmB,EACwBkZ,eADxB,CAArB;;AAEAlZ,SAAKwY,cAAL,CAAoBnL,IAApB,CAAyB,YAAY;AACnC/L,aAAOiY,aAAP,CAAqBF,cAArB;AACD,KAFD;AAGD,GAxEuC,CA0ExC;;;AACArZ,OAAK8Y,iCAAL;;AAEA1W,UAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,yBADK,EACsB,CADtB,CAAzB;AAED,CA/ED;;AAiFAjY,EAAE+H,MAAF,CAASuK,qBAAqB7R,SAA9B,EAAyC;AACvC;AACA8a,qCAAmC,YAAY;AAC7C,QAAI9Y,OAAO,IAAX;AACA,QAAIA,KAAK0Y,4BAAL,GAAoC,CAAxC,EACE;AACF,MAAE1Y,KAAK0Y,4BAAP;;AACA1Y,SAAKgZ,UAAL,CAAgBlC,SAAhB,CAA0B,YAAY;AACpC9W,WAAKwZ,UAAL;AACD,KAFD;AAGD,GAVsC;AAYvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAC,mBAAiB,YAAW;AAC1B,QAAIzZ,OAAO,IAAX,CAD0B,CAE1B;AACA;;AACA,MAAEA,KAAK0Y,4BAAP,CAJ0B,CAK1B;;AACA1Y,SAAKgZ,UAAL,CAAgBzC,OAAhB,CAAwB,YAAW,CAAE,CAArC,EAN0B,CAQ1B;AACA;;;AACA,QAAIvW,KAAK0Y,4BAAL,KAAsC,CAA1C,EACE,MAAM,IAAIjW,KAAJ,CAAU,qCACAzC,KAAK0Y,4BADf,CAAN;AAEH,GAjCsC;AAkCvCgB,kBAAgB,YAAW;AACzB,QAAI1Z,OAAO,IAAX,CADyB,CAEzB;;AACA,QAAIA,KAAK0Y,4BAAL,KAAsC,CAA1C,EACE,MAAM,IAAIjW,KAAJ,CAAU,qCACAzC,KAAK0Y,4BADf,CAAN,CAJuB,CAMzB;AACA;;AACA1Y,SAAKgZ,UAAL,CAAgBzC,OAAhB,CAAwB,YAAY;AAClCvW,WAAKwZ,UAAL;AACD,KAFD;AAGD,GA7CsC;AA+CvCA,cAAY,YAAY;AACtB,QAAIxZ,OAAO,IAAX;AACA,MAAEA,KAAK0Y,4BAAP;AAEA,QAAI1Y,KAAK8R,QAAT,EACE;AAEF,QAAI6H,QAAQ,KAAZ;AACA,QAAIC,UAAJ;AACA,QAAIC,aAAa7Z,KAAKyY,QAAtB;;AACA,QAAI,CAACoB,UAAL,EAAiB;AACfF,cAAQ,IAAR,CADe,CAEf;;AACAE,mBAAa7Z,KAAKyV,QAAL,GAAgB,EAAhB,GAAqB,IAAI9Q,gBAAgBmI,MAApB,EAAlC;AACD;;AAED9M,SAAKqP,qBAAL,IAA8BrP,KAAKqP,qBAAL,EAA9B,CAhBsB,CAkBtB;;AACA,QAAIyK,iBAAiB9Z,KAAK2Y,cAA1B;AACA3Y,SAAK2Y,cAAL,GAAsB,EAAtB,CApBsB,CAsBtB;;AACA,QAAI;AACFiB,mBAAa5Z,KAAK+J,kBAAL,CAAwByD,aAAxB,CAAsCxN,KAAKyV,QAA3C,CAAb;AACD,KAFD,CAEE,OAAOhR,CAAP,EAAU;AACV,UAAIkV,SAAS,OAAOlV,EAAEsV,IAAT,KAAmB,QAAhC,EAA0C;AACxC;AACA;AACA;AACA;AACA;AACA/Z,aAAK4X,YAAL,CAAkBb,UAAlB,CACE,IAAItU,KAAJ,CACE,mCACEyS,KAAK1G,SAAL,CAAexO,KAAK8J,kBAApB,CADF,GAC4C,IAD5C,GACmDrF,EAAEuV,OAFvD,CADF;;AAIA;AACD,OAZS,CAcV;AACA;AACA;AACA;AACA;AACA;;;AACAC,YAAMjc,SAAN,CAAgBqP,IAAhB,CAAqB1E,KAArB,CAA2B3I,KAAK2Y,cAAhC,EAAgDmB,cAAhD;;AACAxY,aAAOiS,MAAP,CAAc,mCACA2B,KAAK1G,SAAL,CAAexO,KAAK8J,kBAApB,CADd,EACuDrF,CADvD;;AAEA;AACD,KAjDqB,CAmDtB;;;AACA,QAAI,CAACzE,KAAK8R,QAAV,EAAoB;AAClBnN,sBAAgBuV,iBAAhB,CACEla,KAAKyV,QADP,EACiBoE,UADjB,EAC6BD,UAD7B,EACyC5Z,KAAK4X,YAD9C;AAED,KAvDqB,CAyDtB;AACA;AACA;;;AACA,QAAI+B,KAAJ,EACE3Z,KAAK4X,YAAL,CAAkBf,KAAlB,GA7DoB,CA+DtB;AACA;AACA;;AACA7W,SAAKyY,QAAL,GAAgBmB,UAAhB,CAlEsB,CAoEtB;AACA;AACA;AACA;;AACA5Z,SAAK4X,YAAL,CAAkBX,OAAlB,CAA0B,YAAY;AACpC1Z,QAAEK,IAAF,CAAOkc,cAAP,EAAuB,UAAUK,CAAV,EAAa;AAClCA,UAAEtW,SAAF;AACD,OAFD;AAGD,KAJD;AAKD,GA5HsC;AA8HvClB,QAAM,YAAY;AAChB,QAAI3C,OAAO,IAAX;AACAA,SAAK8R,QAAL,GAAgB,IAAhB;;AACAvU,MAAEK,IAAF,CAAOoC,KAAKwY,cAAZ,EAA4B,UAAU4B,CAAV,EAAa;AAAEA;AAAM,KAAjD,EAHgB,CAIhB;;;AACA7c,MAAEK,IAAF,CAAOoC,KAAK2Y,cAAZ,EAA4B,UAAUwB,CAAV,EAAa;AACvCA,QAAEtW,SAAF;AACD,KAFD;;AAGAzB,YAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,yBADK,EACsB,CAAC,CADvB,CAAzB;AAED;AAxIsC,CAAzC,E;;;;;;;;;;;ACjFA,IAAI/Y,SAASC,IAAIC,OAAJ,CAAY,eAAZ,CAAb;;AAEA,IAAI0d,QAAQ;AACVC,YAAU,UADA;AAEVC,YAAU,UAFA;AAGVC,UAAQ;AAHE,CAAZ,C,CAMA;AACA;;AACA,IAAIC,kBAAkB,YAAY,CAAE,CAApC;;AACA,IAAIC,0BAA0B,UAAU/K,CAAV,EAAa;AACzC,SAAO,YAAY;AACjB,QAAI;AACFA,QAAEhH,KAAF,CAAQ,IAAR,EAAcC,SAAd;AACD,KAFD,CAEE,OAAOnE,CAAP,EAAU;AACV,UAAI,EAAEA,aAAagW,eAAf,CAAJ,EACE,MAAMhW,CAAN;AACH;AACF,GAPD;AAQD,CATD;;AAWA,IAAIkW,YAAY,CAAhB,C,CAEA;AACA;AACA;AACA;AACA;;AACAnL,qBAAqB,UAAUzP,OAAV,EAAmB;AACtC,MAAIC,OAAO,IAAX;AACAA,OAAK4a,UAAL,GAAkB,IAAlB,CAFsC,CAEb;;AAEzB5a,OAAK8E,GAAL,GAAW6V,SAAX;AACAA;AAEA3a,OAAK8J,kBAAL,GAA0B/J,QAAQ6J,iBAAlC;AACA5J,OAAKuY,YAAL,GAAoBxY,QAAQ+P,WAA5B;AACA9P,OAAK4X,YAAL,GAAoB7X,QAAQ0O,WAA5B;;AAEA,MAAI1O,QAAQkL,OAAZ,EAAqB;AACnB,UAAMxI,MAAM,2DAAN,CAAN;AACD;;AAED,MAAIyM,SAASnP,QAAQmP,MAArB,CAfsC,CAgBtC;AACA;;AACA,MAAI2L,aAAa3L,UAAUA,OAAO4L,aAAP,EAA3B;;AAEA,MAAI/a,QAAQ6J,iBAAR,CAA0B7J,OAA1B,CAAkCkJ,KAAtC,EAA6C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,QAAI8R,cAAc;AAAEC,aAAOrW,gBAAgBmI;AAAzB,KAAlB;AACA9M,SAAKib,MAAL,GAAcjb,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCkJ,KAA9C;AACAjJ,SAAKkb,WAAL,GAAmBL,UAAnB;AACA7a,SAAKmb,OAAL,GAAejM,MAAf;AACAlP,SAAKob,kBAAL,GAA0B,IAAIC,UAAJ,CAAeR,UAAf,EAA2BE,WAA3B,CAA1B,CAd2C,CAe3C;;AACA/a,SAAKsb,UAAL,GAAkB,IAAIC,OAAJ,CAAYV,UAAZ,EAAwBE,WAAxB,CAAlB;AACD,GAjBD,MAiBO;AACL/a,SAAKib,MAAL,GAAc,CAAd;AACAjb,SAAKkb,WAAL,GAAmB,IAAnB;AACAlb,SAAKmb,OAAL,GAAe,IAAf;AACAnb,SAAKob,kBAAL,GAA0B,IAA1B;AACApb,SAAKsb,UAAL,GAAkB,IAAI3W,gBAAgBmI,MAApB,EAAlB;AACD,GA3CqC,CA6CtC;AACA;AACA;;;AACA9M,OAAKwb,mBAAL,GAA2B,KAA3B;AAEAxb,OAAK8R,QAAL,GAAgB,KAAhB;AACA9R,OAAKyb,YAAL,GAAoB,EAApB;AAEArZ,UAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,uBADK,EACoB,CADpB,CAAzB;;AAGAxV,OAAK0b,oBAAL,CAA0BrB,MAAMC,QAAhC;;AAEAta,OAAK2b,QAAL,GAAgB5b,QAAQkP,OAAxB;AACA,MAAI2M,aAAa5b,KAAK8J,kBAAL,CAAwB/J,OAAxB,CAAgCiM,MAAhC,IAA0C,EAA3D;AACAhM,OAAK6b,aAAL,GAAqBlX,gBAAgBmX,kBAAhB,CAAmCF,UAAnC,CAArB,CA5DsC,CA6DtC;AACA;;AACA5b,OAAK+b,iBAAL,GAAyB/b,KAAK2b,QAAL,CAAcK,qBAAd,CAAoCJ,UAApC,CAAzB;AACA,MAAI1M,MAAJ,EACElP,KAAK+b,iBAAL,GAAyB7M,OAAO8M,qBAAP,CAA6Bhc,KAAK+b,iBAAlC,CAAzB;AACF/b,OAAKic,mBAAL,GAA2BtX,gBAAgBmX,kBAAhB,CACzB9b,KAAK+b,iBADoB,CAA3B;AAGA/b,OAAKkc,YAAL,GAAoB,IAAIvX,gBAAgBmI,MAApB,EAApB;AACA9M,OAAKmc,kBAAL,GAA0B,IAA1B;AACAnc,OAAKoc,gBAAL,GAAwB,CAAxB;AAEApc,OAAKqc,yBAAL,GAAiC,KAAjC;AACArc,OAAKsc,gCAAL,GAAwC,EAAxC,CA1EsC,CA4EtC;AACA;;AACAtc,OAAKyb,YAAL,CAAkBpO,IAAlB,CAAuBrN,KAAKuY,YAAL,CAAkBrX,YAAlB,CAA+BuS,gBAA/B,CACrBiH,wBAAwB,YAAY;AAClC1a,SAAKuc,gBAAL;AACD,GAFD,CADqB,CAAvB;;AAMAnM,iBAAepQ,KAAK8J,kBAApB,EAAwC,UAAUuG,OAAV,EAAmB;AACzDrQ,SAAKyb,YAAL,CAAkBpO,IAAlB,CAAuBrN,KAAKuY,YAAL,CAAkBrX,YAAlB,CAA+BkS,YAA/B,CACrB/C,OADqB,EACZ,UAAUiD,YAAV,EAAwB;AAC/BhS,aAAOsN,gBAAP,CAAwB8L,wBAAwB,YAAY;AAC1D,YAAIpJ,KAAKgC,aAAahC,EAAtB;;AACA,YAAIgC,aAAavN,cAAb,IAA+BuN,aAAapN,YAAhD,EAA8D;AAC5D;AACA;AACA;AACAlG,eAAKuc,gBAAL;AACD,SALD,MAKO;AACL;AACA,cAAIvc,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EAAoC;AAClCta,iBAAKyc,yBAAL,CAA+BnL,EAA/B;AACD,WAFD,MAEO;AACLtR,iBAAK0c,iCAAL,CAAuCpL,EAAvC;AACD;AACF;AACF,OAfuB,CAAxB;AAgBD,KAlBoB,CAAvB;AAoBD,GArBD,EApFsC,CA2GtC;;AACAtR,OAAKyb,YAAL,CAAkBpO,IAAlB,CAAuB4C,UACrBjQ,KAAK8J,kBADgB,EACI,UAAUwJ,YAAV,EAAwB;AAC/C;AACA,QAAI9P,QAAQC,UAAUC,kBAAV,CAA6BC,GAA7B,EAAZ;;AACA,QAAI,CAACH,KAAD,IAAUA,MAAMmZ,KAApB,EACE;;AAEF,QAAInZ,MAAMoZ,oBAAV,EAAgC;AAC9BpZ,YAAMoZ,oBAAN,CAA2B5c,KAAK8E,GAAhC,IAAuC9E,IAAvC;AACA;AACD;;AAEDwD,UAAMoZ,oBAAN,GAA6B,EAA7B;AACApZ,UAAMoZ,oBAAN,CAA2B5c,KAAK8E,GAAhC,IAAuC9E,IAAvC;AAEAwD,UAAMqZ,YAAN,CAAmB,YAAY;AAC7B,UAAIC,UAAUtZ,MAAMoZ,oBAApB;AACA,aAAOpZ,MAAMoZ,oBAAb,CAF6B,CAI7B;AACA;;AACA5c,WAAKuY,YAAL,CAAkBrX,YAAlB,CAA+BwS,iBAA/B;;AAEAnW,QAAEK,IAAF,CAAOkf,OAAP,EAAgB,UAAUC,MAAV,EAAkB;AAChC,YAAIA,OAAOjL,QAAX,EACE;AAEF,YAAI7N,QAAQT,MAAMI,UAAN,EAAZ;;AACA,YAAImZ,OAAOP,MAAP,KAAkBnC,MAAMG,MAA5B,EAAoC;AAClC;AACA;AACA;AACAuC,iBAAOnF,YAAP,CAAoBX,OAApB,CAA4B,YAAY;AACtChT,kBAAMJ,SAAN;AACD,WAFD;AAGD,SAPD,MAOO;AACLkZ,iBAAOT,gCAAP,CAAwCjP,IAAxC,CAA6CpJ,KAA7C;AACD;AACF,OAfD;AAgBD,KAxBD;AAyBD,GAxCoB,CAAvB,EA5GsC,CAuJtC;AACA;;;AACAjE,OAAKyb,YAAL,CAAkBpO,IAAlB,CAAuBrN,KAAKuY,YAAL,CAAkBzU,WAAlB,CAA8B4W,wBACnD,YAAY;AACV1a,SAAKuc,gBAAL;AACD,GAHkD,CAA9B,CAAvB,EAzJsC,CA8JtC;AACA;;;AACAjb,SAAO+M,KAAP,CAAaqM,wBAAwB,YAAY;AAC/C1a,SAAKgd,gBAAL;AACD,GAFY,CAAb;AAGD,CAnKD;;AAqKAzf,EAAE+H,MAAF,CAASkK,mBAAmBxR,SAA5B,EAAuC;AACrCif,iBAAe,UAAUpY,EAAV,EAAc/C,GAAd,EAAmB;AAChC,QAAI9B,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI5C,SAASzO,EAAEU,KAAF,CAAQ6D,GAAR,CAAb;;AACA,aAAOkK,OAAOlH,GAAd;;AACA9E,WAAKsb,UAAL,CAAgBtO,GAAhB,CAAoBnI,EAApB,EAAwB7E,KAAKic,mBAAL,CAAyBna,GAAzB,CAAxB;;AACA9B,WAAK4X,YAAL,CAAkBjH,KAAlB,CAAwB9L,EAAxB,EAA4B7E,KAAK6b,aAAL,CAAmB7P,MAAnB,CAA5B,EAJkC,CAMlC;AACA;AACA;AACA;;;AACA,UAAIhM,KAAKib,MAAL,IAAejb,KAAKsb,UAAL,CAAgBxc,IAAhB,KAAyBkB,KAAKib,MAAjD,EAAyD;AACvD;AACA,YAAIjb,KAAKsb,UAAL,CAAgBxc,IAAhB,OAA2BkB,KAAKib,MAAL,GAAc,CAA7C,EAAgD;AAC9C,gBAAM,IAAIxY,KAAJ,CAAU,iCACCzC,KAAKsb,UAAL,CAAgBxc,IAAhB,KAAyBkB,KAAKib,MAD/B,IAEA,oCAFV,CAAN;AAGD;;AAED,YAAIiC,mBAAmBld,KAAKsb,UAAL,CAAgB6B,YAAhB,EAAvB;;AACA,YAAIC,iBAAiBpd,KAAKsb,UAAL,CAAgB3X,GAAhB,CAAoBuZ,gBAApB,CAArB;;AAEA,YAAIne,MAAMse,MAAN,CAAaH,gBAAb,EAA+BrY,EAA/B,CAAJ,EAAwC;AACtC,gBAAM,IAAIpC,KAAJ,CAAU,0DAAV,CAAN;AACD;;AAEDzC,aAAKsb,UAAL,CAAgB1V,MAAhB,CAAuBsX,gBAAvB;;AACAld,aAAK4X,YAAL,CAAkB0F,OAAlB,CAA0BJ,gBAA1B;;AACAld,aAAKud,YAAL,CAAkBL,gBAAlB,EAAoCE,cAApC;AACD;AACF,KA7BD;AA8BD,GAjCoC;AAkCrCI,oBAAkB,UAAU3Y,EAAV,EAAc;AAC9B,QAAI7E,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAKsb,UAAL,CAAgB1V,MAAhB,CAAuBf,EAAvB;;AACA7E,WAAK4X,YAAL,CAAkB0F,OAAlB,CAA0BzY,EAA1B;;AACA,UAAI,CAAE7E,KAAKib,MAAP,IAAiBjb,KAAKsb,UAAL,CAAgBxc,IAAhB,OAA2BkB,KAAKib,MAArD,EACE;AAEF,UAAIjb,KAAKsb,UAAL,CAAgBxc,IAAhB,KAAyBkB,KAAKib,MAAlC,EACE,MAAMxY,MAAM,6BAAN,CAAN,CAPgC,CASlC;AACA;;AAEA,UAAI,CAACzC,KAAKob,kBAAL,CAAwBqC,KAAxB,EAAL,EAAsC;AACpC;AACA;AACA,YAAIC,WAAW1d,KAAKob,kBAAL,CAAwBuC,YAAxB,EAAf;;AACA,YAAI3W,SAAShH,KAAKob,kBAAL,CAAwBzX,GAAxB,CAA4B+Z,QAA5B,CAAb;;AACA1d,aAAK4d,eAAL,CAAqBF,QAArB;;AACA1d,aAAKid,aAAL,CAAmBS,QAAnB,EAA6B1W,MAA7B;;AACA;AACD,OApBiC,CAsBlC;AAEA;AACA;AACA;AACA;AACA;;;AACA,UAAIhH,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EACE,OA9BgC,CAgClC;AACA;AACA;AACA;;AACA,UAAIta,KAAKwb,mBAAT,EACE,OArCgC,CAuClC;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAM,IAAI/Y,KAAJ,CAAU,2BAAV,CAAN;AACD,KA/CD;AAgDD,GApFoC;AAqFrCob,oBAAkB,UAAUhZ,EAAV,EAAciZ,MAAd,EAAsB9W,MAAtB,EAA8B;AAC9C,QAAIhH,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAKsb,UAAL,CAAgBtO,GAAhB,CAAoBnI,EAApB,EAAwB7E,KAAKic,mBAAL,CAAyBjV,MAAzB,CAAxB;;AACA,UAAI+W,eAAe/d,KAAK6b,aAAL,CAAmB7U,MAAnB,CAAnB;;AACA,UAAIgX,eAAehe,KAAK6b,aAAL,CAAmBiC,MAAnB,CAAnB;;AACA,UAAIG,UAAUC,aAAaC,iBAAb,CACZJ,YADY,EACEC,YADF,CAAd;AAEA,UAAI,CAACzgB,EAAEsX,OAAF,CAAUoJ,OAAV,CAAL,EACEje,KAAK4X,YAAL,CAAkBqG,OAAlB,CAA0BpZ,EAA1B,EAA8BoZ,OAA9B;AACH,KARD;AASD,GAhGoC;AAiGrCV,gBAAc,UAAU1Y,EAAV,EAAc/C,GAAd,EAAmB;AAC/B,QAAI9B,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAKob,kBAAL,CAAwBpO,GAAxB,CAA4BnI,EAA5B,EAAgC7E,KAAKic,mBAAL,CAAyBna,GAAzB,CAAhC,EADkC,CAGlC;;;AACA,UAAI9B,KAAKob,kBAAL,CAAwBtc,IAAxB,KAAiCkB,KAAKib,MAA1C,EAAkD;AAChD,YAAImD,gBAAgBpe,KAAKob,kBAAL,CAAwB+B,YAAxB,EAApB;;AAEAnd,aAAKob,kBAAL,CAAwBxV,MAAxB,CAA+BwY,aAA/B,EAHgD,CAKhD;AACA;;;AACApe,aAAKwb,mBAAL,GAA2B,KAA3B;AACD;AACF,KAbD;AAcD,GAjHoC;AAkHrC;AACA;AACAoC,mBAAiB,UAAU/Y,EAAV,EAAc;AAC7B,QAAI7E,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAKob,kBAAL,CAAwBxV,MAAxB,CAA+Bf,EAA/B,EADkC,CAElC;AACA;AACA;;;AACA,UAAI,CAAE7E,KAAKob,kBAAL,CAAwBtc,IAAxB,EAAF,IAAoC,CAAEkB,KAAKwb,mBAA/C,EACExb,KAAKuc,gBAAL;AACH,KAPD;AAQD,GA9HoC;AA+HrC;AACA;AACA;AACA8B,gBAAc,UAAUvc,GAAV,EAAe;AAC3B,QAAI9B,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI/J,KAAK/C,IAAIgD,GAAb;AACA,UAAI9E,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAJ,EACE,MAAMpC,MAAM,8CAA8CoC,EAApD,CAAN;AACF,UAAI7E,KAAKib,MAAL,IAAejb,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CAAnB,EACE,MAAMpC,MAAM,sDAAsDoC,EAA5D,CAAN;AAEF,UAAIoE,QAAQjJ,KAAKib,MAAjB;AACA,UAAIJ,aAAa7a,KAAKkb,WAAtB;AACA,UAAIoD,eAAgBrV,SAASjJ,KAAKsb,UAAL,CAAgBxc,IAAhB,KAAyB,CAAnC,GACjBkB,KAAKsb,UAAL,CAAgB3X,GAAhB,CAAoB3D,KAAKsb,UAAL,CAAgB6B,YAAhB,EAApB,CADiB,GACqC,IADxD;AAEA,UAAIoB,cAAetV,SAASjJ,KAAKob,kBAAL,CAAwBtc,IAAxB,KAAiC,CAA3C,GACdkB,KAAKob,kBAAL,CAAwBzX,GAAxB,CAA4B3D,KAAKob,kBAAL,CAAwB+B,YAAxB,EAA5B,CADc,GAEd,IAFJ,CAXkC,CAclC;AACA;AACA;;AACA,UAAIqB,YAAY,CAAEvV,KAAF,IAAWjJ,KAAKsb,UAAL,CAAgBxc,IAAhB,KAAyBmK,KAApC,IACd4R,WAAW/Y,GAAX,EAAgBwc,YAAhB,IAAgC,CADlC,CAjBkC,CAoBlC;AACA;AACA;;AACA,UAAIG,oBAAoB,CAACD,SAAD,IAAcxe,KAAKwb,mBAAnB,IACtBxb,KAAKob,kBAAL,CAAwBtc,IAAxB,KAAiCmK,KADnC,CAvBkC,CA0BlC;AACA;;AACA,UAAIyV,sBAAsB,CAACF,SAAD,IAAcD,WAAd,IACxB1D,WAAW/Y,GAAX,EAAgByc,WAAhB,KAAgC,CADlC;AAGA,UAAII,WAAWF,qBAAqBC,mBAApC;;AAEA,UAAIF,SAAJ,EAAe;AACbxe,aAAKid,aAAL,CAAmBpY,EAAnB,EAAuB/C,GAAvB;AACD,OAFD,MAEO,IAAI6c,QAAJ,EAAc;AACnB3e,aAAKud,YAAL,CAAkB1Y,EAAlB,EAAsB/C,GAAtB;AACD,OAFM,MAEA;AACL;AACA9B,aAAKwb,mBAAL,GAA2B,KAA3B;AACD;AACF,KAzCD;AA0CD,GA9KoC;AA+KrC;AACA;AACA;AACAoD,mBAAiB,UAAU/Z,EAAV,EAAc;AAC7B,QAAI7E,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI,CAAE5O,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAF,IAA6B,CAAE7E,KAAKib,MAAxC,EACE,MAAMxY,MAAM,uDAAuDoC,EAA7D,CAAN;;AAEF,UAAI7E,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAJ,EAA6B;AAC3B7E,aAAKwd,gBAAL,CAAsB3Y,EAAtB;AACD,OAFD,MAEO,IAAI7E,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CAAJ,EAAqC;AAC1C7E,aAAK4d,eAAL,CAAqB/Y,EAArB;AACD;AACF,KATD;AAUD,GA9LoC;AA+LrCga,cAAY,UAAUha,EAAV,EAAcmC,MAAd,EAAsB;AAChC,QAAIhH,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAIkQ,aAAa9X,UAAUhH,KAAK2b,QAAL,CAAcoD,eAAd,CAA8B/X,MAA9B,EAAsC7C,MAAjE;;AAEA,UAAI6a,kBAAkBhf,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAtB;;AACA,UAAIoa,iBAAiBjf,KAAKib,MAAL,IAAejb,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CAApC;;AACA,UAAIqa,eAAeF,mBAAmBC,cAAtC;;AAEA,UAAIH,cAAc,CAACI,YAAnB,EAAiC;AAC/Blf,aAAKqe,YAAL,CAAkBrX,MAAlB;AACD,OAFD,MAEO,IAAIkY,gBAAgB,CAACJ,UAArB,EAAiC;AACtC9e,aAAK4e,eAAL,CAAqB/Z,EAArB;AACD,OAFM,MAEA,IAAIqa,gBAAgBJ,UAApB,EAAgC;AACrC,YAAIhB,SAAS9d,KAAKsb,UAAL,CAAgB3X,GAAhB,CAAoBkB,EAApB,CAAb;;AACA,YAAIgW,aAAa7a,KAAKkb,WAAtB;;AACA,YAAIiE,cAAcnf,KAAKib,MAAL,IAAejb,KAAKob,kBAAL,CAAwBtc,IAAxB,EAAf,IAChBkB,KAAKob,kBAAL,CAAwBzX,GAAxB,CAA4B3D,KAAKob,kBAAL,CAAwBuC,YAAxB,EAA5B,CADF;;AAEA,YAAIY,WAAJ;;AAEA,YAAIS,eAAJ,EAAqB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAII,mBAAmB,CAAEpf,KAAKib,MAAP,IACrBjb,KAAKob,kBAAL,CAAwBtc,IAAxB,OAAmC,CADd,IAErB+b,WAAW7T,MAAX,EAAmBmY,WAAnB,KAAmC,CAFrC;;AAIA,cAAIC,gBAAJ,EAAsB;AACpBpf,iBAAK6d,gBAAL,CAAsBhZ,EAAtB,EAA0BiZ,MAA1B,EAAkC9W,MAAlC;AACD,WAFD,MAEO;AACL;AACAhH,iBAAKwd,gBAAL,CAAsB3Y,EAAtB,EAFK,CAGL;;;AACA0Z,0BAAcve,KAAKob,kBAAL,CAAwBzX,GAAxB,CACZ3D,KAAKob,kBAAL,CAAwB+B,YAAxB,EADY,CAAd;AAGA,gBAAIwB,WAAW3e,KAAKwb,mBAAL,IACR+C,eAAe1D,WAAW7T,MAAX,EAAmBuX,WAAnB,KAAmC,CADzD;;AAGA,gBAAII,QAAJ,EAAc;AACZ3e,mBAAKud,YAAL,CAAkB1Y,EAAlB,EAAsBmC,MAAtB;AACD,aAFD,MAEO;AACL;AACAhH,mBAAKwb,mBAAL,GAA2B,KAA3B;AACD;AACF;AACF,SAjCD,MAiCO,IAAIyD,cAAJ,EAAoB;AACzBnB,mBAAS9d,KAAKob,kBAAL,CAAwBzX,GAAxB,CAA4BkB,EAA5B,CAAT,CADyB,CAEzB;AACA;AACA;AACA;;AACA7E,eAAKob,kBAAL,CAAwBxV,MAAxB,CAA+Bf,EAA/B;;AAEA,cAAIyZ,eAAete,KAAKsb,UAAL,CAAgB3X,GAAhB,CACjB3D,KAAKsb,UAAL,CAAgB6B,YAAhB,EADiB,CAAnB;;AAEAoB,wBAAcve,KAAKob,kBAAL,CAAwBtc,IAAxB,MACRkB,KAAKob,kBAAL,CAAwBzX,GAAxB,CACE3D,KAAKob,kBAAL,CAAwB+B,YAAxB,EADF,CADN,CAVyB,CAczB;;AACA,cAAIqB,YAAY3D,WAAW7T,MAAX,EAAmBsX,YAAnB,IAAmC,CAAnD,CAfyB,CAiBzB;;AACA,cAAIe,gBAAiB,CAAEb,SAAF,IAAexe,KAAKwb,mBAArB,IACb,CAACgD,SAAD,IAAcD,WAAd,IACA1D,WAAW7T,MAAX,EAAmBuX,WAAnB,KAAmC,CAF1C;;AAIA,cAAIC,SAAJ,EAAe;AACbxe,iBAAKid,aAAL,CAAmBpY,EAAnB,EAAuBmC,MAAvB;AACD,WAFD,MAEO,IAAIqY,aAAJ,EAAmB;AACxB;AACArf,iBAAKob,kBAAL,CAAwBpO,GAAxB,CAA4BnI,EAA5B,EAAgCmC,MAAhC;AACD,WAHM,MAGA;AACL;AACAhH,iBAAKwb,mBAAL,GAA2B,KAA3B,CAFK,CAGL;AACA;;AACA,gBAAI,CAAExb,KAAKob,kBAAL,CAAwBtc,IAAxB,EAAN,EAAsC;AACpCkB,mBAAKuc,gBAAL;AACD;AACF;AACF,SApCM,MAoCA;AACL,gBAAM,IAAI9Z,KAAJ,CAAU,2EAAV,CAAN;AACD;AACF;AACF,KA3FD;AA4FD,GA7RoC;AA8RrC6c,2BAAyB,YAAY;AACnC,QAAItf,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAK0b,oBAAL,CAA0BrB,MAAME,QAAhC,EADkC,CAElC;AACA;;;AACAjZ,aAAO+M,KAAP,CAAaqM,wBAAwB,YAAY;AAC/C,eAAO,CAAC1a,KAAK8R,QAAN,IAAkB,CAAC9R,KAAKkc,YAAL,CAAkBuB,KAAlB,EAA1B,EAAqD;AACnD,cAAIzd,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EAAoC;AAClC;AACA;AACA;AACA;AACD,WANkD,CAQnD;;;AACA,cAAIta,KAAKwc,MAAL,KAAgBnC,MAAME,QAA1B,EACE,MAAM,IAAI9X,KAAJ,CAAU,sCAAsCzC,KAAKwc,MAArD,CAAN;AAEFxc,eAAKmc,kBAAL,GAA0Bnc,KAAKkc,YAA/B;AACA,cAAIqD,iBAAiB,EAAEvf,KAAKoc,gBAA5B;AACApc,eAAKkc,YAAL,GAAoB,IAAIvX,gBAAgBmI,MAApB,EAApB;AACA,cAAI0S,UAAU,CAAd;AACA,cAAIC,MAAM,IAAIhjB,MAAJ,EAAV,CAhBmD,CAiBnD;AACA;;AACAuD,eAAKmc,kBAAL,CAAwB/Q,OAAxB,CAAgC,UAAU8M,QAAV,EAAoBrT,EAApB,EAAwB;AACtD2a;;AACAxf,iBAAKuY,YAAL,CAAkBpX,WAAlB,CAA8B+H,KAA9B,CACElJ,KAAK8J,kBAAL,CAAwBhH,cAD1B,EAC0C+B,EAD1C,EAC8CqT,QAD9C,EAEEwC,wBAAwB,UAAUlZ,GAAV,EAAeM,GAAf,EAAoB;AAC1C,kBAAI;AACF,oBAAIN,GAAJ,EAAS;AACPF,yBAAOiS,MAAP,CAAc,wCAAd,EACc/R,GADd,EADO,CAGP;AACA;AACA;AACA;;;AACA,sBAAIxB,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EAAoC;AAClCta,yBAAKuc,gBAAL;AACD;AACF,iBAVD,MAUO,IAAI,CAACvc,KAAK8R,QAAN,IAAkB9R,KAAKwc,MAAL,KAAgBnC,MAAME,QAAxC,IACGva,KAAKoc,gBAAL,KAA0BmD,cADjC,EACiD;AACtD;AACA;AACA;AACA;AACAvf,uBAAK6e,UAAL,CAAgBha,EAAhB,EAAoB/C,GAApB;AACD;AACF,eAnBD,SAmBU;AACR0d,0BADQ,CAER;AACA;AACA;;AACA,oBAAIA,YAAY,CAAhB,EACEC,IAAI7K,MAAJ;AACH;AACF,aA5BD,CAFF;AA+BD,WAjCD;;AAkCA6K,cAAIvd,IAAJ,GArDmD,CAsDnD;;AACA,cAAIlC,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EACE;AACFta,eAAKmc,kBAAL,GAA0B,IAA1B;AACD,SA3D8C,CA4D/C;AACA;;;AACA,YAAInc,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EACEta,KAAK0f,SAAL;AACH,OAhEY,CAAb;AAiED,KArED;AAsED,GAtWoC;AAuWrCA,aAAW,YAAY;AACrB,QAAI1f,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAK0b,oBAAL,CAA0BrB,MAAMG,MAAhC;;AACA,UAAImF,SAAS3f,KAAKsc,gCAAlB;AACAtc,WAAKsc,gCAAL,GAAwC,EAAxC;;AACAtc,WAAK4X,YAAL,CAAkBX,OAAlB,CAA0B,YAAY;AACpC1Z,UAAEK,IAAF,CAAO+hB,MAAP,EAAe,UAAUxF,CAAV,EAAa;AAC1BA,YAAEtW,SAAF;AACD,SAFD;AAGD,OAJD;AAKD,KATD;AAUD,GAnXoC;AAoXrC4Y,6BAA2B,UAAUnL,EAAV,EAAc;AACvC,QAAItR,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC5O,WAAKkc,YAAL,CAAkBlP,GAAlB,CAAsBqE,QAAQC,EAAR,CAAtB,EAAmCA,GAAGzF,EAAH,CAAM+T,QAAN,EAAnC;AACD,KAFD;AAGD,GAzXoC;AA0XrClD,qCAAmC,UAAUpL,EAAV,EAAc;AAC/C,QAAItR,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI/J,KAAKwM,QAAQC,EAAR,CAAT,CADkC,CAElC;AACA;;AACA,UAAItR,KAAKwc,MAAL,KAAgBnC,MAAME,QAAtB,KACEva,KAAKmc,kBAAL,IAA2Bnc,KAAKmc,kBAAL,CAAwBrb,GAAxB,CAA4B+D,EAA5B,CAA5B,IACA7E,KAAKkc,YAAL,CAAkBpb,GAAlB,CAAsB+D,EAAtB,CAFD,CAAJ,EAEiC;AAC/B7E,aAAKkc,YAAL,CAAkBlP,GAAlB,CAAsBnI,EAAtB,EAA0ByM,GAAGzF,EAAH,CAAM+T,QAAN,EAA1B;;AACA;AACD;;AAED,UAAItO,GAAGA,EAAH,KAAU,GAAd,EAAmB;AACjB,YAAItR,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,KACC7E,KAAKib,MAAL,IAAejb,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CADpB,EAEE7E,KAAK4e,eAAL,CAAqB/Z,EAArB;AACH,OAJD,MAIO,IAAIyM,GAAGA,EAAH,KAAU,GAAd,EAAmB;AACxB,YAAItR,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAJ,EACE,MAAM,IAAIpC,KAAJ,CAAU,mDAAV,CAAN;AACF,YAAIzC,KAAKob,kBAAL,IAA2Bpb,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CAA/B,EACE,MAAM,IAAIpC,KAAJ,CAAU,gDAAV,CAAN,CAJsB,CAMxB;AACA;;AACA,YAAIzC,KAAK2b,QAAL,CAAcoD,eAAd,CAA8BzN,GAAGC,CAAjC,EAAoCpN,MAAxC,EACEnE,KAAKqe,YAAL,CAAkB/M,GAAGC,CAArB;AACH,OAVM,MAUA,IAAID,GAAGA,EAAH,KAAU,GAAd,EAAmB;AACxB;AACA;AACA;AACA;AACA,YAAIuO,YAAY,CAACtiB,EAAEuD,GAAF,CAAMwQ,GAAGC,CAAT,EAAY,MAAZ,CAAD,IAAwB,CAAChU,EAAEuD,GAAF,CAAMwQ,GAAGC,CAAT,EAAY,QAAZ,CAAzC,CALwB,CAMxB;AACA;AACA;AACA;;AACA,YAAIuO,uBACF,CAACD,SAAD,IAAcE,6BAA6BzO,GAAGC,CAAhC,CADhB;;AAGA,YAAIyN,kBAAkBhf,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,CAAtB;;AACA,YAAIoa,iBAAiBjf,KAAKib,MAAL,IAAejb,KAAKob,kBAAL,CAAwBta,GAAxB,CAA4B+D,EAA5B,CAApC;;AAEA,YAAIgb,SAAJ,EAAe;AACb7f,eAAK6e,UAAL,CAAgBha,EAAhB,EAAoBtH,EAAE+H,MAAF,CAAS;AAACR,iBAAKD;AAAN,WAAT,EAAoByM,GAAGC,CAAvB,CAApB;AACD,SAFD,MAEO,IAAI,CAACyN,mBAAmBC,cAApB,KACAa,oBADJ,EAC0B;AAC/B;AACA;AACA,cAAI9Y,SAAShH,KAAKsb,UAAL,CAAgBxa,GAAhB,CAAoB+D,EAApB,IACT7E,KAAKsb,UAAL,CAAgB3X,GAAhB,CAAoBkB,EAApB,CADS,GACiB7E,KAAKob,kBAAL,CAAwBzX,GAAxB,CAA4BkB,EAA5B,CAD9B;AAEAmC,mBAASjI,MAAMd,KAAN,CAAY+I,MAAZ,CAAT;AAEAA,iBAAOlC,GAAP,GAAaD,EAAb;;AACA,cAAI;AACFF,4BAAgBqb,OAAhB,CAAwBhZ,MAAxB,EAAgCsK,GAAGC,CAAnC;AACD,WAFD,CAEE,OAAO9M,CAAP,EAAU;AACV,gBAAIA,EAAEtG,IAAF,KAAW,gBAAf,EACE,MAAMsG,CAAN,CAFQ,CAGV;;AACAzE,iBAAKkc,YAAL,CAAkBlP,GAAlB,CAAsBnI,EAAtB,EAA0ByM,GAAGzF,EAAH,CAAM+T,QAAN,EAA1B;;AACA,gBAAI5f,KAAKwc,MAAL,KAAgBnC,MAAMG,MAA1B,EAAkC;AAChCxa,mBAAKsf,uBAAL;AACD;;AACD;AACD;;AACDtf,eAAK6e,UAAL,CAAgBha,EAAhB,EAAoB7E,KAAKic,mBAAL,CAAyBjV,MAAzB,CAApB;AACD,SAtBM,MAsBA,IAAI,CAAC8Y,oBAAD,IACA9f,KAAK2b,QAAL,CAAcsE,uBAAd,CAAsC3O,GAAGC,CAAzC,CADA,IAECvR,KAAKmb,OAAL,IAAgBnb,KAAKmb,OAAL,CAAa+E,kBAAb,CAAgC5O,GAAGC,CAAnC,CAFrB,EAE6D;AAClEvR,eAAKkc,YAAL,CAAkBlP,GAAlB,CAAsBnI,EAAtB,EAA0ByM,GAAGzF,EAAH,CAAM+T,QAAN,EAA1B;;AACA,cAAI5f,KAAKwc,MAAL,KAAgBnC,MAAMG,MAA1B,EACExa,KAAKsf,uBAAL;AACH;AACF,OA/CM,MA+CA;AACL,cAAM7c,MAAM,+BAA+B6O,EAArC,CAAN;AACD;AACF,KA3ED;AA4ED,GAxcoC;AAycrC;AACA0L,oBAAkB,YAAY;AAC5B,QAAIhd,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE,MAAM,IAAIrP,KAAJ,CAAU,kCAAV,CAAN;;AAEFzC,SAAKmgB,SAAL,CAAe;AAACC,eAAS;AAAV,KAAf,EAL4B,CAKM;;;AAElC,QAAIpgB,KAAK8R,QAAT,EACE,OAR0B,CAQjB;AAEX;AACA;;AACA9R,SAAK4X,YAAL,CAAkBf,KAAlB;;AAEA7W,SAAKqgB,aAAL,GAd4B,CAcL;;AACxB,GAzdoC;AA2drC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAC,cAAY,YAAY;AACtB,QAAItgB,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI5O,KAAK8R,QAAT,EACE,OAFgC,CAIlC;;AACA9R,WAAKkc,YAAL,GAAoB,IAAIvX,gBAAgBmI,MAApB,EAApB;AACA9M,WAAKmc,kBAAL,GAA0B,IAA1B;AACA,QAAEnc,KAAKoc,gBAAP,CAPkC,CAOR;;AAC1Bpc,WAAK0b,oBAAL,CAA0BrB,MAAMC,QAAhC,EARkC,CAUlC;AACA;;;AACAhZ,aAAO+M,KAAP,CAAa,YAAY;AACvBrO,aAAKmgB,SAAL;;AACAngB,aAAKqgB,aAAL;AACD,OAHD;AAID,KAhBD;AAiBD,GA5foC;AA8frC;AACAF,aAAW,UAAUpgB,OAAV,EAAmB;AAC5B,QAAIC,OAAO,IAAX;AACAD,cAAUA,WAAW,EAArB;AACA,QAAI6Z,UAAJ,EAAgB2G,SAAhB,CAH4B,CAK5B;;AACA,WAAO,IAAP,EAAa;AACX;AACA,UAAIvgB,KAAK8R,QAAT,EACE;AAEF8H,mBAAa,IAAIjV,gBAAgBmI,MAApB,EAAb;AACAyT,kBAAY,IAAI5b,gBAAgBmI,MAApB,EAAZ,CANW,CAQX;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAIgB,SAAS9N,KAAKwgB,eAAL,CAAqB;AAAEvX,eAAOjJ,KAAKib,MAAL,GAAc;AAAvB,OAArB,CAAb;;AACA,UAAI;AACFnN,eAAO1C,OAAP,CAAe,UAAUtJ,GAAV,EAAe2e,CAAf,EAAkB;AAAG;AAClC,cAAI,CAACzgB,KAAKib,MAAN,IAAgBwF,IAAIzgB,KAAKib,MAA7B,EAAqC;AACnCrB,uBAAW5M,GAAX,CAAelL,IAAIgD,GAAnB,EAAwBhD,GAAxB;AACD,WAFD,MAEO;AACLye,sBAAUvT,GAAV,CAAclL,IAAIgD,GAAlB,EAAuBhD,GAAvB;AACD;AACF,SAND;AAOA;AACD,OATD,CASE,OAAO2C,CAAP,EAAU;AACV,YAAI1E,QAAQqgB,OAAR,IAAmB,OAAO3b,EAAEsV,IAAT,KAAmB,QAA1C,EAAoD;AAClD;AACA;AACA;AACA;AACA;AACA/Z,eAAK4X,YAAL,CAAkBb,UAAlB,CAA6BtS,CAA7B;;AACA;AACD,SATS,CAWV;AACA;;;AACAnD,eAAOiS,MAAP,CAAc,mCAAd,EAAmD9O,CAAnD;;AACAnD,eAAOuS,WAAP,CAAmB,GAAnB;AACD;AACF;;AAED,QAAI7T,KAAK8R,QAAT,EACE;;AAEF9R,SAAK0gB,kBAAL,CAAwB9G,UAAxB,EAAoC2G,SAApC;AACD,GApjBoC;AAsjBrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAhE,oBAAkB,YAAY;AAC5B,QAAIvc,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI5O,KAAK8R,QAAT,EACE,OAFgC,CAIlC;AACA;;AACA,UAAI9R,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EAAoC;AAClCta,aAAKsgB,UAAL;;AACA,cAAM,IAAI7F,eAAJ,EAAN;AACD,OATiC,CAWlC;AACA;;;AACAza,WAAKqc,yBAAL,GAAiC,IAAjC;AACD,KAdD;AAeD,GAnlBoC;AAqlBrC;AACAgE,iBAAe,YAAY;AACzB,QAAIrgB,OAAO,IAAX;AAEA,QAAIA,KAAK8R,QAAT,EACE;;AACF9R,SAAKuY,YAAL,CAAkBrX,YAAlB,CAA+BwS,iBAA/B,GALyB,CAK4B;;;AACrD,QAAI1T,KAAK8R,QAAT,EACE;AACF,QAAI9R,KAAKwc,MAAL,KAAgBnC,MAAMC,QAA1B,EACE,MAAM7X,MAAM,wBAAwBzC,KAAKwc,MAAnC,CAAN;;AAEFlb,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAI5O,KAAKqc,yBAAT,EAAoC;AAClCrc,aAAKqc,yBAAL,GAAiC,KAAjC;;AACArc,aAAKsgB,UAAL;AACD,OAHD,MAGO,IAAItgB,KAAKkc,YAAL,CAAkBuB,KAAlB,EAAJ,EAA+B;AACpCzd,aAAK0f,SAAL;AACD,OAFM,MAEA;AACL1f,aAAKsf,uBAAL;AACD;AACF,KATD;AAUD,GA3mBoC;AA6mBrCkB,mBAAiB,UAAUG,gBAAV,EAA4B;AAC3C,QAAI3gB,OAAO,IAAX;AACA,WAAOsB,OAAOsN,gBAAP,CAAwB,YAAY;AACzC;AACA;AACA;AACA;AACA;AACA,UAAI7O,UAAUxC,EAAEU,KAAF,CAAQ+B,KAAK8J,kBAAL,CAAwB/J,OAAhC,CAAd,CANyC,CAQzC;AACA;;;AACAxC,QAAE+H,MAAF,CAASvF,OAAT,EAAkB4gB,gBAAlB;;AAEA5gB,cAAQiM,MAAR,GAAiBhM,KAAK+b,iBAAtB;AACA,aAAOhc,QAAQyK,SAAf,CAbyC,CAczC;;AACA,UAAIoW,cAAc,IAAI7X,iBAAJ,CAChB/I,KAAK8J,kBAAL,CAAwBhH,cADR,EAEhB9C,KAAK8J,kBAAL,CAAwB5E,QAFR,EAGhBnF,OAHgB,CAAlB;AAIA,aAAO,IAAI+I,MAAJ,CAAW9I,KAAKuY,YAAhB,EAA8BqI,WAA9B,CAAP;AACD,KApBM,CAAP;AAqBD,GApoBoC;AAuoBrC;AACA;AACA;AACA;AACA;AACA;AACA;AACAF,sBAAoB,UAAU9G,UAAV,EAAsB2G,SAAtB,EAAiC;AACnD,QAAIvgB,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAElC;AACA;AACA,UAAI5O,KAAKib,MAAT,EAAiB;AACfjb,aAAKob,kBAAL,CAAwBrG,KAAxB;AACD,OANiC,CAQlC;AACA;;;AACA,UAAI8L,cAAc,EAAlB;;AACA7gB,WAAKsb,UAAL,CAAgBlQ,OAAhB,CAAwB,UAAUtJ,GAAV,EAAe+C,EAAf,EAAmB;AACzC,YAAI,CAAC+U,WAAW9Y,GAAX,CAAe+D,EAAf,CAAL,EACEgc,YAAYxT,IAAZ,CAAiBxI,EAAjB;AACH,OAHD;;AAIAtH,QAAEK,IAAF,CAAOijB,WAAP,EAAoB,UAAUhc,EAAV,EAAc;AAChC7E,aAAKwd,gBAAL,CAAsB3Y,EAAtB;AACD,OAFD,EAfkC,CAmBlC;AACA;AACA;;;AACA+U,iBAAWxO,OAAX,CAAmB,UAAUtJ,GAAV,EAAe+C,EAAf,EAAmB;AACpC7E,aAAK6e,UAAL,CAAgBha,EAAhB,EAAoB/C,GAApB;AACD,OAFD,EAtBkC,CA0BlC;AACA;AACA;;AACA,UAAI9B,KAAKsb,UAAL,CAAgBxc,IAAhB,OAA2B8a,WAAW9a,IAAX,EAA/B,EAAkD;AAChD,cAAM2D,MACJ,2DACE,+DADF,GAEE,2BAFF,GAGE1D,MAAMyP,SAAN,CAAgBxO,KAAK8J,kBAAL,CAAwB5E,QAAxC,CAJE,CAAN;AAKD;;AACDlF,WAAKsb,UAAL,CAAgBlQ,OAAhB,CAAwB,UAAUtJ,GAAV,EAAe+C,EAAf,EAAmB;AACzC,YAAI,CAAC+U,WAAW9Y,GAAX,CAAe+D,EAAf,CAAL,EACE,MAAMpC,MAAM,mDAAmDoC,EAAzD,CAAN;AACH,OAHD,EApCkC,CAyClC;;;AACA0b,gBAAUnV,OAAV,CAAkB,UAAUtJ,GAAV,EAAe+C,EAAf,EAAmB;AACnC7E,aAAKud,YAAL,CAAkB1Y,EAAlB,EAAsB/C,GAAtB;AACD,OAFD;AAIA9B,WAAKwb,mBAAL,GAA2B+E,UAAUzhB,IAAV,KAAmBkB,KAAKib,MAAnD;AACD,KA/CD;AAgDD,GAhsBoC;AAksBrC;AACA;AACA;AACA;AACA;AACA;AACAtY,QAAM,YAAY;AAChB,QAAI3C,OAAO,IAAX;AACA,QAAIA,KAAK8R,QAAT,EACE;AACF9R,SAAK8R,QAAL,GAAgB,IAAhB;;AACAvU,MAAEK,IAAF,CAAOoC,KAAKyb,YAAZ,EAA0B,UAAUpF,MAAV,EAAkB;AAC1CA,aAAO1T,IAAP;AACD,KAFD,EALgB,CAShB;AACA;AACA;AACA;AACA;;;AACApF,MAAEK,IAAF,CAAOoC,KAAKsc,gCAAZ,EAA8C,UAAUnC,CAAV,EAAa;AACzDA,QAAEtW,SAAF,GADyD,CACzC;AACjB,KAFD;;AAGA7D,SAAKsc,gCAAL,GAAwC,IAAxC,CAjBgB,CAmBhB;;AACAtc,SAAKsb,UAAL,GAAkB,IAAlB;AACAtb,SAAKob,kBAAL,GAA0B,IAA1B;AACApb,SAAKkc,YAAL,GAAoB,IAApB;AACAlc,SAAKmc,kBAAL,GAA0B,IAA1B;AACAnc,SAAK8gB,iBAAL,GAAyB,IAAzB;AACA9gB,SAAK+gB,gBAAL,GAAwB,IAAxB;AAEA3e,YAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,uBADK,EACoB,CAAC,CADrB,CAAzB;AAED,GAruBoC;AAuuBrCkG,wBAAsB,UAAUsF,KAAV,EAAiB;AACrC,QAAIhhB,OAAO,IAAX;;AACAsB,WAAOsN,gBAAP,CAAwB,YAAY;AAClC,UAAIqS,MAAM,IAAIC,IAAJ,EAAV;;AAEA,UAAIlhB,KAAKwc,MAAT,EAAiB;AACf,YAAI2E,WAAWF,MAAMjhB,KAAKohB,eAA1B;AACAhf,gBAAQ,YAAR,KAAyBA,QAAQ,YAAR,EAAsBmT,KAAtB,CAA4BC,mBAA5B,CACvB,gBADuB,EACL,mBAAmBxV,KAAKwc,MAAxB,GAAiC,QAD5B,EACsC2E,QADtC,CAAzB;AAED;;AAEDnhB,WAAKwc,MAAL,GAAcwE,KAAd;AACAhhB,WAAKohB,eAAL,GAAuBH,GAAvB;AACD,KAXD;AAYD;AArvBoC,CAAvC,E,CAwvBA;AACA;AACA;;;AACAzR,mBAAmBC,eAAnB,GAAqC,UAAU7F,iBAAV,EAA6BqF,OAA7B,EAAsC;AACzE;AACA,MAAIlP,UAAU6J,kBAAkB7J,OAAhC,CAFyE,CAIzE;AACA;;AACA,MAAIA,QAAQshB,YAAR,IAAwBthB,QAAQuhB,aAApC,EACE,OAAO,KAAP,CAPuE,CASzE;AACA;AACA;AACA;;AACA,MAAIvhB,QAAQ0L,IAAR,IAAiB1L,QAAQkJ,KAAR,IAAiB,CAAClJ,QAAQyL,IAA/C,EAAsD,OAAO,KAAP,CAbmB,CAezE;AACA;;AACA,MAAIzL,QAAQiM,MAAZ,EAAoB;AAClB,QAAI;AACFrH,sBAAgB4c,yBAAhB,CAA0CxhB,QAAQiM,MAAlD;AACD,KAFD,CAEE,OAAOvH,CAAP,EAAU;AACV,UAAIA,EAAEtG,IAAF,KAAW,gBAAf,EAAiC;AAC/B,eAAO,KAAP;AACD,OAFD,MAEO;AACL,cAAMsG,CAAN;AACD;AACF;AACF,GA3BwE,CA6BzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAAO,CAACwK,QAAQuS,QAAR,EAAD,IAAuB,CAACvS,QAAQwS,WAAR,EAA/B;AACD,CAtCD;;AAwCA,IAAI1B,+BAA+B,UAAU2B,QAAV,EAAoB;AACrD,SAAOnkB,EAAE6R,GAAF,CAAMsS,QAAN,EAAgB,UAAU1V,MAAV,EAAkB2V,SAAlB,EAA6B;AAClD,WAAOpkB,EAAE6R,GAAF,CAAMpD,MAAN,EAAc,UAAUnO,KAAV,EAAiB+jB,KAAjB,EAAwB;AAC3C,aAAO,CAAC,UAAUhhB,IAAV,CAAeghB,KAAf,CAAR;AACD,KAFM,CAAP;AAGD,GAJM,CAAP;AAKD,CAND;;AAQAhlB,eAAe4S,kBAAf,GAAoCA,kBAApC,C;;;;;;;;;;;AC7+BAtS,OAAO2kB,MAAP,CAAc;AAACC,yBAAsB,MAAIA;AAA3B,CAAd;AACO,MAAMA,wBAAwB,IAAK,MAAMA,qBAAN,CAA4B;AACpEC,gBAAc;AACZ,SAAKC,iBAAL,GAAyB3hB,OAAO4hB,MAAP,CAAc,IAAd,CAAzB;AACD;;AAEDC,OAAK/jB,IAAL,EAAWgkB,IAAX,EAAiB;AACf,QAAI,CAAEhkB,IAAN,EAAY;AACV,aAAO,IAAIwG,eAAJ,EAAP;AACD;;AAED,QAAI,CAAEwd,IAAN,EAAY;AACV,aAAOC,iBAAiBjkB,IAAjB,EAAuB,KAAK6jB,iBAA5B,CAAP;AACD;;AAED,QAAI,CAAEG,KAAKE,2BAAX,EAAwC;AACtCF,WAAKE,2BAAL,GAAmChiB,OAAO4hB,MAAP,CAAc,IAAd,CAAnC;AACD,KAXc,CAaf;AACA;;;AACA,WAAOG,iBAAiBjkB,IAAjB,EAAuBgkB,KAAKE,2BAA5B,CAAP;AACD;;AArBmE,CAAjC,EAA9B;;AAwBP,SAASD,gBAAT,CAA0BjkB,IAA1B,EAAgCmkB,WAAhC,EAA6C;AAC3C,SAAQnkB,QAAQmkB,WAAT,GACHA,YAAYnkB,IAAZ,CADG,GAEHmkB,YAAYnkB,IAAZ,IAAoB,IAAIwG,eAAJ,CAAoBxG,IAApB,CAFxB;AAGD,C;;;;;;;;;;;AC7BDvB,eAAe2lB,sBAAf,GAAwC,UACtCC,SADsC,EAC3BziB,OAD2B,EAClB;AACpB,MAAIC,OAAO,IAAX;AACAA,OAAK2J,KAAL,GAAa,IAAI9J,eAAJ,CAAoB2iB,SAApB,EAA+BziB,OAA/B,CAAb;AACD,CAJD;;AAMAxC,EAAE+H,MAAF,CAAS1I,eAAe2lB,sBAAf,CAAsCvkB,SAA/C,EAA0D;AACxDkkB,QAAM,UAAU/jB,IAAV,EAAgB;AACpB,QAAI6B,OAAO,IAAX;AACA,QAAIrC,MAAM,EAAV;;AACAJ,MAAEK,IAAF,CACE,CAAC,MAAD,EAAS,SAAT,EAAoB,QAApB,EAA8B,QAA9B,EAAwC,QAAxC,EACC,QADD,EACW,cADX,EAC2B,YAD3B,EACyC,yBADzC,EAEC,gBAFD,EAEmB,eAFnB,CADF,EAIE,UAAU6kB,CAAV,EAAa;AACX9kB,UAAI8kB,CAAJ,IAASllB,EAAEG,IAAF,CAAOsC,KAAK2J,KAAL,CAAW8Y,CAAX,CAAP,EAAsBziB,KAAK2J,KAA3B,EAAkCxL,IAAlC,CAAT;AACD,KANH;;AAOA,WAAOR,GAAP;AACD;AAZuD,CAA1D,E,CAgBA;AACA;AACA;;;AACAf,eAAe8lB,6BAAf,GAA+CnlB,EAAEolB,IAAF,CAAO,YAAY;AAChE,MAAIC,oBAAoB,EAAxB;AAEA,MAAIC,WAAW9R,QAAQC,GAAR,CAAY8R,SAA3B;;AAEA,MAAI/R,QAAQC,GAAR,CAAY+R,eAAhB,EAAiC;AAC/BH,sBAAkBzgB,QAAlB,GAA6B4O,QAAQC,GAAR,CAAY+R,eAAzC;AACD;;AAED,MAAI,CAAEF,QAAN,EACE,MAAM,IAAIpgB,KAAJ,CAAU,sCAAV,CAAN;AAEF,SAAO,IAAI7F,eAAe2lB,sBAAnB,CAA0CM,QAA1C,EAAoDD,iBAApD,CAAP;AACD,CAb8C,CAA/C,C;;;;;;;;;;;;;;;ACzBA;AACA;;AAEA;;;;AAIAhkB,QAAQ,EAAR;AAEA;;;;;;;;;;;;;;;;;;AAiBAA,MAAM6K,UAAN,GAAmB,SAASA,UAAT,CAAoBtL,IAApB,EAA0B4B,OAA1B,EAAmC;AACpD,MAAI,CAAC5B,IAAD,IAAUA,SAAS,IAAvB,EAA8B;AAC5BmD,WAAOiS,MAAP,CAAc,4DACA,yDADA,GAEA,gDAFd;;AAGApV,WAAO,IAAP;AACD;;AAED,MAAIA,SAAS,IAAT,IAAiB,OAAOA,IAAP,KAAgB,QAArC,EAA+C;AAC7C,UAAM,IAAIsE,KAAJ,CACJ,iEADI,CAAN;AAED;;AAED,MAAI1C,WAAWA,QAAQiL,OAAvB,EAAgC;AAC9B;AACA;AACA;AACA;AACAjL,cAAU;AAACijB,kBAAYjjB;AAAb,KAAV;AACD,GAnBmD,CAoBpD;;;AACA,MAAIA,WAAWA,QAAQkjB,OAAnB,IAA8B,CAACljB,QAAQijB,UAA3C,EAAuD;AACrDjjB,YAAQijB,UAAR,GAAqBjjB,QAAQkjB,OAA7B;AACD;;AAEDljB;AACEijB,gBAAY/jB,SADd;AAEEikB,kBAAc,QAFhB;AAGE1Y,eAAW,IAHb;AAIE2Y,aAASlkB,SAJX;AAKEmkB,yBAAqB;AALvB,KAMOrjB,OANP;;AASA,UAAQA,QAAQmjB,YAAhB;AACA,SAAK,OAAL;AACE,WAAKG,UAAL,GAAkB,YAAY;AAC5B,YAAIC,MAAMnlB,OAAOolB,IAAIC,YAAJ,CAAiB,iBAAiBrlB,IAAlC,CAAP,GAAiDslB,OAAOC,QAAlE;AACA,eAAO,IAAI9kB,MAAMD,QAAV,CAAmB2kB,IAAIK,SAAJ,CAAc,EAAd,CAAnB,CAAP;AACD,OAHD;;AAIA;;AACF,SAAK,QAAL;AACA;AACE,WAAKN,UAAL,GAAkB,YAAY;AAC5B,YAAIC,MAAMnlB,OAAOolB,IAAIC,YAAJ,CAAiB,iBAAiBrlB,IAAlC,CAAP,GAAiDslB,OAAOC,QAAlE;AACA,eAAOJ,IAAIze,EAAJ,EAAP;AACD,OAHD;;AAIA;AAbF;;AAgBA,OAAK0H,UAAL,GAAkB5H,gBAAgB6H,aAAhB,CAA8BzM,QAAQyK,SAAtC,CAAlB;AAEA,MAAI,CAAErM,IAAF,IAAU4B,QAAQijB,UAAR,KAAuB,IAArC,EACE;AACA,SAAKY,WAAL,GAAmB,IAAnB,CAFF,KAGK,IAAI7jB,QAAQijB,UAAZ,EACH,KAAKY,WAAL,GAAmB7jB,QAAQijB,UAA3B,CADG,KAEA,IAAI1hB,OAAOuiB,QAAX,EACH,KAAKD,WAAL,GAAmBtiB,OAAO0hB,UAA1B,CADG,KAGH,KAAKY,WAAL,GAAmBtiB,OAAOwiB,MAA1B;;AAEF,MAAI,CAAC/jB,QAAQojB,OAAb,EAAsB;AACpB;AACA;AACA;AACA;AACA,QAAIhlB,QAAQ,KAAKylB,WAAL,KAAqBtiB,OAAOwiB,MAApC,IACA,OAAOlnB,cAAP,KAA0B,WAD1B,IAEAA,eAAe8lB,6BAFnB,EAEkD;AAChD3iB,cAAQojB,OAAR,GAAkBvmB,eAAe8lB,6BAAf,EAAlB;AACD,KAJD,MAIO;AACL,YAAM;AAAEZ;AAAF,UACJnlB,QAAQ,8BAAR,CADF;;AAEAoD,cAAQojB,OAAR,GAAkBrB,qBAAlB;AACD;AACF;;AAED,OAAKiC,WAAL,GAAmBhkB,QAAQojB,OAAR,CAAgBjB,IAAhB,CAAqB/jB,IAArB,EAA2B,KAAKylB,WAAhC,CAAnB;AACA,OAAKI,KAAL,GAAa7lB,IAAb;AACA,OAAKglB,OAAL,GAAepjB,QAAQojB,OAAvB;;AAEA,OAAKc,sBAAL,CAA4B9lB,IAA5B,EAAkC4B,OAAlC,EAlFoD,CAoFpD;AACA;AACA;;;AACA,MAAIA,QAAQmkB,qBAAR,KAAkC,KAAtC,EAA6C;AAC3C,QAAI;AACF,WAAKC,sBAAL,CAA4B;AAC1BC,qBAAarkB,QAAQskB,sBAAR,KAAmC;AADtB,OAA5B;AAGD,KAJD,CAIE,OAAOhd,KAAP,EAAc;AACd;AACA,UAAIA,MAAM2S,OAAN,KAAmB,oBAAmB7b,IAAK,6BAA/C,EACE,MAAM,IAAIsE,KAAJ,CAAW,wCAAuCtE,IAAK,GAAvD,CAAN;AACF,YAAMkJ,KAAN;AACD;AACF,GAlGmD,CAoGpD;;;AACA,MAAIjF,QAAQkiB,WAAR,IACA,CAAEvkB,QAAQqjB,mBADV,IAEA,KAAKQ,WAFL,IAGA,KAAKA,WAAL,CAAiBW,OAHrB,EAG8B;AAC5B,SAAKX,WAAL,CAAiBW,OAAjB,CAAyB,IAAzB,EAA+B,MAAM,KAAK1b,IAAL,EAArC,EAAkD;AAChD2b,eAAS;AADuC,KAAlD;AAGD;AACF,CA7GD;;AA+GAnkB,OAAOC,MAAP,CAAc1B,MAAM6K,UAAN,CAAiBzL,SAA/B,EAA0C;AACxCimB,yBAAuB9lB,IAAvB,EAA6B;AAC3BkmB,6BAAyB;AADE,GAA7B,EAEG;AACD,UAAMrkB,OAAO,IAAb;;AACA,QAAI,EAAGA,KAAK4jB,WAAL,IACA5jB,KAAK4jB,WAAL,CAAiBa,aADpB,CAAJ,EACwC;AACtC;AACD,KALA,CAOD;AACA;AACA;;;AACA,UAAMC,KAAK1kB,KAAK4jB,WAAL,CAAiBa,aAAjB,CAA+BtmB,IAA/B,EAAqC;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACAwmB,kBAAYC,SAAZ,EAAuBC,KAAvB,EAA8B;AAC5B;AACA;AACA;AACA;AACA;AACA,YAAID,YAAY,CAAZ,IAAiBC,KAArB,EACE7kB,KAAK+jB,WAAL,CAAiBe,cAAjB;AAEF,YAAID,KAAJ,EACE7kB,KAAK+jB,WAAL,CAAiBne,MAAjB,CAAwB,EAAxB;AACH,OAtB6C;;AAwB9C;AACA;AACA6B,aAAOsd,GAAP,EAAY;AACV,YAAIC,UAAUC,QAAQC,OAAR,CAAgBH,IAAIlgB,EAApB,CAAd;;AACA,YAAI/C,MAAM9B,KAAK+jB,WAAL,CAAiB/a,OAAjB,CAAyBgc,OAAzB,CAAV,CAFU,CAIV;AACA;AACA;;;AACA,YAAID,IAAIA,GAAJ,KAAY,SAAhB,EAA2B;AACzB,cAAII,UAAUJ,IAAII,OAAlB;;AACA,cAAI,CAACA,OAAL,EAAc;AACZ,gBAAIrjB,GAAJ,EACE9B,KAAK+jB,WAAL,CAAiBne,MAAjB,CAAwBof,OAAxB;AACH,WAHD,MAGO,IAAI,CAACljB,GAAL,EAAU;AACf9B,iBAAK+jB,WAAL,CAAiBhf,MAAjB,CAAwBogB,OAAxB;AACD,WAFM,MAEA;AACL;AACAnlB,iBAAK+jB,WAAL,CAAiBtc,MAAjB,CAAwBud,OAAxB,EAAiCG,OAAjC;AACD;;AACD;AACD,SAZD,MAYO,IAAIJ,IAAIA,GAAJ,KAAY,OAAhB,EAAyB;AAC9B,cAAIjjB,GAAJ,EAAS;AACP,kBAAM,IAAIW,KAAJ,CAAU,4DAAV,CAAN;AACD;;AACDzC,eAAK+jB,WAAL,CAAiBhf,MAAjB;AAA0BD,iBAAKkgB;AAA/B,aAA2CD,IAAI/Y,MAA/C;AACD,SALM,MAKA,IAAI+Y,IAAIA,GAAJ,KAAY,SAAhB,EAA2B;AAChC,cAAI,CAACjjB,GAAL,EACE,MAAM,IAAIW,KAAJ,CAAU,yDAAV,CAAN;;AACFzC,eAAK+jB,WAAL,CAAiBne,MAAjB,CAAwBof,OAAxB;AACD,SAJM,MAIA,IAAID,IAAIA,GAAJ,KAAY,SAAhB,EAA2B;AAChC,cAAI,CAACjjB,GAAL,EACE,MAAM,IAAIW,KAAJ,CAAU,uCAAV,CAAN;AACF,gBAAM4U,OAAOhX,OAAOgX,IAAP,CAAY0N,IAAI/Y,MAAhB,CAAb;;AACA,cAAIqL,KAAKxP,MAAL,GAAc,CAAlB,EAAqB;AACnB,gBAAI6Z,WAAW,EAAf;AACArK,iBAAKjM,OAAL,CAAatN,OAAO;AAClB,oBAAMD,QAAQknB,IAAI/Y,MAAJ,CAAWlO,GAAX,CAAd;;AACA,kBAAI,OAAOD,KAAP,KAAiB,WAArB,EAAkC;AAChC,oBAAI,CAAC6jB,SAAS0D,MAAd,EAAsB;AACpB1D,2BAAS0D,MAAT,GAAkB,EAAlB;AACD;;AACD1D,yBAAS0D,MAAT,CAAgBtnB,GAAhB,IAAuB,CAAvB;AACD,eALD,MAKO;AACL,oBAAI,CAAC4jB,SAAS2D,IAAd,EAAoB;AAClB3D,2BAAS2D,IAAT,GAAgB,EAAhB;AACD;;AACD3D,yBAAS2D,IAAT,CAAcvnB,GAAd,IAAqBD,KAArB;AACD;AACF,aAbD;;AAcAmC,iBAAK+jB,WAAL,CAAiBtc,MAAjB,CAAwBud,OAAxB,EAAiCtD,QAAjC;AACD;AACF,SAtBM,MAsBA;AACL,gBAAM,IAAIjf,KAAJ,CAAU,4CAAV,CAAN;AACD;AACF,OA/E6C;;AAiF9C;AACA6iB,kBAAY;AACVtlB,aAAK+jB,WAAL,CAAiBwB,eAAjB;AACD,OApF6C;;AAsF9C;AACA;AACAC,sBAAgB;AACdxlB,aAAK+jB,WAAL,CAAiByB,aAAjB;AACD,OA1F6C;;AA2F9CC,0BAAoB;AAClB,eAAOzlB,KAAK+jB,WAAL,CAAiB0B,iBAAjB,EAAP;AACD,OA7F6C;;AA+F9C;AACAC,aAAO7gB,EAAP,EAAW;AACT,eAAO7E,KAAKgJ,OAAL,CAAanE,EAAb,CAAP;AACD,OAlG6C;;AAoG9C;AACA8gB,uBAAiB;AACf,eAAO3lB,IAAP;AACD;;AAvG6C,KAArC,CAAX;;AA0GA,QAAI,CAAE0kB,EAAN,EAAU;AACR,YAAM1K,UAAW,wCAAuC7b,IAAK,GAA7D;;AACA,UAAIkmB,2BAA2B,IAA/B,EAAqC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACAuB,gBAAQC,IAAR,GAAeD,QAAQC,IAAR,CAAa7L,OAAb,CAAf,GAAuC4L,QAAQE,GAAR,CAAY9L,OAAZ,CAAvC;AACD,OATD,MASO;AACL,cAAM,IAAIvX,KAAJ,CAAUuX,OAAV,CAAN;AACD;AACF;AACF,GAtIuC;;AAwIxC;AACA;AACA;AAEA+L,mBAAiB5O,IAAjB,EAAuB;AACrB,QAAIA,KAAKtP,MAAL,IAAe,CAAnB,EACE,OAAO,EAAP,CADF,KAGE,OAAOsP,KAAK,CAAL,CAAP;AACH,GAjJuC;;AAmJxC6O,kBAAgB7O,IAAhB,EAAsB;AACpB,QAAInX,OAAO,IAAX;;AACA,QAAImX,KAAKtP,MAAL,GAAc,CAAlB,EAAqB;AACnB,aAAO;AAAE2C,mBAAWxK,KAAKuM;AAAlB,OAAP;AACD,KAFD,MAEO;AACL4L,YAAMhB,KAAK,CAAL,CAAN,EAAe8O,MAAMC,QAAN,CAAeD,MAAME,eAAN,CAAsB;AAClDna,gBAAQia,MAAMC,QAAN,CAAeD,MAAMG,KAAN,CAAY/lB,MAAZ,EAAoBpB,SAApB,CAAf,CAD0C;AAElDuM,cAAMya,MAAMC,QAAN,CAAeD,MAAMG,KAAN,CAAY/lB,MAAZ,EAAoB4Z,KAApB,EAA2B5T,QAA3B,EAAqCpH,SAArC,CAAf,CAF4C;AAGlDgK,eAAOgd,MAAMC,QAAN,CAAeD,MAAMG,KAAN,CAAYC,MAAZ,EAAoBpnB,SAApB,CAAf,CAH2C;AAIlDwM,cAAMwa,MAAMC,QAAN,CAAeD,MAAMG,KAAN,CAAYC,MAAZ,EAAoBpnB,SAApB,CAAf;AAJ4C,OAAtB,CAAf,CAAf;AAOA;AACEuL,mBAAWxK,KAAKuM;AADlB,SAEK4K,KAAK,CAAL,CAFL;AAID;AACF,GApKuC;;AAsKxC;;;;;;;;;;;;;;;;;;;;;AAqBAtO,OAAK,GAAGsO,IAAR,EAAc;AACZ;AACA;AACA;AACA,WAAO,KAAK4M,WAAL,CAAiBlb,IAAjB,CACL,KAAKkd,gBAAL,CAAsB5O,IAAtB,CADK,EAEL,KAAK6O,eAAL,CAAqB7O,IAArB,CAFK,CAAP;AAID,GAnMuC;;AAqMxC;;;;;;;;;;;;;;;AAeAnO,UAAQ,GAAGmO,IAAX,EAAiB;AACf,WAAO,KAAK4M,WAAL,CAAiB/a,OAAjB,CACL,KAAK+c,gBAAL,CAAsB5O,IAAtB,CADK,EAEL,KAAK6O,eAAL,CAAqB7O,IAArB,CAFK,CAAP;AAID;;AAzNuC,CAA1C;AA4NA9W,OAAOC,MAAP,CAAc1B,MAAM6K,UAApB,EAAgC;AAC9BgB,iBAAeqD,MAAf,EAAuBpD,GAAvB,EAA4B1H,UAA5B,EAAwC;AACtC,QAAI+L,gBAAgBjB,OAAO/C,cAAP,CAAsB;AACxC4F,aAAO,UAAU9L,EAAV,EAAcmH,MAAd,EAAsB;AAC3BtB,YAAIiG,KAAJ,CAAU3N,UAAV,EAAsB6B,EAAtB,EAA0BmH,MAA1B;AACD,OAHuC;AAIxCiS,eAAS,UAAUpZ,EAAV,EAAcmH,MAAd,EAAsB;AAC7BtB,YAAIuT,OAAJ,CAAYjb,UAAZ,EAAwB6B,EAAxB,EAA4BmH,MAA5B;AACD,OANuC;AAOxCsR,eAAS,UAAUzY,EAAV,EAAc;AACrB6F,YAAI4S,OAAJ,CAAYta,UAAZ,EAAwB6B,EAAxB;AACD;AATuC,KAAtB,CAApB,CADsC,CAatC;AACA;AAEA;;AACA6F,QAAIoE,MAAJ,CAAW,YAAY;AACrBC,oBAAcpM,IAAd;AACD,KAFD,EAjBsC,CAqBtC;;AACA,WAAOoM,aAAP;AACD,GAxB6B;;AA0B9B;AACA;AACA;AACA;AACA;AACArF,mBAAiBxE,QAAjB,EAA2B;AAAEohB;AAAF,MAAiB,EAA5C,EAAgD;AAC9C;AACA,QAAI3hB,gBAAgB4hB,aAAhB,CAA8BrhB,QAA9B,CAAJ,EACEA,WAAW;AAACJ,WAAKI;AAAN,KAAX;;AAEF,QAAI+U,MAAMzc,OAAN,CAAc0H,QAAd,CAAJ,EAA6B;AAC3B;AACA;AACA,YAAM,IAAIzC,KAAJ,CAAU,mCAAV,CAAN;AACD;;AAED,QAAI,CAACyC,QAAD,IAAe,SAASA,QAAV,IAAuB,CAACA,SAASJ,GAAnD,EAAyD;AACvD;AACA,aAAO;AAAEA,aAAKwhB,cAAc7C,OAAO5e,EAAP;AAArB,OAAP;AACD;;AAED,WAAOK,QAAP;AACD;;AAhD6B,CAAhC;AAmDA7E,OAAOC,MAAP,CAAc1B,MAAM6K,UAAN,CAAiBzL,SAA/B,EAA0C;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;;AASA+G,SAAOjD,GAAP,EAAYC,QAAZ,EAAsB;AACpB;AACA,QAAI,CAACD,GAAL,EAAU;AACR,YAAM,IAAIW,KAAJ,CAAU,6BAAV,CAAN;AACD,KAJmB,CAMpB;;;AACAX,UAAMzB,OAAO4hB,MAAP,CACJ5hB,OAAOmmB,cAAP,CAAsB1kB,GAAtB,CADI,EAEJzB,OAAOomB,yBAAP,CAAiC3kB,GAAjC,CAFI,CAAN;;AAKA,QAAI,SAASA,GAAb,EAAkB;AAChB,UAAI,CAAEA,IAAIgD,GAAN,IACA,EAAG,OAAOhD,IAAIgD,GAAX,KAAmB,QAAnB,IACAhD,IAAIgD,GAAJ,YAAmBlG,MAAMD,QAD5B,CADJ,EAE2C;AACzC,cAAM,IAAI8D,KAAJ,CACJ,0EADI,CAAN;AAED;AACF,KAPD,MAOO;AACL,UAAIikB,aAAa,IAAjB,CADK,CAGL;AACA;AACA;;AACA,UAAI,KAAKC,mBAAL,EAAJ,EAAgC;AAC9B,cAAMC,YAAYrD,IAAIsD,wBAAJ,CAA6BljB,GAA7B,EAAlB;;AACA,YAAI,CAACijB,SAAL,EAAgB;AACdF,uBAAa,KAAb;AACD;AACF;;AAED,UAAIA,UAAJ,EAAgB;AACd5kB,YAAIgD,GAAJ,GAAU,KAAKue,UAAL,EAAV;AACD;AACF,KAnCmB,CAqCpB;AACA;;;AACA,QAAIyD,wCAAwC,UAAU3iB,MAAV,EAAkB;AAC5D,UAAIrC,IAAIgD,GAAR,EAAa;AACX,eAAOhD,IAAIgD,GAAX;AACD,OAH2D,CAK5D;AACA;AACA;;;AACAhD,UAAIgD,GAAJ,GAAUX,MAAV;AAEA,aAAOA,MAAP;AACD,KAXD;;AAaA,UAAMqB,kBAAkBuhB,aACtBhlB,QADsB,EACZ+kB,qCADY,CAAxB;;AAGA,QAAI,KAAKH,mBAAL,EAAJ,EAAgC;AAC9B,YAAMxiB,SAAS,KAAK6iB,kBAAL,CAAwB,QAAxB,EAAkC,CAACllB,GAAD,CAAlC,EAAyC0D,eAAzC,CAAf;;AACA,aAAOshB,sCAAsC3iB,MAAtC,CAAP;AACD,KA1DmB,CA4DpB;AACA;;;AACA,QAAI;AACF;AACA;AACA;AACA,YAAMA,SAAS,KAAK4f,WAAL,CAAiBhf,MAAjB,CAAwBjD,GAAxB,EAA6B0D,eAA7B,CAAf;;AACA,aAAOshB,sCAAsC3iB,MAAtC,CAAP;AACD,KAND,CAME,OAAOM,CAAP,EAAU;AACV,UAAI1C,QAAJ,EAAc;AACZA,iBAAS0C,CAAT;AACA,eAAO,IAAP;AACD;;AACD,YAAMA,CAAN;AACD;AACF,GAnHuC;;AAqHxC;;;;;;;;;;;;;AAaAgD,SAAOvC,QAAP,EAAiBwc,QAAjB,EAA2B,GAAGuF,kBAA9B,EAAkD;AAChD,UAAMllB,WAAWmlB,oBAAoBD,kBAApB,CAAjB,CADgD,CAGhD;AACA;;AACA,UAAMlnB,0CAAgBknB,mBAAmB,CAAnB,KAAyB,IAAzC,CAAN;AACA,QAAI/f,UAAJ;;AACA,QAAInH,WAAWA,QAAQwG,MAAvB,EAA+B;AAC7B;AACA,UAAIxG,QAAQmH,UAAZ,EAAwB;AACtB,YAAI,EAAE,OAAOnH,QAAQmH,UAAf,KAA8B,QAA9B,IAA0CnH,QAAQmH,UAAR,YAA8BtI,MAAMD,QAAhF,CAAJ,EACE,MAAM,IAAI8D,KAAJ,CAAU,uCAAV,CAAN;AACFyE,qBAAanH,QAAQmH,UAArB;AACD,OAJD,MAIO,IAAI,CAAChC,QAAD,IAAa,CAACA,SAASJ,GAA3B,EAAgC;AACrCoC,qBAAa,KAAKmc,UAAL,EAAb;AACAtjB,gBAAQoH,WAAR,GAAsB,IAAtB;AACApH,gBAAQmH,UAAR,GAAqBA,UAArB;AACD;AACF;;AAEDhC,eACEtG,MAAM6K,UAAN,CAAiBC,gBAAjB,CAAkCxE,QAAlC,EAA4C;AAAEohB,kBAAYpf;AAAd,KAA5C,CADF;AAGA,UAAM1B,kBAAkBuhB,aAAahlB,QAAb,CAAxB;;AAEA,QAAI,KAAK4kB,mBAAL,EAAJ,EAAgC;AAC9B,YAAMxP,OAAO,CACXjS,QADW,EAEXwc,QAFW,EAGX3hB,OAHW,CAAb;AAMA,aAAO,KAAKinB,kBAAL,CAAwB,QAAxB,EAAkC7P,IAAlC,EAAwC3R,eAAxC,CAAP;AACD,KAjC+C,CAmChD;AACA;;;AACA,QAAI;AACF;AACA;AACA;AACA,aAAO,KAAKue,WAAL,CAAiBtc,MAAjB,CACLvC,QADK,EACKwc,QADL,EACe3hB,OADf,EACwByF,eADxB,CAAP;AAED,KAND,CAME,OAAOf,CAAP,EAAU;AACV,UAAI1C,QAAJ,EAAc;AACZA,iBAAS0C,CAAT;AACA,eAAO,IAAP;AACD;;AACD,YAAMA,CAAN;AACD;AACF,GApLuC;;AAsLxC;;;;;;;;;AASAmB,SAAOV,QAAP,EAAiBnD,QAAjB,EAA2B;AACzBmD,eAAWtG,MAAM6K,UAAN,CAAiBC,gBAAjB,CAAkCxE,QAAlC,CAAX;AAEA,UAAMM,kBAAkBuhB,aAAahlB,QAAb,CAAxB;;AAEA,QAAI,KAAK4kB,mBAAL,EAAJ,EAAgC;AAC9B,aAAO,KAAKK,kBAAL,CAAwB,QAAxB,EAAkC,CAAC9hB,QAAD,CAAlC,EAA8CM,eAA9C,CAAP;AACD,KAPwB,CASzB;AACA;;;AACA,QAAI;AACF;AACA;AACA;AACA,aAAO,KAAKue,WAAL,CAAiBne,MAAjB,CAAwBV,QAAxB,EAAkCM,eAAlC,CAAP;AACD,KALD,CAKE,OAAOf,CAAP,EAAU;AACV,UAAI1C,QAAJ,EAAc;AACZA,iBAAS0C,CAAT;AACA,eAAO,IAAP;AACD;;AACD,YAAMA,CAAN;AACD;AACF,GAtNuC;;AAwNxC;AACA;AACAkiB,wBAAsB;AACpB;AACA,WAAO,KAAK/C,WAAL,IAAoB,KAAKA,WAAL,KAAqBtiB,OAAOwiB,MAAvD;AACD,GA7NuC;;AA+NxC;;;;;;;;;;;;AAYAvd,SAAOrB,QAAP,EAAiBwc,QAAjB,EAA2B3hB,OAA3B,EAAoCgC,QAApC,EAA8C;AAC5C,QAAI,CAAEA,QAAF,IAAc,OAAOhC,OAAP,KAAmB,UAArC,EAAiD;AAC/CgC,iBAAWhC,OAAX;AACAA,gBAAU,EAAV;AACD;;AAED,WAAO,KAAK0H,MAAL,CAAYvC,QAAZ,EAAsBwc,QAAtB,kCACF3hB,OADE;AAELuH,qBAAe,IAFV;AAGLf,cAAQ;AAHH,QAIJxE,QAJI,CAAP;AAKD,GAtPuC;;AAwPxC;AACA;AACAoH,eAAaC,KAAb,EAAoBrJ,OAApB,EAA6B;AAC3B,QAAIC,OAAO,IAAX;AACA,QAAI,CAACA,KAAK+jB,WAAL,CAAiB5a,YAAtB,EACE,MAAM,IAAI1G,KAAJ,CAAU,kDAAV,CAAN;;AACFzC,SAAK+jB,WAAL,CAAiB5a,YAAjB,CAA8BC,KAA9B,EAAqCrJ,OAArC;AACD,GA/PuC;;AAiQxCwJ,aAAWH,KAAX,EAAkB;AAChB,QAAIpJ,OAAO,IAAX;AACA,QAAI,CAACA,KAAK+jB,WAAL,CAAiBxa,UAAtB,EACE,MAAM,IAAI9G,KAAJ,CAAU,gDAAV,CAAN;;AACFzC,SAAK+jB,WAAL,CAAiBxa,UAAjB,CAA4BH,KAA5B;AACD,GAtQuC;;AAwQxCvD,oBAAkB;AAChB,QAAI7F,OAAO,IAAX;AACA,QAAI,CAACA,KAAK+jB,WAAL,CAAiBhe,cAAtB,EACE,MAAM,IAAItD,KAAJ,CAAU,qDAAV,CAAN;;AACFzC,SAAK+jB,WAAL,CAAiBhe,cAAjB;AACD,GA7QuC;;AA+QxC9C,0BAAwBC,QAAxB,EAAkCC,YAAlC,EAAgD;AAC9C,QAAInD,OAAO,IAAX;AACA,QAAI,CAACA,KAAK+jB,WAAL,CAAiB9gB,uBAAtB,EACE,MAAM,IAAIR,KAAJ,CAAU,6DAAV,CAAN;;AACFzC,SAAK+jB,WAAL,CAAiB9gB,uBAAjB,CAAyCC,QAAzC,EAAmDC,YAAnD;AACD,GApRuC;;AAsRxC;;;;AAIAN,kBAAgB;AACd,QAAI7C,OAAO,IAAX;;AACA,QAAI,CAAEA,KAAK+jB,WAAL,CAAiBlhB,aAAvB,EAAsC;AACpC,YAAM,IAAIJ,KAAJ,CAAU,mDAAV,CAAN;AACD;;AACD,WAAOzC,KAAK+jB,WAAL,CAAiBlhB,aAAjB,EAAP;AACD,GAhSuC;;AAkSxC;;;;AAIAskB,gBAAc;AACZ,QAAInnB,OAAO,IAAX;;AACA,QAAI,EAAGA,KAAKmjB,OAAL,CAAaxZ,KAAb,IAAsB3J,KAAKmjB,OAAL,CAAaxZ,KAAb,CAAmB3I,EAA5C,CAAJ,EAAqD;AACnD,YAAM,IAAIyB,KAAJ,CAAU,iDAAV,CAAN;AACD;;AACD,WAAOzC,KAAKmjB,OAAL,CAAaxZ,KAAb,CAAmB3I,EAA1B;AACD;;AA5SuC,CAA1C,E,CA+SA;;AACA,SAAS+lB,YAAT,CAAsBhlB,QAAtB,EAAgCqlB,aAAhC,EAA+C;AAC7C,SAAOrlB,YAAY,UAAUsF,KAAV,EAAiBlD,MAAjB,EAAyB;AAC1C,QAAIkD,KAAJ,EAAW;AACTtF,eAASsF,KAAT;AACD,KAFD,MAEO,IAAI,OAAO+f,aAAP,KAAyB,UAA7B,EAAyC;AAC9CrlB,eAAS,IAAT,EAAeqlB,cAAcjjB,MAAd,CAAf;AACD,KAFM,MAEA;AACLpC,eAAS,IAAT,EAAeoC,MAAf;AACD;AACF,GARD;AASD;AAED;;;;;;;;AAMAvF,MAAMD,QAAN,GAAiBsmB,QAAQtmB,QAAzB;AAEA;;;;;;AAKAC,MAAMkK,MAAN,GAAenE,gBAAgBmE,MAA/B;AAEA;;;;AAGAlK,MAAM6K,UAAN,CAAiBX,MAAjB,GAA0BlK,MAAMkK,MAAhC;AAEA;;;;AAGAlK,MAAM6K,UAAN,CAAiB9K,QAAjB,GAA4BC,MAAMD,QAAlC;AAEA;;;;AAGA2C,OAAOmI,UAAP,GAAoB7K,MAAM6K,UAA1B,C,CAEA;;AACApJ,OAAOC,MAAP,CACEgB,OAAOmI,UAAP,CAAkBzL,SADpB,EAEEqpB,UAAUC,mBAFZ;;AAKA,SAASJ,mBAAT,CAA6B/P,IAA7B,EAAmC;AACjC;AACA;AACA,MAAIA,KAAKtP,MAAL,KACCsP,KAAKA,KAAKtP,MAAL,GAAc,CAAnB,MAA0B5I,SAA1B,IACAkY,KAAKA,KAAKtP,MAAL,GAAc,CAAnB,aAAiCxB,QAFlC,CAAJ,EAEiD;AAC/C,WAAO8Q,KAAKrC,GAAL,EAAP;AACD;AACF,C;;;;;;;;;;;AChwBD;;;;;;AAMAlW,MAAM2oB,oBAAN,GAA6B,SAASA,oBAAT,CAA+BxnB,OAA/B,EAAwC;AACnEoY,QAAMpY,OAAN,EAAeM,MAAf;AACAzB,QAAM+B,kBAAN,GAA2BZ,OAA3B;AACD,CAHD,C","file":"/packages/mongo.js","sourcesContent":["/**\n * Provide a synchronous Collection API using fibers, backed by\n * MongoDB.  This is only for use on the server, and mostly identical\n * to the client API.\n *\n * NOTE: the public API methods must be run within a fiber. If you call\n * these outside of a fiber they will explode!\n */\n\nvar MongoDB = NpmModuleMongodb;\nvar Future = Npm.require('fibers/future');\n\nMongoInternals = {};\nMongoTest = {};\n\nMongoInternals.NpmModules = {\n  mongodb: {\n    version: NpmModuleMongodbVersion,\n    module: MongoDB\n  }\n};\n\n// Older version of what is now available via\n// MongoInternals.NpmModules.mongodb.module.  It was never documented, but\n// people do use it.\n// XXX COMPAT WITH 1.0.3.2\nMongoInternals.NpmModule = MongoDB;\n\n// This is used to add or remove EJSON from the beginning of everything nested\n// inside an EJSON custom type. It should only be called on pure JSON!\nvar replaceNames = function (filter, thing) {\n  if (typeof thing === \"object\" && thing !== null) {\n    if (_.isArray(thing)) {\n      return _.map(thing, _.bind(replaceNames, null, filter));\n    }\n    var ret = {};\n    _.each(thing, function (value, key) {\n      ret[filter(key)] = replaceNames(filter, value);\n    });\n    return ret;\n  }\n  return thing;\n};\n\n// Ensure that EJSON.clone keeps a Timestamp as a Timestamp (instead of just\n// doing a structural clone).\n// XXX how ok is this? what if there are multiple copies of MongoDB loaded?\nMongoDB.Timestamp.prototype.clone = function () {\n  // Timestamps should be immutable.\n  return this;\n};\n\nvar makeMongoLegal = function (name) { return \"EJSON\" + name; };\nvar unmakeMongoLegal = function (name) { return name.substr(5); };\n\nvar replaceMongoAtomWithMeteor = function (document) {\n  if (document instanceof MongoDB.Binary) {\n    var buffer = document.value(true);\n    return new Uint8Array(buffer);\n  }\n  if (document instanceof MongoDB.ObjectID) {\n    return new Mongo.ObjectID(document.toHexString());\n  }\n  if (document[\"EJSON$type\"] && document[\"EJSON$value\"] && _.size(document) === 2) {\n    return EJSON.fromJSONValue(replaceNames(unmakeMongoLegal, document));\n  }\n  if (document instanceof MongoDB.Timestamp) {\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\n    // this is a weird internal thing used in the oplog!) is the same as the\n    // Mongo representation. We need to do this explicitly or else we would do a\n    // structural clone and lose the prototype.\n    return document;\n  }\n  return undefined;\n};\n\nvar replaceMeteorAtomWithMongo = function (document) {\n  if (EJSON.isBinary(document)) {\n    // This does more copies than we'd like, but is necessary because\n    // MongoDB.BSON only looks like it takes a Uint8Array (and doesn't actually\n    // serialize it correctly).\n    return new MongoDB.Binary(Buffer.from(document));\n  }\n  if (document instanceof Mongo.ObjectID) {\n    return new MongoDB.ObjectID(document.toHexString());\n  }\n  if (document instanceof MongoDB.Timestamp) {\n    // For now, the Meteor representation of a Mongo timestamp type (not a date!\n    // this is a weird internal thing used in the oplog!) is the same as the\n    // Mongo representation. We need to do this explicitly or else we would do a\n    // structural clone and lose the prototype.\n    return document;\n  }\n  if (EJSON._isCustomType(document)) {\n    return replaceNames(makeMongoLegal, EJSON.toJSONValue(document));\n  }\n  // It is not ordinarily possible to stick dollar-sign keys into mongo\n  // so we don't bother checking for things that need escaping at this time.\n  return undefined;\n};\n\nvar replaceTypes = function (document, atomTransformer) {\n  if (typeof document !== 'object' || document === null)\n    return document;\n\n  var replacedTopLevelAtom = atomTransformer(document);\n  if (replacedTopLevelAtom !== undefined)\n    return replacedTopLevelAtom;\n\n  var ret = document;\n  _.each(document, function (val, key) {\n    var valReplaced = replaceTypes(val, atomTransformer);\n    if (val !== valReplaced) {\n      // Lazy clone. Shallow copy.\n      if (ret === document)\n        ret = _.clone(document);\n      ret[key] = valReplaced;\n    }\n  });\n  return ret;\n};\n\n\nMongoConnection = function (url, options) {\n  var self = this;\n  options = options || {};\n  self._observeMultiplexers = {};\n  self._onFailoverHook = new Hook;\n\n  var mongoOptions = Object.assign({\n    // Reconnect on error.\n    autoReconnect: true,\n    // Try to reconnect forever, instead of stopping after 30 tries (the\n    // default), with each attempt separated by 1000ms.\n    reconnectTries: Infinity,\n    ignoreUndefined: true\n  }, Mongo._connectionOptions);\n\n  // Disable the native parser by default, unless specifically enabled\n  // in the mongo URL.\n  // - The native driver can cause errors which normally would be\n  //   thrown, caught, and handled into segfaults that take down the\n  //   whole app.\n  // - Binary modules don't yet work when you bundle and move the bundle\n  //   to a different platform (aka deploy)\n  // We should revisit this after binary npm module support lands.\n  if (!(/[\\?&]native_?[pP]arser=/.test(url))) {\n    mongoOptions.native_parser = false;\n  }\n\n  // Internally the oplog connections specify their own poolSize\n  // which we don't want to overwrite with any user defined value\n  if (_.has(options, 'poolSize')) {\n    // If we just set this for \"server\", replSet will override it. If we just\n    // set it for replSet, it will be ignored if we're not using a replSet.\n    mongoOptions.poolSize = options.poolSize;\n  }\n\n  self.db = null;\n  // We keep track of the ReplSet's primary, so that we can trigger hooks when\n  // it changes.  The Node driver's joined callback seems to fire way too\n  // often, which is why we need to track it ourselves.\n  self._primary = null;\n  self._oplogHandle = null;\n  self._docFetcher = null;\n\n\n  var connectFuture = new Future;\n  MongoDB.connect(\n    url,\n    mongoOptions,\n    Meteor.bindEnvironment(\n      function (err, db) {\n        if (err) {\n          throw err;\n        }\n\n        // First, figure out what the current primary is, if any.\n        if (db.serverConfig.isMasterDoc) {\n          self._primary = db.serverConfig.isMasterDoc.primary;\n        }\n\n        db.serverConfig.on(\n          'joined', Meteor.bindEnvironment(function (kind, doc) {\n            if (kind === 'primary') {\n              if (doc.primary !== self._primary) {\n                self._primary = doc.primary;\n                self._onFailoverHook.each(function (callback) {\n                  callback();\n                  return true;\n                });\n              }\n            } else if (doc.me === self._primary) {\n              // The thing we thought was primary is now something other than\n              // primary.  Forget that we thought it was primary.  (This means\n              // that if a server stops being primary and then starts being\n              // primary again without another server becoming primary in the\n              // middle, we'll correctly count it as a failover.)\n              self._primary = null;\n            }\n          }));\n\n        // Allow the constructor to return.\n        connectFuture['return'](db);\n      },\n      connectFuture.resolver()  // onException\n    )\n  );\n\n  // Wait for the connection to be successful; throws on failure.\n  self.db = connectFuture.wait();\n\n  if (options.oplogUrl && ! Package['disable-oplog']) {\n    self._oplogHandle = new OplogHandle(options.oplogUrl, self.db.databaseName);\n    self._docFetcher = new DocFetcher(self);\n  }\n};\n\nMongoConnection.prototype.close = function() {\n  var self = this;\n\n  if (! self.db)\n    throw Error(\"close called before Connection created?\");\n\n  // XXX probably untested\n  var oplogHandle = self._oplogHandle;\n  self._oplogHandle = null;\n  if (oplogHandle)\n    oplogHandle.stop();\n\n  // Use Future.wrap so that errors get thrown. This happens to\n  // work even outside a fiber since the 'close' method is not\n  // actually asynchronous.\n  Future.wrap(_.bind(self.db.close, self.db))(true).wait();\n};\n\n// Returns the Mongo Collection object; may yield.\nMongoConnection.prototype.rawCollection = function (collectionName) {\n  var self = this;\n\n  if (! self.db)\n    throw Error(\"rawCollection called before Connection created?\");\n\n  var future = new Future;\n  self.db.collection(collectionName, future.resolver());\n  return future.wait();\n};\n\nMongoConnection.prototype._createCappedCollection = function (\n    collectionName, byteSize, maxDocuments) {\n  var self = this;\n\n  if (! self.db)\n    throw Error(\"_createCappedCollection called before Connection created?\");\n\n  var future = new Future();\n  self.db.createCollection(\n    collectionName,\n    { capped: true, size: byteSize, max: maxDocuments },\n    future.resolver());\n  future.wait();\n};\n\n// This should be called synchronously with a write, to create a\n// transaction on the current write fence, if any. After we can read\n// the write, and after observers have been notified (or at least,\n// after the observer notifiers have added themselves to the write\n// fence), you should call 'committed()' on the object returned.\nMongoConnection.prototype._maybeBeginWrite = function () {\n  var fence = DDPServer._CurrentWriteFence.get();\n  if (fence) {\n    return fence.beginWrite();\n  } else {\n    return {committed: function () {}};\n  }\n};\n\n// Internal interface: adds a callback which is called when the Mongo primary\n// changes. Returns a stop handle.\nMongoConnection.prototype._onFailover = function (callback) {\n  return this._onFailoverHook.register(callback);\n};\n\n\n//////////// Public API //////////\n\n// The write methods block until the database has confirmed the write (it may\n// not be replicated or stable on disk, but one server has confirmed it) if no\n// callback is provided. If a callback is provided, then they call the callback\n// when the write is confirmed. They return nothing on success, and raise an\n// exception on failure.\n//\n// After making a write (with insert, update, remove), observers are\n// notified asynchronously. If you want to receive a callback once all\n// of the observer notifications have landed for your write, do the\n// writes inside a write fence (set DDPServer._CurrentWriteFence to a new\n// _WriteFence, and then set a callback on the write fence.)\n//\n// Since our execution environment is single-threaded, this is\n// well-defined -- a write \"has been made\" if it's returned, and an\n// observer \"has been notified\" if its callback has returned.\n\nvar writeCallback = function (write, refresh, callback) {\n  return function (err, result) {\n    if (! err) {\n      // XXX We don't have to run this on error, right?\n      try {\n        refresh();\n      } catch (refreshErr) {\n        if (callback) {\n          callback(refreshErr);\n          return;\n        } else {\n          throw refreshErr;\n        }\n      }\n    }\n    write.committed();\n    if (callback) {\n      callback(err, result);\n    } else if (err) {\n      throw err;\n    }\n  };\n};\n\nvar bindEnvironmentForWrite = function (callback) {\n  return Meteor.bindEnvironment(callback, \"Mongo write\");\n};\n\nMongoConnection.prototype._insert = function (collection_name, document,\n                                              callback) {\n  var self = this;\n\n  var sendError = function (e) {\n    if (callback)\n      return callback(e);\n    throw e;\n  };\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n    sendError(e);\n    return;\n  }\n\n  if (!(LocalCollection._isPlainObject(document) &&\n        !EJSON._isCustomType(document))) {\n    sendError(new Error(\n      \"Only plain objects may be inserted into MongoDB\"));\n    return;\n  }\n\n  var write = self._maybeBeginWrite();\n  var refresh = function () {\n    Meteor.refresh({collection: collection_name, id: document._id });\n  };\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\n  try {\n    var collection = self.rawCollection(collection_name);\n    collection.insert(replaceTypes(document, replaceMeteorAtomWithMongo),\n                      {safe: true}, callback);\n  } catch (err) {\n    write.committed();\n    throw err;\n  }\n};\n\n// Cause queries that may be affected by the selector to poll in this write\n// fence.\nMongoConnection.prototype._refresh = function (collectionName, selector) {\n  var refreshKey = {collection: collectionName};\n  // If we know which documents we're removing, don't poll queries that are\n  // specific to other documents. (Note that multiple notifications here should\n  // not cause multiple polls, since all our listener is doing is enqueueing a\n  // poll.)\n  var specificIds = LocalCollection._idsMatchedBySelector(selector);\n  if (specificIds) {\n    _.each(specificIds, function (id) {\n      Meteor.refresh(_.extend({id: id}, refreshKey));\n    });\n  } else {\n    Meteor.refresh(refreshKey);\n  }\n};\n\nMongoConnection.prototype._remove = function (collection_name, selector,\n                                              callback) {\n  var self = this;\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n    if (callback) {\n      return callback(e);\n    } else {\n      throw e;\n    }\n  }\n\n  var write = self._maybeBeginWrite();\n  var refresh = function () {\n    self._refresh(collection_name, selector);\n  };\n  callback = bindEnvironmentForWrite(writeCallback(write, refresh, callback));\n\n  try {\n    var collection = self.rawCollection(collection_name);\n    var wrappedCallback = function(err, driverResult) {\n      callback(err, transformResult(driverResult).numberAffected);\n    };\n    collection.remove(replaceTypes(selector, replaceMeteorAtomWithMongo),\n                       {safe: true}, wrappedCallback);\n  } catch (err) {\n    write.committed();\n    throw err;\n  }\n};\n\nMongoConnection.prototype._dropCollection = function (collectionName, cb) {\n  var self = this;\n\n  var write = self._maybeBeginWrite();\n  var refresh = function () {\n    Meteor.refresh({collection: collectionName, id: null,\n                    dropCollection: true});\n  };\n  cb = bindEnvironmentForWrite(writeCallback(write, refresh, cb));\n\n  try {\n    var collection = self.rawCollection(collectionName);\n    collection.drop(cb);\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n};\n\n// For testing only.  Slightly better than `c.rawDatabase().dropDatabase()`\n// because it lets the test's fence wait for it to be complete.\nMongoConnection.prototype._dropDatabase = function (cb) {\n  var self = this;\n\n  var write = self._maybeBeginWrite();\n  var refresh = function () {\n    Meteor.refresh({ dropDatabase: true });\n  };\n  cb = bindEnvironmentForWrite(writeCallback(write, refresh, cb));\n\n  try {\n    self.db.dropDatabase(cb);\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n};\n\nMongoConnection.prototype._update = function (collection_name, selector, mod,\n                                              options, callback) {\n  var self = this;\n\n  if (! callback && options instanceof Function) {\n    callback = options;\n    options = null;\n  }\n\n  if (collection_name === \"___meteor_failure_test_collection\") {\n    var e = new Error(\"Failure test\");\n    e._expectedByTest = true;\n    if (callback) {\n      return callback(e);\n    } else {\n      throw e;\n    }\n  }\n\n  // explicit safety check. null and undefined can crash the mongo\n  // driver. Although the node driver and minimongo do 'support'\n  // non-object modifier in that they don't crash, they are not\n  // meaningful operations and do not do anything. Defensively throw an\n  // error here.\n  if (!mod || typeof mod !== 'object')\n    throw new Error(\"Invalid modifier. Modifier must be an object.\");\n\n  if (!(LocalCollection._isPlainObject(mod) &&\n        !EJSON._isCustomType(mod))) {\n    throw new Error(\n      \"Only plain objects may be used as replacement\" +\n        \" documents in MongoDB\");\n  }\n\n  if (!options) options = {};\n\n  var write = self._maybeBeginWrite();\n  var refresh = function () {\n    self._refresh(collection_name, selector);\n  };\n  callback = writeCallback(write, refresh, callback);\n  try {\n    var collection = self.rawCollection(collection_name);\n    var mongoOpts = {safe: true};\n    // explictly enumerate options that minimongo supports\n    if (options.upsert) mongoOpts.upsert = true;\n    if (options.multi) mongoOpts.multi = true;\n    // Lets you get a more more full result from MongoDB. Use with caution:\n    // might not work with C.upsert (as opposed to C.update({upsert:true}) or\n    // with simulated upsert.\n    if (options.fullResult) mongoOpts.fullResult = true;\n\n    var mongoSelector = replaceTypes(selector, replaceMeteorAtomWithMongo);\n    var mongoMod = replaceTypes(mod, replaceMeteorAtomWithMongo);\n\n    var isModify = LocalCollection._isModificationMod(mongoMod);\n\n    if (options._forbidReplace && !isModify) {\n      var err = new Error(\"Invalid modifier. Replacements are forbidden.\");\n      if (callback) {\n        return callback(err);\n      } else {\n        throw err;\n      }\n    }\n\n    // We've already run replaceTypes/replaceMeteorAtomWithMongo on\n    // selector and mod.  We assume it doesn't matter, as far as\n    // the behavior of modifiers is concerned, whether `_modify`\n    // is run on EJSON or on mongo-converted EJSON.\n\n    // Run this code up front so that it fails fast if someone uses\n    // a Mongo update operator we don't support.\n    let knownId;\n    if (options.upsert) {\n      try {\n        let newDoc = LocalCollection._createUpsertDocument(selector, mod);\n        knownId = newDoc._id;\n      } catch (err) {\n        if (callback) {\n          return callback(err);\n        } else {\n          throw err;\n        }\n      }\n    }\n\n    if (options.upsert &&\n        ! isModify &&\n        ! knownId &&\n        options.insertedId &&\n        ! (options.insertedId instanceof Mongo.ObjectID &&\n           options.generatedId)) {\n      // In case of an upsert with a replacement, where there is no _id defined\n      // in either the query or the replacement doc, mongo will generate an id itself.\n      // Therefore we need this special strategy if we want to control the id ourselves.\n\n      // We don't need to do this when:\n      // - This is not a replacement, so we can add an _id to $setOnInsert\n      // - The id is defined by query or mod we can just add it to the replacement doc\n      // - The user did not specify any id preference and the id is a Mongo ObjectId,\n      //     then we can just let Mongo generate the id\n\n      simulateUpsertWithInsertedId(\n        collection, mongoSelector, mongoMod, options,\n        // This callback does not need to be bindEnvironment'ed because\n        // simulateUpsertWithInsertedId() wraps it and then passes it through\n        // bindEnvironmentForWrite.\n        function (error, result) {\n          // If we got here via a upsert() call, then options._returnObject will\n          // be set and we should return the whole object. Otherwise, we should\n          // just return the number of affected docs to match the mongo API.\n          if (result && ! options._returnObject) {\n            callback(error, result.numberAffected);\n          } else {\n            callback(error, result);\n          }\n        }\n      );\n    } else {\n\n      if (options.upsert && !knownId && options.insertedId && isModify) {\n        if (!mongoMod.hasOwnProperty('$setOnInsert')) {\n          mongoMod.$setOnInsert = {};\n        }\n        knownId = options.insertedId;\n        Object.assign(mongoMod.$setOnInsert, replaceTypes({_id: options.insertedId}, replaceMeteorAtomWithMongo));\n      }\n\n      collection.update(\n        mongoSelector, mongoMod, mongoOpts,\n        bindEnvironmentForWrite(function (err, result) {\n          if (! err) {\n            var meteorResult = transformResult(result);\n            if (meteorResult && options._returnObject) {\n              // If this was an upsert() call, and we ended up\n              // inserting a new doc and we know its id, then\n              // return that id as well.\n              if (options.upsert && meteorResult.insertedId) {\n                if (knownId) {\n                  meteorResult.insertedId = knownId;\n                } else if (meteorResult.insertedId instanceof MongoDB.ObjectID) {\n                  meteorResult.insertedId = new Mongo.ObjectID(meteorResult.insertedId.toHexString());\n                }\n              }\n\n              callback(err, meteorResult);\n            } else {\n              callback(err, meteorResult.numberAffected);\n            }\n          } else {\n            callback(err);\n          }\n        }));\n    }\n  } catch (e) {\n    write.committed();\n    throw e;\n  }\n};\n\nvar transformResult = function (driverResult) {\n  var meteorResult = { numberAffected: 0 };\n  if (driverResult) {\n    var mongoResult = driverResult.result;\n\n    // On updates with upsert:true, the inserted values come as a list of\n    // upserted values -- even with options.multi, when the upsert does insert,\n    // it only inserts one element.\n    if (mongoResult.upserted) {\n      meteorResult.numberAffected += mongoResult.upserted.length;\n\n      if (mongoResult.upserted.length == 1) {\n        meteorResult.insertedId = mongoResult.upserted[0]._id;\n      }\n    } else {\n      meteorResult.numberAffected = mongoResult.n;\n    }\n  }\n\n  return meteorResult;\n};\n\n\nvar NUM_OPTIMISTIC_TRIES = 3;\n\n// exposed for testing\nMongoConnection._isCannotChangeIdError = function (err) {\n\n  // Mongo 3.2.* returns error as next Object:\n  // {name: String, code: Number, errmsg: String}\n  // Older Mongo returns:\n  // {name: String, code: Number, err: String}\n  var error = err.errmsg || err.err;\n\n  // We don't use the error code here\n  // because the error code we observed it producing (16837) appears to be\n  // a far more generic error code based on examining the source.\n  if (error.indexOf('The _id field cannot be changed') === 0\n    || error.indexOf(\"the (immutable) field '_id' was found to have been altered to _id\") !== -1) {\n    return true;\n  }\n\n  return false;\n};\n\nvar simulateUpsertWithInsertedId = function (collection, selector, mod,\n                                             options, callback) {\n  // STRATEGY: First try doing an upsert with a generated ID.\n  // If this throws an error about changing the ID on an existing document\n  // then without affecting the database, we know we should probably try\n  // an update without the generated ID. If it affected 0 documents,\n  // then without affecting the database, we the document that first\n  // gave the error is probably removed and we need to try an insert again\n  // We go back to step one and repeat.\n  // Like all \"optimistic write\" schemes, we rely on the fact that it's\n  // unlikely our writes will continue to be interfered with under normal\n  // circumstances (though sufficiently heavy contention with writers\n  // disagreeing on the existence of an object will cause writes to fail\n  // in theory).\n\n  var insertedId = options.insertedId; // must exist\n  var mongoOptsForUpdate = {\n    safe: true,\n    multi: options.multi\n  };\n  var mongoOptsForInsert = {\n    safe: true,\n    upsert: true\n  };\n\n  var replacementWithId = Object.assign(\n    replaceTypes({_id: insertedId}, replaceMeteorAtomWithMongo),\n    mod);\n\n  var tries = NUM_OPTIMISTIC_TRIES;\n\n  var doUpdate = function () {\n    tries--;\n    if (! tries) {\n      callback(new Error(\"Upsert failed after \" + NUM_OPTIMISTIC_TRIES + \" tries.\"));\n    } else {\n      collection.update(selector, mod, mongoOptsForUpdate,\n                        bindEnvironmentForWrite(function (err, result) {\n                          if (err) {\n                            callback(err);\n                          } else if (result && result.result.n != 0) {\n                            callback(null, {\n                              numberAffected: result.result.n\n                            });\n                          } else {\n                            doConditionalInsert();\n                          }\n                        }));\n    }\n  };\n\n  var doConditionalInsert = function () {\n    collection.update(selector, replacementWithId, mongoOptsForInsert,\n                      bindEnvironmentForWrite(function (err, result) {\n                        if (err) {\n                          // figure out if this is a\n                          // \"cannot change _id of document\" error, and\n                          // if so, try doUpdate() again, up to 3 times.\n                          if (MongoConnection._isCannotChangeIdError(err)) {\n                            doUpdate();\n                          } else {\n                            callback(err);\n                          }\n                        } else {\n                          callback(null, {\n                            numberAffected: result.result.upserted.length,\n                            insertedId: insertedId,\n                          });\n                        }\n                      }));\n  };\n\n  doUpdate();\n};\n\n_.each([\"insert\", \"update\", \"remove\", \"dropCollection\", \"dropDatabase\"], function (method) {\n  MongoConnection.prototype[method] = function (/* arguments */) {\n    var self = this;\n    return Meteor.wrapAsync(self[\"_\" + method]).apply(self, arguments);\n  };\n});\n\n// XXX MongoConnection.upsert() does not return the id of the inserted document\n// unless you set it explicitly in the selector or modifier (as a replacement\n// doc).\nMongoConnection.prototype.upsert = function (collectionName, selector, mod,\n                                             options, callback) {\n  var self = this;\n  if (typeof options === \"function\" && ! callback) {\n    callback = options;\n    options = {};\n  }\n\n  return self.update(collectionName, selector, mod,\n                     _.extend({}, options, {\n                       upsert: true,\n                       _returnObject: true\n                     }), callback);\n};\n\nMongoConnection.prototype.find = function (collectionName, selector, options) {\n  var self = this;\n\n  if (arguments.length === 1)\n    selector = {};\n\n  return new Cursor(\n    self, new CursorDescription(collectionName, selector, options));\n};\n\nMongoConnection.prototype.findOne = function (collection_name, selector,\n                                              options) {\n  var self = this;\n  if (arguments.length === 1)\n    selector = {};\n\n  options = options || {};\n  options.limit = 1;\n  return self.find(collection_name, selector, options).fetch()[0];\n};\n\n// We'll actually design an index API later. For now, we just pass through to\n// Mongo's, but make it synchronous.\nMongoConnection.prototype._ensureIndex = function (collectionName, index,\n                                                   options) {\n  var self = this;\n\n  // We expect this function to be called at startup, not from within a method,\n  // so we don't interact with the write fence.\n  var collection = self.rawCollection(collectionName);\n  var future = new Future;\n  var indexName = collection.ensureIndex(index, options, future.resolver());\n  future.wait();\n};\nMongoConnection.prototype._dropIndex = function (collectionName, index) {\n  var self = this;\n\n  // This function is only used by test code, not within a method, so we don't\n  // interact with the write fence.\n  var collection = self.rawCollection(collectionName);\n  var future = new Future;\n  var indexName = collection.dropIndex(index, future.resolver());\n  future.wait();\n};\n\n// CURSORS\n\n// There are several classes which relate to cursors:\n//\n// CursorDescription represents the arguments used to construct a cursor:\n// collectionName, selector, and (find) options.  Because it is used as a key\n// for cursor de-dup, everything in it should either be JSON-stringifiable or\n// not affect observeChanges output (eg, options.transform functions are not\n// stringifiable but do not affect observeChanges).\n//\n// SynchronousCursor is a wrapper around a MongoDB cursor\n// which includes fully-synchronous versions of forEach, etc.\n//\n// Cursor is the cursor object returned from find(), which implements the\n// documented Mongo.Collection cursor API.  It wraps a CursorDescription and a\n// SynchronousCursor (lazily: it doesn't contact Mongo until you call a method\n// like fetch or forEach on it).\n//\n// ObserveHandle is the \"observe handle\" returned from observeChanges. It has a\n// reference to an ObserveMultiplexer.\n//\n// ObserveMultiplexer allows multiple identical ObserveHandles to be driven by a\n// single observe driver.\n//\n// There are two \"observe drivers\" which drive ObserveMultiplexers:\n//   - PollingObserveDriver caches the results of a query and reruns it when\n//     necessary.\n//   - OplogObserveDriver follows the Mongo operation log to directly observe\n//     database changes.\n// Both implementations follow the same simple interface: when you create them,\n// they start sending observeChanges callbacks (and a ready() invocation) to\n// their ObserveMultiplexer, and you stop them by calling their stop() method.\n\nCursorDescription = function (collectionName, selector, options) {\n  var self = this;\n  self.collectionName = collectionName;\n  self.selector = Mongo.Collection._rewriteSelector(selector);\n  self.options = options || {};\n};\n\nCursor = function (mongo, cursorDescription) {\n  var self = this;\n\n  self._mongo = mongo;\n  self._cursorDescription = cursorDescription;\n  self._synchronousCursor = null;\n};\n\n_.each(['forEach', 'map', 'fetch', 'count', Symbol.iterator], function (method) {\n  Cursor.prototype[method] = function () {\n    var self = this;\n\n    // You can only observe a tailable cursor.\n    if (self._cursorDescription.options.tailable)\n      throw new Error(\"Cannot call \" + method + \" on a tailable cursor\");\n\n    if (!self._synchronousCursor) {\n      self._synchronousCursor = self._mongo._createSynchronousCursor(\n        self._cursorDescription, {\n          // Make sure that the \"self\" argument to forEach/map callbacks is the\n          // Cursor, not the SynchronousCursor.\n          selfForIteration: self,\n          useTransform: true\n        });\n    }\n\n    return self._synchronousCursor[method].apply(\n      self._synchronousCursor, arguments);\n  };\n});\n\n// Since we don't actually have a \"nextObject\" interface, there's really no\n// reason to have a \"rewind\" interface.  All it did was make multiple calls\n// to fetch/map/forEach return nothing the second time.\n// XXX COMPAT WITH 0.8.1\nCursor.prototype.rewind = function () {\n};\n\nCursor.prototype.getTransform = function () {\n  return this._cursorDescription.options.transform;\n};\n\n// When you call Meteor.publish() with a function that returns a Cursor, we need\n// to transmute it into the equivalent subscription.  This is the function that\n// does that.\n\nCursor.prototype._publishCursor = function (sub) {\n  var self = this;\n  var collection = self._cursorDescription.collectionName;\n  return Mongo.Collection._publishCursor(self, sub, collection);\n};\n\n// Used to guarantee that publish functions return at most one cursor per\n// collection. Private, because we might later have cursors that include\n// documents from multiple collections somehow.\nCursor.prototype._getCollectionName = function () {\n  var self = this;\n  return self._cursorDescription.collectionName;\n};\n\nCursor.prototype.observe = function (callbacks) {\n  var self = this;\n  return LocalCollection._observeFromObserveChanges(self, callbacks);\n};\n\nCursor.prototype.observeChanges = function (callbacks) {\n  var self = this;\n  var methods = [\n    'addedAt',\n    'added',\n    'changedAt',\n    'changed',\n    'removedAt',\n    'removed',\n    'movedTo'\n  ];\n  var ordered = LocalCollection._observeChangesCallbacksAreOrdered(callbacks);\n\n  // XXX: Can we find out if callbacks are from observe?\n  var exceptionName = ' observe/observeChanges callback';\n  methods.forEach(function (method) {\n    if (callbacks[method] && typeof callbacks[method] == \"function\") {\n      callbacks[method] = Meteor.bindEnvironment(callbacks[method], method + exceptionName);\n    }\n  });\n\n  return self._mongo._observeChanges(\n    self._cursorDescription, ordered, callbacks);\n};\n\nMongoConnection.prototype._createSynchronousCursor = function(\n    cursorDescription, options) {\n  var self = this;\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\n\n  var collection = self.rawCollection(cursorDescription.collectionName);\n  var cursorOptions = cursorDescription.options;\n  var mongoOptions = {\n    sort: cursorOptions.sort,\n    limit: cursorOptions.limit,\n    skip: cursorOptions.skip\n  };\n\n  // Do we want a tailable cursor (which only works on capped collections)?\n  if (cursorOptions.tailable) {\n    // We want a tailable cursor...\n    mongoOptions.tailable = true;\n    // ... and for the server to wait a bit if any getMore has no data (rather\n    // than making us put the relevant sleeps in the client)...\n    mongoOptions.awaitdata = true;\n    // ... and to keep querying the server indefinitely rather than just 5 times\n    // if there's no more data.\n    mongoOptions.numberOfRetries = -1;\n    // And if this is on the oplog collection and the cursor specifies a 'ts',\n    // then set the undocumented oplog replay flag, which does a special scan to\n    // find the first document (instead of creating an index on ts). This is a\n    // very hard-coded Mongo flag which only works on the oplog collection and\n    // only works with the ts field.\n    if (cursorDescription.collectionName === OPLOG_COLLECTION &&\n        cursorDescription.selector.ts) {\n      mongoOptions.oplogReplay = true;\n    }\n  }\n\n  var dbCursor = collection.find(\n    replaceTypes(cursorDescription.selector, replaceMeteorAtomWithMongo),\n    cursorOptions.fields, mongoOptions);\n\n  if (typeof cursorOptions.maxTimeMs !== 'undefined') {\n    dbCursor = dbCursor.maxTimeMS(cursorOptions.maxTimeMs);\n  }\n  if (typeof cursorOptions.hint !== 'undefined') {\n    dbCursor = dbCursor.hint(cursorOptions.hint);\n  }\n\n  return new SynchronousCursor(dbCursor, cursorDescription, options);\n};\n\nvar SynchronousCursor = function (dbCursor, cursorDescription, options) {\n  var self = this;\n  options = _.pick(options || {}, 'selfForIteration', 'useTransform');\n\n  self._dbCursor = dbCursor;\n  self._cursorDescription = cursorDescription;\n  // The \"self\" argument passed to forEach/map callbacks. If we're wrapped\n  // inside a user-visible Cursor, we want to provide the outer cursor!\n  self._selfForIteration = options.selfForIteration || self;\n  if (options.useTransform && cursorDescription.options.transform) {\n    self._transform = LocalCollection.wrapTransform(\n      cursorDescription.options.transform);\n  } else {\n    self._transform = null;\n  }\n\n  // Need to specify that the callback is the first argument to nextObject,\n  // since otherwise when we try to call it with no args the driver will\n  // interpret \"undefined\" first arg as an options hash and crash.\n  self._synchronousNextObject = Future.wrap(\n    dbCursor.nextObject.bind(dbCursor), 0);\n  self._synchronousCount = Future.wrap(dbCursor.count.bind(dbCursor));\n  self._visitedIds = new LocalCollection._IdMap;\n};\n\n_.extend(SynchronousCursor.prototype, {\n  _nextObject: function () {\n    var self = this;\n\n    while (true) {\n      var doc = self._synchronousNextObject().wait();\n\n      if (!doc) return null;\n      doc = replaceTypes(doc, replaceMongoAtomWithMeteor);\n\n      if (!self._cursorDescription.options.tailable && _.has(doc, '_id')) {\n        // Did Mongo give us duplicate documents in the same cursor? If so,\n        // ignore this one. (Do this before the transform, since transform might\n        // return some unrelated value.) We don't do this for tailable cursors,\n        // because we want to maintain O(1) memory usage. And if there isn't _id\n        // for some reason (maybe it's the oplog), then we don't do this either.\n        // (Be careful to do this for falsey but existing _id, though.)\n        if (self._visitedIds.has(doc._id)) continue;\n        self._visitedIds.set(doc._id, true);\n      }\n\n      if (self._transform)\n        doc = self._transform(doc);\n\n      return doc;\n    }\n  },\n\n  forEach: function (callback, thisArg) {\n    var self = this;\n\n    // Get back to the beginning.\n    self._rewind();\n\n    // We implement the loop ourself instead of using self._dbCursor.each,\n    // because \"each\" will call its callback outside of a fiber which makes it\n    // much more complex to make this function synchronous.\n    var index = 0;\n    while (true) {\n      var doc = self._nextObject();\n      if (!doc) return;\n      callback.call(thisArg, doc, index++, self._selfForIteration);\n    }\n  },\n\n  // XXX Allow overlapping callback executions if callback yields.\n  map: function (callback, thisArg) {\n    var self = this;\n    var res = [];\n    self.forEach(function (doc, index) {\n      res.push(callback.call(thisArg, doc, index, self._selfForIteration));\n    });\n    return res;\n  },\n\n  _rewind: function () {\n    var self = this;\n\n    // known to be synchronous\n    self._dbCursor.rewind();\n\n    self._visitedIds = new LocalCollection._IdMap;\n  },\n\n  // Mostly usable for tailable cursors.\n  close: function () {\n    var self = this;\n\n    self._dbCursor.close();\n  },\n\n  fetch: function () {\n    var self = this;\n    return self.map(_.identity);\n  },\n\n  count: function (applySkipLimit = false) {\n    var self = this;\n    return self._synchronousCount(applySkipLimit).wait();\n  },\n\n  // This method is NOT wrapped in Cursor.\n  getRawObjects: function (ordered) {\n    var self = this;\n    if (ordered) {\n      return self.fetch();\n    } else {\n      var results = new LocalCollection._IdMap;\n      self.forEach(function (doc) {\n        results.set(doc._id, doc);\n      });\n      return results;\n    }\n  }\n});\n\nSynchronousCursor.prototype[Symbol.iterator] = function () {\n  var self = this;\n\n  // Get back to the beginning.\n  self._rewind();\n\n  return {\n    next() {\n      const doc = self._nextObject();\n      return doc ? {\n        value: doc\n      } : {\n        done: true\n      };\n    }\n  };\n};\n\nMongoConnection.prototype.tail = function (cursorDescription, docCallback) {\n  var self = this;\n  if (!cursorDescription.options.tailable)\n    throw new Error(\"Can only tail a tailable cursor\");\n\n  var cursor = self._createSynchronousCursor(cursorDescription);\n\n  var stopped = false;\n  var lastTS;\n  var loop = function () {\n    var doc = null;\n    while (true) {\n      if (stopped)\n        return;\n      try {\n        doc = cursor._nextObject();\n      } catch (err) {\n        // There's no good way to figure out if this was actually an error\n        // from Mongo. Ah well. But either way, we need to retry the cursor\n        // (unless the failure was because the observe got stopped).\n        doc = null;\n      }\n      // Since cursor._nextObject can yield, we need to check again to see if\n      // we've been stopped before calling the callback.\n      if (stopped)\n        return;\n      if (doc) {\n        // If a tailable cursor contains a \"ts\" field, use it to recreate the\n        // cursor on error. (\"ts\" is a standard that Mongo uses internally for\n        // the oplog, and there's a special flag that lets you do binary search\n        // on it instead of needing to use an index.)\n        lastTS = doc.ts;\n        docCallback(doc);\n      } else {\n        var newSelector = _.clone(cursorDescription.selector);\n        if (lastTS) {\n          newSelector.ts = {$gt: lastTS};\n        }\n        cursor = self._createSynchronousCursor(new CursorDescription(\n          cursorDescription.collectionName,\n          newSelector,\n          cursorDescription.options));\n        // Mongo failover takes many seconds.  Retry in a bit.  (Without this\n        // setTimeout, we peg the CPU at 100% and never notice the actual\n        // failover.\n        Meteor.setTimeout(loop, 100);\n        break;\n      }\n    }\n  };\n\n  Meteor.defer(loop);\n\n  return {\n    stop: function () {\n      stopped = true;\n      cursor.close();\n    }\n  };\n};\n\nMongoConnection.prototype._observeChanges = function (\n    cursorDescription, ordered, callbacks) {\n  var self = this;\n\n  if (cursorDescription.options.tailable) {\n    return self._observeChangesTailable(cursorDescription, ordered, callbacks);\n  }\n\n  // You may not filter out _id when observing changes, because the id is a core\n  // part of the observeChanges API.\n  if (cursorDescription.options.fields &&\n      (cursorDescription.options.fields._id === 0 ||\n       cursorDescription.options.fields._id === false)) {\n    throw Error(\"You may not observe a cursor with {fields: {_id: 0}}\");\n  }\n\n  var observeKey = EJSON.stringify(\n    _.extend({ordered: ordered}, cursorDescription));\n\n  var multiplexer, observeDriver;\n  var firstHandle = false;\n\n  // Find a matching ObserveMultiplexer, or create a new one. This next block is\n  // guaranteed to not yield (and it doesn't call anything that can observe a\n  // new query), so no other calls to this function can interleave with it.\n  Meteor._noYieldsAllowed(function () {\n    if (_.has(self._observeMultiplexers, observeKey)) {\n      multiplexer = self._observeMultiplexers[observeKey];\n    } else {\n      firstHandle = true;\n      // Create a new ObserveMultiplexer.\n      multiplexer = new ObserveMultiplexer({\n        ordered: ordered,\n        onStop: function () {\n          delete self._observeMultiplexers[observeKey];\n          observeDriver.stop();\n        }\n      });\n      self._observeMultiplexers[observeKey] = multiplexer;\n    }\n  });\n\n  var observeHandle = new ObserveHandle(multiplexer, callbacks);\n\n  if (firstHandle) {\n    var matcher, sorter;\n    var canUseOplog = _.all([\n      function () {\n        // At a bare minimum, using the oplog requires us to have an oplog, to\n        // want unordered callbacks, and to not want a callback on the polls\n        // that won't happen.\n        return self._oplogHandle && !ordered &&\n          !callbacks._testOnlyPollCallback;\n      }, function () {\n        // We need to be able to compile the selector. Fall back to polling for\n        // some newfangled $selector that minimongo doesn't support yet.\n        try {\n          matcher = new Minimongo.Matcher(cursorDescription.selector);\n          return true;\n        } catch (e) {\n          // XXX make all compilation errors MinimongoError or something\n          //     so that this doesn't ignore unrelated exceptions\n          return false;\n        }\n      }, function () {\n        // ... and the selector itself needs to support oplog.\n        return OplogObserveDriver.cursorSupported(cursorDescription, matcher);\n      }, function () {\n        // And we need to be able to compile the sort, if any.  eg, can't be\n        // {$natural: 1}.\n        if (!cursorDescription.options.sort)\n          return true;\n        try {\n          sorter = new Minimongo.Sorter(cursorDescription.options.sort,\n                                        { matcher: matcher });\n          return true;\n        } catch (e) {\n          // XXX make all compilation errors MinimongoError or something\n          //     so that this doesn't ignore unrelated exceptions\n          return false;\n        }\n      }], function (f) { return f(); });  // invoke each function\n\n    var driverClass = canUseOplog ? OplogObserveDriver : PollingObserveDriver;\n    observeDriver = new driverClass({\n      cursorDescription: cursorDescription,\n      mongoHandle: self,\n      multiplexer: multiplexer,\n      ordered: ordered,\n      matcher: matcher,  // ignored by polling\n      sorter: sorter,  // ignored by polling\n      _testOnlyPollCallback: callbacks._testOnlyPollCallback\n    });\n\n    // This field is only set for use in tests.\n    multiplexer._observeDriver = observeDriver;\n  }\n\n  // Blocks until the initial adds have been sent.\n  multiplexer.addHandleAndSendInitialAdds(observeHandle);\n\n  return observeHandle;\n};\n\n// Listen for the invalidation messages that will trigger us to poll the\n// database for changes. If this selector specifies specific IDs, specify them\n// here, so that updates to different specific IDs don't cause us to poll.\n// listenCallback is the same kind of (notification, complete) callback passed\n// to InvalidationCrossbar.listen.\n\nlistenAll = function (cursorDescription, listenCallback) {\n  var listeners = [];\n  forEachTrigger(cursorDescription, function (trigger) {\n    listeners.push(DDPServer._InvalidationCrossbar.listen(\n      trigger, listenCallback));\n  });\n\n  return {\n    stop: function () {\n      _.each(listeners, function (listener) {\n        listener.stop();\n      });\n    }\n  };\n};\n\nforEachTrigger = function (cursorDescription, triggerCallback) {\n  var key = {collection: cursorDescription.collectionName};\n  var specificIds = LocalCollection._idsMatchedBySelector(\n    cursorDescription.selector);\n  if (specificIds) {\n    _.each(specificIds, function (id) {\n      triggerCallback(_.extend({id: id}, key));\n    });\n    triggerCallback(_.extend({dropCollection: true, id: null}, key));\n  } else {\n    triggerCallback(key);\n  }\n  // Everyone cares about the database being dropped.\n  triggerCallback({ dropDatabase: true });\n};\n\n// observeChanges for tailable cursors on capped collections.\n//\n// Some differences from normal cursors:\n//   - Will never produce anything other than 'added' or 'addedBefore'. If you\n//     do update a document that has already been produced, this will not notice\n//     it.\n//   - If you disconnect and reconnect from Mongo, it will essentially restart\n//     the query, which will lead to duplicate results. This is pretty bad,\n//     but if you include a field called 'ts' which is inserted as\n//     new MongoInternals.MongoTimestamp(0, 0) (which is initialized to the\n//     current Mongo-style timestamp), we'll be able to find the place to\n//     restart properly. (This field is specifically understood by Mongo with an\n//     optimization which allows it to find the right place to start without\n//     an index on ts. It's how the oplog works.)\n//   - No callbacks are triggered synchronously with the call (there's no\n//     differentiation between \"initial data\" and \"later changes\"; everything\n//     that matches the query gets sent asynchronously).\n//   - De-duplication is not implemented.\n//   - Does not yet interact with the write fence. Probably, this should work by\n//     ignoring removes (which don't work on capped collections) and updates\n//     (which don't affect tailable cursors), and just keeping track of the ID\n//     of the inserted object, and closing the write fence once you get to that\n//     ID (or timestamp?).  This doesn't work well if the document doesn't match\n//     the query, though.  On the other hand, the write fence can close\n//     immediately if it does not match the query. So if we trust minimongo\n//     enough to accurately evaluate the query against the write fence, we\n//     should be able to do this...  Of course, minimongo doesn't even support\n//     Mongo Timestamps yet.\nMongoConnection.prototype._observeChangesTailable = function (\n    cursorDescription, ordered, callbacks) {\n  var self = this;\n\n  // Tailable cursors only ever call added/addedBefore callbacks, so it's an\n  // error if you didn't provide them.\n  if ((ordered && !callbacks.addedBefore) ||\n      (!ordered && !callbacks.added)) {\n    throw new Error(\"Can't observe an \" + (ordered ? \"ordered\" : \"unordered\")\n                    + \" tailable cursor without a \"\n                    + (ordered ? \"addedBefore\" : \"added\") + \" callback\");\n  }\n\n  return self.tail(cursorDescription, function (doc) {\n    var id = doc._id;\n    delete doc._id;\n    // The ts is an implementation detail. Hide it.\n    delete doc.ts;\n    if (ordered) {\n      callbacks.addedBefore(id, doc, null);\n    } else {\n      callbacks.added(id, doc);\n    }\n  });\n};\n\n// XXX We probably need to find a better way to expose this. Right now\n// it's only used by tests, but in fact you need it in normal\n// operation to interact with capped collections.\nMongoInternals.MongoTimestamp = MongoDB.Timestamp;\n\nMongoInternals.Connection = MongoConnection;\n","var Future = Npm.require('fibers/future');\n\nOPLOG_COLLECTION = 'oplog.rs';\n\nvar TOO_FAR_BEHIND = process.env.METEOR_OPLOG_TOO_FAR_BEHIND || 2000;\n\nvar showTS = function (ts) {\n  return \"Timestamp(\" + ts.getHighBits() + \", \" + ts.getLowBits() + \")\";\n};\n\nidForOp = function (op) {\n  if (op.op === 'd')\n    return op.o._id;\n  else if (op.op === 'i')\n    return op.o._id;\n  else if (op.op === 'u')\n    return op.o2._id;\n  else if (op.op === 'c')\n    throw Error(\"Operator 'c' doesn't supply an object with id: \" +\n                EJSON.stringify(op));\n  else\n    throw Error(\"Unknown op: \" + EJSON.stringify(op));\n};\n\nOplogHandle = function (oplogUrl, dbName) {\n  var self = this;\n  self._oplogUrl = oplogUrl;\n  self._dbName = dbName;\n\n  self._oplogLastEntryConnection = null;\n  self._oplogTailConnection = null;\n  self._stopped = false;\n  self._tailHandle = null;\n  self._readyFuture = new Future();\n  self._crossbar = new DDPServer._Crossbar({\n    factPackage: \"mongo-livedata\", factName: \"oplog-watchers\"\n  });\n  self._baseOplogSelector = {\n    ns: new RegExp('^' + Meteor._escapeRegExp(self._dbName) + '\\\\.'),\n    $or: [\n      { op: {$in: ['i', 'u', 'd']} },\n      // drop collection\n      { op: 'c', 'o.drop': { $exists: true } },\n      { op: 'c', 'o.dropDatabase': 1 },\n    ]\n  };\n\n  // Data structures to support waitUntilCaughtUp(). Each oplog entry has a\n  // MongoTimestamp object on it (which is not the same as a Date --- it's a\n  // combination of time and an incrementing counter; see\n  // http://docs.mongodb.org/manual/reference/bson-types/#timestamps).\n  //\n  // _catchingUpFutures is an array of {ts: MongoTimestamp, future: Future}\n  // objects, sorted by ascending timestamp. _lastProcessedTS is the\n  // MongoTimestamp of the last oplog entry we've processed.\n  //\n  // Each time we call waitUntilCaughtUp, we take a peek at the final oplog\n  // entry in the db.  If we've already processed it (ie, it is not greater than\n  // _lastProcessedTS), waitUntilCaughtUp immediately returns. Otherwise,\n  // waitUntilCaughtUp makes a new Future and inserts it along with the final\n  // timestamp entry that it read, into _catchingUpFutures. waitUntilCaughtUp\n  // then waits on that future, which is resolved once _lastProcessedTS is\n  // incremented to be past its timestamp by the worker fiber.\n  //\n  // XXX use a priority queue or something else that's faster than an array\n  self._catchingUpFutures = [];\n  self._lastProcessedTS = null;\n\n  self._onSkippedEntriesHook = new Hook({\n    debugPrintExceptions: \"onSkippedEntries callback\"\n  });\n\n  self._entryQueue = new Meteor._DoubleEndedQueue();\n  self._workerActive = false;\n\n  self._startTailing();\n};\n\n_.extend(OplogHandle.prototype, {\n  stop: function () {\n    var self = this;\n    if (self._stopped)\n      return;\n    self._stopped = true;\n    if (self._tailHandle)\n      self._tailHandle.stop();\n    // XXX should close connections too\n  },\n  onOplogEntry: function (trigger, callback) {\n    var self = this;\n    if (self._stopped)\n      throw new Error(\"Called onOplogEntry on stopped handle!\");\n\n    // Calling onOplogEntry requires us to wait for the tailing to be ready.\n    self._readyFuture.wait();\n\n    var originalCallback = callback;\n    callback = Meteor.bindEnvironment(function (notification) {\n      // XXX can we avoid this clone by making oplog.js careful?\n      originalCallback(EJSON.clone(notification));\n    }, function (err) {\n      Meteor._debug(\"Error in oplog callback\", err);\n    });\n    var listenHandle = self._crossbar.listen(trigger, callback);\n    return {\n      stop: function () {\n        listenHandle.stop();\n      }\n    };\n  },\n  // Register a callback to be invoked any time we skip oplog entries (eg,\n  // because we are too far behind).\n  onSkippedEntries: function (callback) {\n    var self = this;\n    if (self._stopped)\n      throw new Error(\"Called onSkippedEntries on stopped handle!\");\n    return self._onSkippedEntriesHook.register(callback);\n  },\n  // Calls `callback` once the oplog has been processed up to a point that is\n  // roughly \"now\": specifically, once we've processed all ops that are\n  // currently visible.\n  // XXX become convinced that this is actually safe even if oplogConnection\n  // is some kind of pool\n  waitUntilCaughtUp: function () {\n    var self = this;\n    if (self._stopped)\n      throw new Error(\"Called waitUntilCaughtUp on stopped handle!\");\n\n    // Calling waitUntilCaughtUp requries us to wait for the oplog connection to\n    // be ready.\n    self._readyFuture.wait();\n    var lastEntry;\n\n    while (!self._stopped) {\n      // We need to make the selector at least as restrictive as the actual\n      // tailing selector (ie, we need to specify the DB name) or else we might\n      // find a TS that won't show up in the actual tail stream.\n      try {\n        lastEntry = self._oplogLastEntryConnection.findOne(\n          OPLOG_COLLECTION, self._baseOplogSelector,\n          {fields: {ts: 1}, sort: {$natural: -1}});\n        break;\n      } catch (e) {\n        // During failover (eg) if we get an exception we should log and retry\n        // instead of crashing.\n        Meteor._debug(\"Got exception while reading last entry\", e);\n        Meteor._sleepForMs(100);\n      }\n    }\n\n    if (self._stopped)\n      return;\n\n    if (!lastEntry) {\n      // Really, nothing in the oplog? Well, we've processed everything.\n      return;\n    }\n\n    var ts = lastEntry.ts;\n    if (!ts)\n      throw Error(\"oplog entry without ts: \" + EJSON.stringify(lastEntry));\n\n    if (self._lastProcessedTS && ts.lessThanOrEqual(self._lastProcessedTS)) {\n      // We've already caught up to here.\n      return;\n    }\n\n\n    // Insert the future into our list. Almost always, this will be at the end,\n    // but it's conceivable that if we fail over from one primary to another,\n    // the oplog entries we see will go backwards.\n    var insertAfter = self._catchingUpFutures.length;\n    while (insertAfter - 1 > 0 && self._catchingUpFutures[insertAfter - 1].ts.greaterThan(ts)) {\n      insertAfter--;\n    }\n    var f = new Future;\n    self._catchingUpFutures.splice(insertAfter, 0, {ts: ts, future: f});\n    f.wait();\n  },\n  _startTailing: function () {\n    var self = this;\n    // First, make sure that we're talking to the local database.\n    var mongodbUri = Npm.require('mongodb-uri');\n    if (mongodbUri.parse(self._oplogUrl).database !== 'local') {\n      throw Error(\"$MONGO_OPLOG_URL must be set to the 'local' database of \" +\n                  \"a Mongo replica set\");\n    }\n\n    // We make two separate connections to Mongo. The Node Mongo driver\n    // implements a naive round-robin connection pool: each \"connection\" is a\n    // pool of several (5 by default) TCP connections, and each request is\n    // rotated through the pools. Tailable cursor queries block on the server\n    // until there is some data to return (or until a few seconds have\n    // passed). So if the connection pool used for tailing cursors is the same\n    // pool used for other queries, the other queries will be delayed by seconds\n    // 1/5 of the time.\n    //\n    // The tail connection will only ever be running a single tail command, so\n    // it only needs to make one underlying TCP connection.\n    self._oplogTailConnection = new MongoConnection(\n      self._oplogUrl, {poolSize: 1});\n    // XXX better docs, but: it's to get monotonic results\n    // XXX is it safe to say \"if there's an in flight query, just use its\n    //     results\"? I don't think so but should consider that\n    self._oplogLastEntryConnection = new MongoConnection(\n      self._oplogUrl, {poolSize: 1});\n\n    // Now, make sure that there actually is a repl set here. If not, oplog\n    // tailing won't ever find anything!\n    // More on the isMasterDoc\n    // https://docs.mongodb.com/manual/reference/command/isMaster/\n    var f = new Future;\n    self._oplogLastEntryConnection.db.admin().command(\n      { ismaster: 1 }, f.resolver());\n    var isMasterDoc = f.wait();\n\n    if (!(isMasterDoc && isMasterDoc.setName)) {\n      throw Error(\"$MONGO_OPLOG_URL must be set to the 'local' database of \" +\n                  \"a Mongo replica set\");\n    }\n\n    // Find the last oplog entry.\n    var lastOplogEntry = self._oplogLastEntryConnection.findOne(\n      OPLOG_COLLECTION, {}, {sort: {$natural: -1}, fields: {ts: 1}});\n\n    var oplogSelector = _.clone(self._baseOplogSelector);\n    if (lastOplogEntry) {\n      // Start after the last entry that currently exists.\n      oplogSelector.ts = {$gt: lastOplogEntry.ts};\n      // If there are any calls to callWhenProcessedLatest before any other\n      // oplog entries show up, allow callWhenProcessedLatest to call its\n      // callback immediately.\n      self._lastProcessedTS = lastOplogEntry.ts;\n    }\n\n    var cursorDescription = new CursorDescription(\n      OPLOG_COLLECTION, oplogSelector, {tailable: true});\n\n    self._tailHandle = self._oplogTailConnection.tail(\n      cursorDescription, function (doc) {\n        self._entryQueue.push(doc);\n        self._maybeStartWorker();\n      }\n    );\n    self._readyFuture.return();\n  },\n\n  _maybeStartWorker: function () {\n    var self = this;\n    if (self._workerActive)\n      return;\n    self._workerActive = true;\n    Meteor.defer(function () {\n      try {\n        while (! self._stopped && ! self._entryQueue.isEmpty()) {\n          // Are we too far behind? Just tell our observers that they need to\n          // repoll, and drop our queue.\n          if (self._entryQueue.length > TOO_FAR_BEHIND) {\n            var lastEntry = self._entryQueue.pop();\n            self._entryQueue.clear();\n\n            self._onSkippedEntriesHook.each(function (callback) {\n              callback();\n              return true;\n            });\n\n            // Free any waitUntilCaughtUp() calls that were waiting for us to\n            // pass something that we just skipped.\n            self._setLastProcessedTS(lastEntry.ts);\n            continue;\n          }\n\n          var doc = self._entryQueue.shift();\n\n          if (!(doc.ns && doc.ns.length > self._dbName.length + 1 &&\n                doc.ns.substr(0, self._dbName.length + 1) ===\n                (self._dbName + '.'))) {\n            throw new Error(\"Unexpected ns\");\n          }\n\n          var trigger = {collection: doc.ns.substr(self._dbName.length + 1),\n                         dropCollection: false,\n                         dropDatabase: false,\n                         op: doc};\n\n          // Is it a special command and the collection name is hidden somewhere\n          // in operator?\n          if (trigger.collection === \"$cmd\") {\n            if (doc.o.dropDatabase) {\n              delete trigger.collection;\n              trigger.dropDatabase = true;\n            } else if (_.has(doc.o, 'drop')) {\n              trigger.collection = doc.o.drop;\n              trigger.dropCollection = true;\n              trigger.id = null;\n            } else {\n              throw Error(\"Unknown command \" + JSON.stringify(doc));\n            }\n          } else {\n            // All other ops have an id.\n            trigger.id = idForOp(doc);\n          }\n\n          self._crossbar.fire(trigger);\n\n          // Now that we've processed this operation, process pending\n          // sequencers.\n          if (!doc.ts)\n            throw Error(\"oplog entry without ts: \" + EJSON.stringify(doc));\n          self._setLastProcessedTS(doc.ts);\n        }\n      } finally {\n        self._workerActive = false;\n      }\n    });\n  },\n  _setLastProcessedTS: function (ts) {\n    var self = this;\n    self._lastProcessedTS = ts;\n    while (!_.isEmpty(self._catchingUpFutures) && self._catchingUpFutures[0].ts.lessThanOrEqual(self._lastProcessedTS)) {\n      var sequencer = self._catchingUpFutures.shift();\n      sequencer.future.return();\n    }\n  },\n\n  //Methods used on tests to dinamically change TOO_FAR_BEHIND\n  _defineTooFarBehind: function(value) {\n    TOO_FAR_BEHIND = value;\n  },\n  _resetTooFarBehind: function() {\n    TOO_FAR_BEHIND = process.env.METEOR_OPLOG_TOO_FAR_BEHIND || 2000;\n  }\n});\n","var Future = Npm.require('fibers/future');\n\nObserveMultiplexer = function (options) {\n  var self = this;\n\n  if (!options || !_.has(options, 'ordered'))\n    throw Error(\"must specified ordered\");\n\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n    \"mongo-livedata\", \"observe-multiplexers\", 1);\n\n  self._ordered = options.ordered;\n  self._onStop = options.onStop || function () {};\n  self._queue = new Meteor._SynchronousQueue();\n  self._handles = {};\n  self._readyFuture = new Future;\n  self._cache = new LocalCollection._CachingChangeObserver({\n    ordered: options.ordered});\n  // Number of addHandleAndSendInitialAdds tasks scheduled but not yet\n  // running. removeHandle uses this to know if it's time to call the onStop\n  // callback.\n  self._addHandleTasksScheduledButNotPerformed = 0;\n\n  _.each(self.callbackNames(), function (callbackName) {\n    self[callbackName] = function (/* ... */) {\n      self._applyCallback(callbackName, _.toArray(arguments));\n    };\n  });\n};\n\n_.extend(ObserveMultiplexer.prototype, {\n  addHandleAndSendInitialAdds: function (handle) {\n    var self = this;\n\n    // Check this before calling runTask (even though runTask does the same\n    // check) so that we don't leak an ObserveMultiplexer on error by\n    // incrementing _addHandleTasksScheduledButNotPerformed and never\n    // decrementing it.\n    if (!self._queue.safeToRunTask())\n      throw new Error(\"Can't call observeChanges from an observe callback on the same query\");\n    ++self._addHandleTasksScheduledButNotPerformed;\n\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n      \"mongo-livedata\", \"observe-handles\", 1);\n\n    self._queue.runTask(function () {\n      self._handles[handle._id] = handle;\n      // Send out whatever adds we have so far (whether or not we the\n      // multiplexer is ready).\n      self._sendAdds(handle);\n      --self._addHandleTasksScheduledButNotPerformed;\n    });\n    // *outside* the task, since otherwise we'd deadlock\n    self._readyFuture.wait();\n  },\n\n  // Remove an observe handle. If it was the last observe handle, call the\n  // onStop callback; you cannot add any more observe handles after this.\n  //\n  // This is not synchronized with polls and handle additions: this means that\n  // you can safely call it from within an observe callback, but it also means\n  // that we have to be careful when we iterate over _handles.\n  removeHandle: function (id) {\n    var self = this;\n\n    // This should not be possible: you can only call removeHandle by having\n    // access to the ObserveHandle, which isn't returned to user code until the\n    // multiplex is ready.\n    if (!self._ready())\n      throw new Error(\"Can't remove handles until the multiplex is ready\");\n\n    delete self._handles[id];\n\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n      \"mongo-livedata\", \"observe-handles\", -1);\n\n    if (_.isEmpty(self._handles) &&\n        self._addHandleTasksScheduledButNotPerformed === 0) {\n      self._stop();\n    }\n  },\n  _stop: function (options) {\n    var self = this;\n    options = options || {};\n\n    // It shouldn't be possible for us to stop when all our handles still\n    // haven't been returned from observeChanges!\n    if (! self._ready() && ! options.fromQueryError)\n      throw Error(\"surprising _stop: not ready\");\n\n    // Call stop callback (which kills the underlying process which sends us\n    // callbacks and removes us from the connection's dictionary).\n    self._onStop();\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n      \"mongo-livedata\", \"observe-multiplexers\", -1);\n\n    // Cause future addHandleAndSendInitialAdds calls to throw (but the onStop\n    // callback should make our connection forget about us).\n    self._handles = null;\n  },\n\n  // Allows all addHandleAndSendInitialAdds calls to return, once all preceding\n  // adds have been processed. Does not block.\n  ready: function () {\n    var self = this;\n    self._queue.queueTask(function () {\n      if (self._ready())\n        throw Error(\"can't make ObserveMultiplex ready twice!\");\n      self._readyFuture.return();\n    });\n  },\n\n  // If trying to execute the query results in an error, call this. This is\n  // intended for permanent errors, not transient network errors that could be\n  // fixed. It should only be called before ready(), because if you called ready\n  // that meant that you managed to run the query once. It will stop this\n  // ObserveMultiplex and cause addHandleAndSendInitialAdds calls (and thus\n  // observeChanges calls) to throw the error.\n  queryError: function (err) {\n    var self = this;\n    self._queue.runTask(function () {\n      if (self._ready())\n        throw Error(\"can't claim query has an error after it worked!\");\n      self._stop({fromQueryError: true});\n      self._readyFuture.throw(err);\n    });\n  },\n\n  // Calls \"cb\" once the effects of all \"ready\", \"addHandleAndSendInitialAdds\"\n  // and observe callbacks which came before this call have been propagated to\n  // all handles. \"ready\" must have already been called on this multiplexer.\n  onFlush: function (cb) {\n    var self = this;\n    self._queue.queueTask(function () {\n      if (!self._ready())\n        throw Error(\"only call onFlush on a multiplexer that will be ready\");\n      cb();\n    });\n  },\n  callbackNames: function () {\n    var self = this;\n    if (self._ordered)\n      return [\"addedBefore\", \"changed\", \"movedBefore\", \"removed\"];\n    else\n      return [\"added\", \"changed\", \"removed\"];\n  },\n  _ready: function () {\n    return this._readyFuture.isResolved();\n  },\n  _applyCallback: function (callbackName, args) {\n    var self = this;\n    self._queue.queueTask(function () {\n      // If we stopped in the meantime, do nothing.\n      if (!self._handles)\n        return;\n\n      // First, apply the change to the cache.\n      // XXX We could make applyChange callbacks promise not to hang on to any\n      // state from their arguments (assuming that their supplied callbacks\n      // don't) and skip this clone. Currently 'changed' hangs on to state\n      // though.\n      self._cache.applyChange[callbackName].apply(null, EJSON.clone(args));\n\n      // If we haven't finished the initial adds, then we should only be getting\n      // adds.\n      if (!self._ready() &&\n          (callbackName !== 'added' && callbackName !== 'addedBefore')) {\n        throw new Error(\"Got \" + callbackName + \" during initial adds\");\n      }\n\n      // Now multiplex the callbacks out to all observe handles. It's OK if\n      // these calls yield; since we're inside a task, no other use of our queue\n      // can continue until these are done. (But we do have to be careful to not\n      // use a handle that got removed, because removeHandle does not use the\n      // queue; thus, we iterate over an array of keys that we control.)\n      _.each(_.keys(self._handles), function (handleId) {\n        var handle = self._handles && self._handles[handleId];\n        if (!handle)\n          return;\n        var callback = handle['_' + callbackName];\n        // clone arguments so that callbacks can mutate their arguments\n        callback && callback.apply(null, EJSON.clone(args));\n      });\n    });\n  },\n\n  // Sends initial adds to a handle. It should only be called from within a task\n  // (the task that is processing the addHandleAndSendInitialAdds call). It\n  // synchronously invokes the handle's added or addedBefore; there's no need to\n  // flush the queue afterwards to ensure that the callbacks get out.\n  _sendAdds: function (handle) {\n    var self = this;\n    if (self._queue.safeToRunTask())\n      throw Error(\"_sendAdds may only be called from within a task!\");\n    var add = self._ordered ? handle._addedBefore : handle._added;\n    if (!add)\n      return;\n    // note: docs may be an _IdMap or an OrderedDict\n    self._cache.docs.forEach(function (doc, id) {\n      if (!_.has(self._handles, handle._id))\n        throw Error(\"handle got removed before sending initial adds!\");\n      var fields = EJSON.clone(doc);\n      delete fields._id;\n      if (self._ordered)\n        add(id, fields, null); // we're going in order, so add at end\n      else\n        add(id, fields);\n    });\n  }\n});\n\n\nvar nextObserveHandleId = 1;\nObserveHandle = function (multiplexer, callbacks) {\n  var self = this;\n  // The end user is only supposed to call stop().  The other fields are\n  // accessible to the multiplexer, though.\n  self._multiplexer = multiplexer;\n  _.each(multiplexer.callbackNames(), function (name) {\n    if (callbacks[name]) {\n      self['_' + name] = callbacks[name];\n    } else if (name === \"addedBefore\" && callbacks.added) {\n      // Special case: if you specify \"added\" and \"movedBefore\", you get an\n      // ordered observe where for some reason you don't get ordering data on\n      // the adds.  I dunno, we wrote tests for it, there must have been a\n      // reason.\n      self._addedBefore = function (id, fields, before) {\n        callbacks.added(id, fields);\n      };\n    }\n  });\n  self._stopped = false;\n  self._id = nextObserveHandleId++;\n};\nObserveHandle.prototype.stop = function () {\n  var self = this;\n  if (self._stopped)\n    return;\n  self._stopped = true;\n  self._multiplexer.removeHandle(self._id);\n};\n","var Fiber = Npm.require('fibers');\nvar Future = Npm.require('fibers/future');\n\nDocFetcher = function (mongoConnection) {\n  var self = this;\n  self._mongoConnection = mongoConnection;\n  // Map from cache key -> [callback]\n  self._callbacksForCacheKey = {};\n};\n\n_.extend(DocFetcher.prototype, {\n  // Fetches document \"id\" from collectionName, returning it or null if not\n  // found.\n  //\n  // If you make multiple calls to fetch() with the same cacheKey (a string),\n  // DocFetcher may assume that they all return the same document. (It does\n  // not check to see if collectionName/id match.)\n  //\n  // You may assume that callback is never called synchronously (and in fact\n  // OplogObserveDriver does so).\n  fetch: function (collectionName, id, cacheKey, callback) {\n    var self = this;\n\n    check(collectionName, String);\n    // id is some sort of scalar\n    check(cacheKey, String);\n\n    // If there's already an in-progress fetch for this cache key, yield until\n    // it's done and return whatever it returns.\n    if (_.has(self._callbacksForCacheKey, cacheKey)) {\n      self._callbacksForCacheKey[cacheKey].push(callback);\n      return;\n    }\n\n    var callbacks = self._callbacksForCacheKey[cacheKey] = [callback];\n\n    Fiber(function () {\n      try {\n        var doc = self._mongoConnection.findOne(\n          collectionName, {_id: id}) || null;\n        // Return doc to all relevant callbacks. Note that this array can\n        // continue to grow during callback excecution.\n        while (!_.isEmpty(callbacks)) {\n          // Clone the document so that the various calls to fetch don't return\n          // objects that are intertwingled with each other. Clone before\n          // popping the future, so that if clone throws, the error gets passed\n          // to the next callback.\n          var clonedDoc = EJSON.clone(doc);\n          callbacks.pop()(null, clonedDoc);\n        }\n      } catch (e) {\n        while (!_.isEmpty(callbacks)) {\n          callbacks.pop()(e);\n        }\n      } finally {\n        // XXX consider keeping the doc around for a period of time before\n        // removing from the cache\n        delete self._callbacksForCacheKey[cacheKey];\n      }\n    }).run();\n  }\n});\n\nMongoTest.DocFetcher = DocFetcher;\n","PollingObserveDriver = function (options) {\n  var self = this;\n\n  self._cursorDescription = options.cursorDescription;\n  self._mongoHandle = options.mongoHandle;\n  self._ordered = options.ordered;\n  self._multiplexer = options.multiplexer;\n  self._stopCallbacks = [];\n  self._stopped = false;\n\n  self._synchronousCursor = self._mongoHandle._createSynchronousCursor(\n    self._cursorDescription);\n\n  // previous results snapshot.  on each poll cycle, diffs against\n  // results drives the callbacks.\n  self._results = null;\n\n  // The number of _pollMongo calls that have been added to self._taskQueue but\n  // have not started running. Used to make sure we never schedule more than one\n  // _pollMongo (other than possibly the one that is currently running). It's\n  // also used by _suspendPolling to pretend there's a poll scheduled. Usually,\n  // it's either 0 (for \"no polls scheduled other than maybe one currently\n  // running\") or 1 (for \"a poll scheduled that isn't running yet\"), but it can\n  // also be 2 if incremented by _suspendPolling.\n  self._pollsScheduledButNotStarted = 0;\n  self._pendingWrites = []; // people to notify when polling completes\n\n  // Make sure to create a separately throttled function for each\n  // PollingObserveDriver object.\n  self._ensurePollIsScheduled = _.throttle(\n    self._unthrottledEnsurePollIsScheduled,\n    self._cursorDescription.options.pollingThrottleMs || 50 /* ms */);\n\n  // XXX figure out if we still need a queue\n  self._taskQueue = new Meteor._SynchronousQueue();\n\n  var listenersHandle = listenAll(\n    self._cursorDescription, function (notification) {\n      // When someone does a transaction that might affect us, schedule a poll\n      // of the database. If that transaction happens inside of a write fence,\n      // block the fence until we've polled and notified observers.\n      var fence = DDPServer._CurrentWriteFence.get();\n      if (fence)\n        self._pendingWrites.push(fence.beginWrite());\n      // Ensure a poll is scheduled... but if we already know that one is,\n      // don't hit the throttled _ensurePollIsScheduled function (which might\n      // lead to us calling it unnecessarily in <pollingThrottleMs> ms).\n      if (self._pollsScheduledButNotStarted === 0)\n        self._ensurePollIsScheduled();\n    }\n  );\n  self._stopCallbacks.push(function () { listenersHandle.stop(); });\n\n  // every once and a while, poll even if we don't think we're dirty, for\n  // eventual consistency with database writes from outside the Meteor\n  // universe.\n  //\n  // For testing, there's an undocumented callback argument to observeChanges\n  // which disables time-based polling and gets called at the beginning of each\n  // poll.\n  if (options._testOnlyPollCallback) {\n    self._testOnlyPollCallback = options._testOnlyPollCallback;\n  } else {\n    var pollingInterval =\n          self._cursorDescription.options.pollingIntervalMs ||\n          self._cursorDescription.options._pollingInterval || // COMPAT with 1.2\n          10 * 1000;\n    var intervalHandle = Meteor.setInterval(\n      _.bind(self._ensurePollIsScheduled, self), pollingInterval);\n    self._stopCallbacks.push(function () {\n      Meteor.clearInterval(intervalHandle);\n    });\n  }\n\n  // Make sure we actually poll soon!\n  self._unthrottledEnsurePollIsScheduled();\n\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n    \"mongo-livedata\", \"observe-drivers-polling\", 1);\n};\n\n_.extend(PollingObserveDriver.prototype, {\n  // This is always called through _.throttle (except once at startup).\n  _unthrottledEnsurePollIsScheduled: function () {\n    var self = this;\n    if (self._pollsScheduledButNotStarted > 0)\n      return;\n    ++self._pollsScheduledButNotStarted;\n    self._taskQueue.queueTask(function () {\n      self._pollMongo();\n    });\n  },\n\n  // test-only interface for controlling polling.\n  //\n  // _suspendPolling blocks until any currently running and scheduled polls are\n  // done, and prevents any further polls from being scheduled. (new\n  // ObserveHandles can be added and receive their initial added callbacks,\n  // though.)\n  //\n  // _resumePolling immediately polls, and allows further polls to occur.\n  _suspendPolling: function() {\n    var self = this;\n    // Pretend that there's another poll scheduled (which will prevent\n    // _ensurePollIsScheduled from queueing any more polls).\n    ++self._pollsScheduledButNotStarted;\n    // Now block until all currently running or scheduled polls are done.\n    self._taskQueue.runTask(function() {});\n\n    // Confirm that there is only one \"poll\" (the fake one we're pretending to\n    // have) scheduled.\n    if (self._pollsScheduledButNotStarted !== 1)\n      throw new Error(\"_pollsScheduledButNotStarted is \" +\n                      self._pollsScheduledButNotStarted);\n  },\n  _resumePolling: function() {\n    var self = this;\n    // We should be in the same state as in the end of _suspendPolling.\n    if (self._pollsScheduledButNotStarted !== 1)\n      throw new Error(\"_pollsScheduledButNotStarted is \" +\n                      self._pollsScheduledButNotStarted);\n    // Run a poll synchronously (which will counteract the\n    // ++_pollsScheduledButNotStarted from _suspendPolling).\n    self._taskQueue.runTask(function () {\n      self._pollMongo();\n    });\n  },\n\n  _pollMongo: function () {\n    var self = this;\n    --self._pollsScheduledButNotStarted;\n\n    if (self._stopped)\n      return;\n\n    var first = false;\n    var newResults;\n    var oldResults = self._results;\n    if (!oldResults) {\n      first = true;\n      // XXX maybe use OrderedDict instead?\n      oldResults = self._ordered ? [] : new LocalCollection._IdMap;\n    }\n\n    self._testOnlyPollCallback && self._testOnlyPollCallback();\n\n    // Save the list of pending writes which this round will commit.\n    var writesForCycle = self._pendingWrites;\n    self._pendingWrites = [];\n\n    // Get the new query results. (This yields.)\n    try {\n      newResults = self._synchronousCursor.getRawObjects(self._ordered);\n    } catch (e) {\n      if (first && typeof(e.code) === 'number') {\n        // This is an error document sent to us by mongod, not a connection\n        // error generated by the client. And we've never seen this query work\n        // successfully. Probably it's a bad selector or something, so we should\n        // NOT retry. Instead, we should halt the observe (which ends up calling\n        // `stop` on us).\n        self._multiplexer.queryError(\n          new Error(\n            \"Exception while polling query \" +\n              JSON.stringify(self._cursorDescription) + \": \" + e.message));\n        return;\n      }\n\n      // getRawObjects can throw if we're having trouble talking to the\n      // database.  That's fine --- we will repoll later anyway. But we should\n      // make sure not to lose track of this cycle's writes.\n      // (It also can throw if there's just something invalid about this query;\n      // unfortunately the ObserveDriver API doesn't provide a good way to\n      // \"cancel\" the observe from the inside in this case.\n      Array.prototype.push.apply(self._pendingWrites, writesForCycle);\n      Meteor._debug(\"Exception while polling query \" +\n                    JSON.stringify(self._cursorDescription), e);\n      return;\n    }\n\n    // Run diffs.\n    if (!self._stopped) {\n      LocalCollection._diffQueryChanges(\n        self._ordered, oldResults, newResults, self._multiplexer);\n    }\n\n    // Signals the multiplexer to allow all observeChanges calls that share this\n    // multiplexer to return. (This happens asynchronously, via the\n    // multiplexer's queue.)\n    if (first)\n      self._multiplexer.ready();\n\n    // Replace self._results atomically.  (This assignment is what makes `first`\n    // stay through on the next cycle, so we've waited until after we've\n    // committed to ready-ing the multiplexer.)\n    self._results = newResults;\n\n    // Once the ObserveMultiplexer has processed everything we've done in this\n    // round, mark all the writes which existed before this call as\n    // commmitted. (If new writes have shown up in the meantime, there'll\n    // already be another _pollMongo task scheduled.)\n    self._multiplexer.onFlush(function () {\n      _.each(writesForCycle, function (w) {\n        w.committed();\n      });\n    });\n  },\n\n  stop: function () {\n    var self = this;\n    self._stopped = true;\n    _.each(self._stopCallbacks, function (c) { c(); });\n    // Release any write fences that are waiting on us.\n    _.each(self._pendingWrites, function (w) {\n      w.committed();\n    });\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n      \"mongo-livedata\", \"observe-drivers-polling\", -1);\n  }\n});\n","var Future = Npm.require('fibers/future');\n\nvar PHASE = {\n  QUERYING: \"QUERYING\",\n  FETCHING: \"FETCHING\",\n  STEADY: \"STEADY\"\n};\n\n// Exception thrown by _needToPollQuery which unrolls the stack up to the\n// enclosing call to finishIfNeedToPollQuery.\nvar SwitchedToQuery = function () {};\nvar finishIfNeedToPollQuery = function (f) {\n  return function () {\n    try {\n      f.apply(this, arguments);\n    } catch (e) {\n      if (!(e instanceof SwitchedToQuery))\n        throw e;\n    }\n  };\n};\n\nvar currentId = 0;\n\n// OplogObserveDriver is an alternative to PollingObserveDriver which follows\n// the Mongo operation log instead of just re-polling the query. It obeys the\n// same simple interface: constructing it starts sending observeChanges\n// callbacks (and a ready() invocation) to the ObserveMultiplexer, and you stop\n// it by calling the stop() method.\nOplogObserveDriver = function (options) {\n  var self = this;\n  self._usesOplog = true;  // tests look at this\n\n  self._id = currentId;\n  currentId++;\n\n  self._cursorDescription = options.cursorDescription;\n  self._mongoHandle = options.mongoHandle;\n  self._multiplexer = options.multiplexer;\n\n  if (options.ordered) {\n    throw Error(\"OplogObserveDriver only supports unordered observeChanges\");\n  }\n\n  var sorter = options.sorter;\n  // We don't support $near and other geo-queries so it's OK to initialize the\n  // comparator only once in the constructor.\n  var comparator = sorter && sorter.getComparator();\n\n  if (options.cursorDescription.options.limit) {\n    // There are several properties ordered driver implements:\n    // - _limit is a positive number\n    // - _comparator is a function-comparator by which the query is ordered\n    // - _unpublishedBuffer is non-null Min/Max Heap,\n    //                      the empty buffer in STEADY phase implies that the\n    //                      everything that matches the queries selector fits\n    //                      into published set.\n    // - _published - Min Heap (also implements IdMap methods)\n\n    var heapOptions = { IdMap: LocalCollection._IdMap };\n    self._limit = self._cursorDescription.options.limit;\n    self._comparator = comparator;\n    self._sorter = sorter;\n    self._unpublishedBuffer = new MinMaxHeap(comparator, heapOptions);\n    // We need something that can find Max value in addition to IdMap interface\n    self._published = new MaxHeap(comparator, heapOptions);\n  } else {\n    self._limit = 0;\n    self._comparator = null;\n    self._sorter = null;\n    self._unpublishedBuffer = null;\n    self._published = new LocalCollection._IdMap;\n  }\n\n  // Indicates if it is safe to insert a new document at the end of the buffer\n  // for this query. i.e. it is known that there are no documents matching the\n  // selector those are not in published or buffer.\n  self._safeAppendToBuffer = false;\n\n  self._stopped = false;\n  self._stopHandles = [];\n\n  Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n    \"mongo-livedata\", \"observe-drivers-oplog\", 1);\n\n  self._registerPhaseChange(PHASE.QUERYING);\n\n  self._matcher = options.matcher;\n  var projection = self._cursorDescription.options.fields || {};\n  self._projectionFn = LocalCollection._compileProjection(projection);\n  // Projection function, result of combining important fields for selector and\n  // existing fields projection\n  self._sharedProjection = self._matcher.combineIntoProjection(projection);\n  if (sorter)\n    self._sharedProjection = sorter.combineIntoProjection(self._sharedProjection);\n  self._sharedProjectionFn = LocalCollection._compileProjection(\n    self._sharedProjection);\n\n  self._needToFetch = new LocalCollection._IdMap;\n  self._currentlyFetching = null;\n  self._fetchGeneration = 0;\n\n  self._requeryWhenDoneThisQuery = false;\n  self._writesToCommitWhenWeReachSteady = [];\n\n  // If the oplog handle tells us that it skipped some entries (because it got\n  // behind, say), re-poll.\n  self._stopHandles.push(self._mongoHandle._oplogHandle.onSkippedEntries(\n    finishIfNeedToPollQuery(function () {\n      self._needToPollQuery();\n    })\n  ));\n\n  forEachTrigger(self._cursorDescription, function (trigger) {\n    self._stopHandles.push(self._mongoHandle._oplogHandle.onOplogEntry(\n      trigger, function (notification) {\n        Meteor._noYieldsAllowed(finishIfNeedToPollQuery(function () {\n          var op = notification.op;\n          if (notification.dropCollection || notification.dropDatabase) {\n            // Note: this call is not allowed to block on anything (especially\n            // on waiting for oplog entries to catch up) because that will block\n            // onOplogEntry!\n            self._needToPollQuery();\n          } else {\n            // All other operators should be handled depending on phase\n            if (self._phase === PHASE.QUERYING) {\n              self._handleOplogEntryQuerying(op);\n            } else {\n              self._handleOplogEntrySteadyOrFetching(op);\n            }\n          }\n        }));\n      }\n    ));\n  });\n\n  // XXX ordering w.r.t. everything else?\n  self._stopHandles.push(listenAll(\n    self._cursorDescription, function (notification) {\n      // If we're not in a pre-fire write fence, we don't have to do anything.\n      var fence = DDPServer._CurrentWriteFence.get();\n      if (!fence || fence.fired)\n        return;\n\n      if (fence._oplogObserveDrivers) {\n        fence._oplogObserveDrivers[self._id] = self;\n        return;\n      }\n\n      fence._oplogObserveDrivers = {};\n      fence._oplogObserveDrivers[self._id] = self;\n\n      fence.onBeforeFire(function () {\n        var drivers = fence._oplogObserveDrivers;\n        delete fence._oplogObserveDrivers;\n\n        // This fence cannot fire until we've caught up to \"this point\" in the\n        // oplog, and all observers made it back to the steady state.\n        self._mongoHandle._oplogHandle.waitUntilCaughtUp();\n\n        _.each(drivers, function (driver) {\n          if (driver._stopped)\n            return;\n\n          var write = fence.beginWrite();\n          if (driver._phase === PHASE.STEADY) {\n            // Make sure that all of the callbacks have made it through the\n            // multiplexer and been delivered to ObserveHandles before committing\n            // writes.\n            driver._multiplexer.onFlush(function () {\n              write.committed();\n            });\n          } else {\n            driver._writesToCommitWhenWeReachSteady.push(write);\n          }\n        });\n      });\n    }\n  ));\n\n  // When Mongo fails over, we need to repoll the query, in case we processed an\n  // oplog entry that got rolled back.\n  self._stopHandles.push(self._mongoHandle._onFailover(finishIfNeedToPollQuery(\n    function () {\n      self._needToPollQuery();\n    })));\n\n  // Give _observeChanges a chance to add the new ObserveHandle to our\n  // multiplexer, so that the added calls get streamed.\n  Meteor.defer(finishIfNeedToPollQuery(function () {\n    self._runInitialQuery();\n  }));\n};\n\n_.extend(OplogObserveDriver.prototype, {\n  _addPublished: function (id, doc) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      var fields = _.clone(doc);\n      delete fields._id;\n      self._published.set(id, self._sharedProjectionFn(doc));\n      self._multiplexer.added(id, self._projectionFn(fields));\n\n      // After adding this document, the published set might be overflowed\n      // (exceeding capacity specified by limit). If so, push the maximum\n      // element to the buffer, we might want to save it in memory to reduce the\n      // amount of Mongo lookups in the future.\n      if (self._limit && self._published.size() > self._limit) {\n        // XXX in theory the size of published is no more than limit+1\n        if (self._published.size() !== self._limit + 1) {\n          throw new Error(\"After adding to published, \" +\n                          (self._published.size() - self._limit) +\n                          \" documents are overflowing the set\");\n        }\n\n        var overflowingDocId = self._published.maxElementId();\n        var overflowingDoc = self._published.get(overflowingDocId);\n\n        if (EJSON.equals(overflowingDocId, id)) {\n          throw new Error(\"The document just added is overflowing the published set\");\n        }\n\n        self._published.remove(overflowingDocId);\n        self._multiplexer.removed(overflowingDocId);\n        self._addBuffered(overflowingDocId, overflowingDoc);\n      }\n    });\n  },\n  _removePublished: function (id) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._published.remove(id);\n      self._multiplexer.removed(id);\n      if (! self._limit || self._published.size() === self._limit)\n        return;\n\n      if (self._published.size() > self._limit)\n        throw Error(\"self._published got too big\");\n\n      // OK, we are publishing less than the limit. Maybe we should look in the\n      // buffer to find the next element past what we were publishing before.\n\n      if (!self._unpublishedBuffer.empty()) {\n        // There's something in the buffer; move the first thing in it to\n        // _published.\n        var newDocId = self._unpublishedBuffer.minElementId();\n        var newDoc = self._unpublishedBuffer.get(newDocId);\n        self._removeBuffered(newDocId);\n        self._addPublished(newDocId, newDoc);\n        return;\n      }\n\n      // There's nothing in the buffer.  This could mean one of a few things.\n\n      // (a) We could be in the middle of re-running the query (specifically, we\n      // could be in _publishNewResults). In that case, _unpublishedBuffer is\n      // empty because we clear it at the beginning of _publishNewResults. In\n      // this case, our caller already knows the entire answer to the query and\n      // we don't need to do anything fancy here.  Just return.\n      if (self._phase === PHASE.QUERYING)\n        return;\n\n      // (b) We're pretty confident that the union of _published and\n      // _unpublishedBuffer contain all documents that match selector. Because\n      // _unpublishedBuffer is empty, that means we're confident that _published\n      // contains all documents that match selector. So we have nothing to do.\n      if (self._safeAppendToBuffer)\n        return;\n\n      // (c) Maybe there are other documents out there that should be in our\n      // buffer. But in that case, when we emptied _unpublishedBuffer in\n      // _removeBuffered, we should have called _needToPollQuery, which will\n      // either put something in _unpublishedBuffer or set _safeAppendToBuffer\n      // (or both), and it will put us in QUERYING for that whole time. So in\n      // fact, we shouldn't be able to get here.\n\n      throw new Error(\"Buffer inexplicably empty\");\n    });\n  },\n  _changePublished: function (id, oldDoc, newDoc) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._published.set(id, self._sharedProjectionFn(newDoc));\n      var projectedNew = self._projectionFn(newDoc);\n      var projectedOld = self._projectionFn(oldDoc);\n      var changed = DiffSequence.makeChangedFields(\n        projectedNew, projectedOld);\n      if (!_.isEmpty(changed))\n        self._multiplexer.changed(id, changed);\n    });\n  },\n  _addBuffered: function (id, doc) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._unpublishedBuffer.set(id, self._sharedProjectionFn(doc));\n\n      // If something is overflowing the buffer, we just remove it from cache\n      if (self._unpublishedBuffer.size() > self._limit) {\n        var maxBufferedId = self._unpublishedBuffer.maxElementId();\n\n        self._unpublishedBuffer.remove(maxBufferedId);\n\n        // Since something matching is removed from cache (both published set and\n        // buffer), set flag to false\n        self._safeAppendToBuffer = false;\n      }\n    });\n  },\n  // Is called either to remove the doc completely from matching set or to move\n  // it to the published set later.\n  _removeBuffered: function (id) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._unpublishedBuffer.remove(id);\n      // To keep the contract \"buffer is never empty in STEADY phase unless the\n      // everything matching fits into published\" true, we poll everything as\n      // soon as we see the buffer becoming empty.\n      if (! self._unpublishedBuffer.size() && ! self._safeAppendToBuffer)\n        self._needToPollQuery();\n    });\n  },\n  // Called when a document has joined the \"Matching\" results set.\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\n  // and the effect of limit enforced.\n  _addMatching: function (doc) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      var id = doc._id;\n      if (self._published.has(id))\n        throw Error(\"tried to add something already published \" + id);\n      if (self._limit && self._unpublishedBuffer.has(id))\n        throw Error(\"tried to add something already existed in buffer \" + id);\n\n      var limit = self._limit;\n      var comparator = self._comparator;\n      var maxPublished = (limit && self._published.size() > 0) ?\n        self._published.get(self._published.maxElementId()) : null;\n      var maxBuffered = (limit && self._unpublishedBuffer.size() > 0)\n        ? self._unpublishedBuffer.get(self._unpublishedBuffer.maxElementId())\n        : null;\n      // The query is unlimited or didn't publish enough documents yet or the\n      // new document would fit into published set pushing the maximum element\n      // out, then we need to publish the doc.\n      var toPublish = ! limit || self._published.size() < limit ||\n        comparator(doc, maxPublished) < 0;\n\n      // Otherwise we might need to buffer it (only in case of limited query).\n      // Buffering is allowed if the buffer is not filled up yet and all\n      // matching docs are either in the published set or in the buffer.\n      var canAppendToBuffer = !toPublish && self._safeAppendToBuffer &&\n        self._unpublishedBuffer.size() < limit;\n\n      // Or if it is small enough to be safely inserted to the middle or the\n      // beginning of the buffer.\n      var canInsertIntoBuffer = !toPublish && maxBuffered &&\n        comparator(doc, maxBuffered) <= 0;\n\n      var toBuffer = canAppendToBuffer || canInsertIntoBuffer;\n\n      if (toPublish) {\n        self._addPublished(id, doc);\n      } else if (toBuffer) {\n        self._addBuffered(id, doc);\n      } else {\n        // dropping it and not saving to the cache\n        self._safeAppendToBuffer = false;\n      }\n    });\n  },\n  // Called when a document leaves the \"Matching\" results set.\n  // Takes responsibility of keeping _unpublishedBuffer in sync with _published\n  // and the effect of limit enforced.\n  _removeMatching: function (id) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      if (! self._published.has(id) && ! self._limit)\n        throw Error(\"tried to remove something matching but not cached \" + id);\n\n      if (self._published.has(id)) {\n        self._removePublished(id);\n      } else if (self._unpublishedBuffer.has(id)) {\n        self._removeBuffered(id);\n      }\n    });\n  },\n  _handleDoc: function (id, newDoc) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      var matchesNow = newDoc && self._matcher.documentMatches(newDoc).result;\n\n      var publishedBefore = self._published.has(id);\n      var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\n      var cachedBefore = publishedBefore || bufferedBefore;\n\n      if (matchesNow && !cachedBefore) {\n        self._addMatching(newDoc);\n      } else if (cachedBefore && !matchesNow) {\n        self._removeMatching(id);\n      } else if (cachedBefore && matchesNow) {\n        var oldDoc = self._published.get(id);\n        var comparator = self._comparator;\n        var minBuffered = self._limit && self._unpublishedBuffer.size() &&\n          self._unpublishedBuffer.get(self._unpublishedBuffer.minElementId());\n        var maxBuffered;\n\n        if (publishedBefore) {\n          // Unlimited case where the document stays in published once it\n          // matches or the case when we don't have enough matching docs to\n          // publish or the changed but matching doc will stay in published\n          // anyways.\n          //\n          // XXX: We rely on the emptiness of buffer. Be sure to maintain the\n          // fact that buffer can't be empty if there are matching documents not\n          // published. Notably, we don't want to schedule repoll and continue\n          // relying on this property.\n          var staysInPublished = ! self._limit ||\n            self._unpublishedBuffer.size() === 0 ||\n            comparator(newDoc, minBuffered) <= 0;\n\n          if (staysInPublished) {\n            self._changePublished(id, oldDoc, newDoc);\n          } else {\n            // after the change doc doesn't stay in the published, remove it\n            self._removePublished(id);\n            // but it can move into buffered now, check it\n            maxBuffered = self._unpublishedBuffer.get(\n              self._unpublishedBuffer.maxElementId());\n\n            var toBuffer = self._safeAppendToBuffer ||\n                  (maxBuffered && comparator(newDoc, maxBuffered) <= 0);\n\n            if (toBuffer) {\n              self._addBuffered(id, newDoc);\n            } else {\n              // Throw away from both published set and buffer\n              self._safeAppendToBuffer = false;\n            }\n          }\n        } else if (bufferedBefore) {\n          oldDoc = self._unpublishedBuffer.get(id);\n          // remove the old version manually instead of using _removeBuffered so\n          // we don't trigger the querying immediately.  if we end this block\n          // with the buffer empty, we will need to trigger the query poll\n          // manually too.\n          self._unpublishedBuffer.remove(id);\n\n          var maxPublished = self._published.get(\n            self._published.maxElementId());\n          maxBuffered = self._unpublishedBuffer.size() &&\n                self._unpublishedBuffer.get(\n                  self._unpublishedBuffer.maxElementId());\n\n          // the buffered doc was updated, it could move to published\n          var toPublish = comparator(newDoc, maxPublished) < 0;\n\n          // or stays in buffer even after the change\n          var staysInBuffer = (! toPublish && self._safeAppendToBuffer) ||\n                (!toPublish && maxBuffered &&\n                 comparator(newDoc, maxBuffered) <= 0);\n\n          if (toPublish) {\n            self._addPublished(id, newDoc);\n          } else if (staysInBuffer) {\n            // stays in buffer but changes\n            self._unpublishedBuffer.set(id, newDoc);\n          } else {\n            // Throw away from both published set and buffer\n            self._safeAppendToBuffer = false;\n            // Normally this check would have been done in _removeBuffered but\n            // we didn't use it, so we need to do it ourself now.\n            if (! self._unpublishedBuffer.size()) {\n              self._needToPollQuery();\n            }\n          }\n        } else {\n          throw new Error(\"cachedBefore implies either of publishedBefore or bufferedBefore is true.\");\n        }\n      }\n    });\n  },\n  _fetchModifiedDocuments: function () {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._registerPhaseChange(PHASE.FETCHING);\n      // Defer, because nothing called from the oplog entry handler may yield,\n      // but fetch() yields.\n      Meteor.defer(finishIfNeedToPollQuery(function () {\n        while (!self._stopped && !self._needToFetch.empty()) {\n          if (self._phase === PHASE.QUERYING) {\n            // While fetching, we decided to go into QUERYING mode, and then we\n            // saw another oplog entry, so _needToFetch is not empty. But we\n            // shouldn't fetch these documents until AFTER the query is done.\n            break;\n          }\n\n          // Being in steady phase here would be surprising.\n          if (self._phase !== PHASE.FETCHING)\n            throw new Error(\"phase in fetchModifiedDocuments: \" + self._phase);\n\n          self._currentlyFetching = self._needToFetch;\n          var thisGeneration = ++self._fetchGeneration;\n          self._needToFetch = new LocalCollection._IdMap;\n          var waiting = 0;\n          var fut = new Future;\n          // This loop is safe, because _currentlyFetching will not be updated\n          // during this loop (in fact, it is never mutated).\n          self._currentlyFetching.forEach(function (cacheKey, id) {\n            waiting++;\n            self._mongoHandle._docFetcher.fetch(\n              self._cursorDescription.collectionName, id, cacheKey,\n              finishIfNeedToPollQuery(function (err, doc) {\n                try {\n                  if (err) {\n                    Meteor._debug(\"Got exception while fetching documents\",\n                                  err);\n                    // If we get an error from the fetcher (eg, trouble\n                    // connecting to Mongo), let's just abandon the fetch phase\n                    // altogether and fall back to polling. It's not like we're\n                    // getting live updates anyway.\n                    if (self._phase !== PHASE.QUERYING) {\n                      self._needToPollQuery();\n                    }\n                  } else if (!self._stopped && self._phase === PHASE.FETCHING\n                             && self._fetchGeneration === thisGeneration) {\n                    // We re-check the generation in case we've had an explicit\n                    // _pollQuery call (eg, in another fiber) which should\n                    // effectively cancel this round of fetches.  (_pollQuery\n                    // increments the generation.)\n                    self._handleDoc(id, doc);\n                  }\n                } finally {\n                  waiting--;\n                  // Because fetch() never calls its callback synchronously,\n                  // this is safe (ie, we won't call fut.return() before the\n                  // forEach is done).\n                  if (waiting === 0)\n                    fut.return();\n                }\n              }));\n          });\n          fut.wait();\n          // Exit now if we've had a _pollQuery call (here or in another fiber).\n          if (self._phase === PHASE.QUERYING)\n            return;\n          self._currentlyFetching = null;\n        }\n        // We're done fetching, so we can be steady, unless we've had a\n        // _pollQuery call (here or in another fiber).\n        if (self._phase !== PHASE.QUERYING)\n          self._beSteady();\n      }));\n    });\n  },\n  _beSteady: function () {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._registerPhaseChange(PHASE.STEADY);\n      var writes = self._writesToCommitWhenWeReachSteady;\n      self._writesToCommitWhenWeReachSteady = [];\n      self._multiplexer.onFlush(function () {\n        _.each(writes, function (w) {\n          w.committed();\n        });\n      });\n    });\n  },\n  _handleOplogEntryQuerying: function (op) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      self._needToFetch.set(idForOp(op), op.ts.toString());\n    });\n  },\n  _handleOplogEntrySteadyOrFetching: function (op) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      var id = idForOp(op);\n      // If we're already fetching this one, or about to, we can't optimize;\n      // make sure that we fetch it again if necessary.\n      if (self._phase === PHASE.FETCHING &&\n          ((self._currentlyFetching && self._currentlyFetching.has(id)) ||\n           self._needToFetch.has(id))) {\n        self._needToFetch.set(id, op.ts.toString());\n        return;\n      }\n\n      if (op.op === 'd') {\n        if (self._published.has(id) ||\n            (self._limit && self._unpublishedBuffer.has(id)))\n          self._removeMatching(id);\n      } else if (op.op === 'i') {\n        if (self._published.has(id))\n          throw new Error(\"insert found for already-existing ID in published\");\n        if (self._unpublishedBuffer && self._unpublishedBuffer.has(id))\n          throw new Error(\"insert found for already-existing ID in buffer\");\n\n        // XXX what if selector yields?  for now it can't but later it could\n        // have $where\n        if (self._matcher.documentMatches(op.o).result)\n          self._addMatching(op.o);\n      } else if (op.op === 'u') {\n        // Is this a modifier ($set/$unset, which may require us to poll the\n        // database to figure out if the whole document matches the selector) or\n        // a replacement (in which case we can just directly re-evaluate the\n        // selector)?\n        var isReplace = !_.has(op.o, '$set') && !_.has(op.o, '$unset');\n        // If this modifier modifies something inside an EJSON custom type (ie,\n        // anything with EJSON$), then we can't try to use\n        // LocalCollection._modify, since that just mutates the EJSON encoding,\n        // not the actual object.\n        var canDirectlyModifyDoc =\n          !isReplace && modifierCanBeDirectlyApplied(op.o);\n\n        var publishedBefore = self._published.has(id);\n        var bufferedBefore = self._limit && self._unpublishedBuffer.has(id);\n\n        if (isReplace) {\n          self._handleDoc(id, _.extend({_id: id}, op.o));\n        } else if ((publishedBefore || bufferedBefore) &&\n                   canDirectlyModifyDoc) {\n          // Oh great, we actually know what the document is, so we can apply\n          // this directly.\n          var newDoc = self._published.has(id)\n            ? self._published.get(id) : self._unpublishedBuffer.get(id);\n          newDoc = EJSON.clone(newDoc);\n\n          newDoc._id = id;\n          try {\n            LocalCollection._modify(newDoc, op.o);\n          } catch (e) {\n            if (e.name !== \"MinimongoError\")\n              throw e;\n            // We didn't understand the modifier.  Re-fetch.\n            self._needToFetch.set(id, op.ts.toString());\n            if (self._phase === PHASE.STEADY) {\n              self._fetchModifiedDocuments();\n            }\n            return;\n          }\n          self._handleDoc(id, self._sharedProjectionFn(newDoc));\n        } else if (!canDirectlyModifyDoc ||\n                   self._matcher.canBecomeTrueByModifier(op.o) ||\n                   (self._sorter && self._sorter.affectedByModifier(op.o))) {\n          self._needToFetch.set(id, op.ts.toString());\n          if (self._phase === PHASE.STEADY)\n            self._fetchModifiedDocuments();\n        }\n      } else {\n        throw Error(\"XXX SURPRISING OPERATION: \" + op);\n      }\n    });\n  },\n  // Yields!\n  _runInitialQuery: function () {\n    var self = this;\n    if (self._stopped)\n      throw new Error(\"oplog stopped surprisingly early\");\n\n    self._runQuery({initial: true});  // yields\n\n    if (self._stopped)\n      return;  // can happen on queryError\n\n    // Allow observeChanges calls to return. (After this, it's possible for\n    // stop() to be called.)\n    self._multiplexer.ready();\n\n    self._doneQuerying();  // yields\n  },\n\n  // In various circumstances, we may just want to stop processing the oplog and\n  // re-run the initial query, just as if we were a PollingObserveDriver.\n  //\n  // This function may not block, because it is called from an oplog entry\n  // handler.\n  //\n  // XXX We should call this when we detect that we've been in FETCHING for \"too\n  // long\".\n  //\n  // XXX We should call this when we detect Mongo failover (since that might\n  // mean that some of the oplog entries we have processed have been rolled\n  // back). The Node Mongo driver is in the middle of a bunch of huge\n  // refactorings, including the way that it notifies you when primary\n  // changes. Will put off implementing this until driver 1.4 is out.\n  _pollQuery: function () {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      if (self._stopped)\n        return;\n\n      // Yay, we get to forget about all the things we thought we had to fetch.\n      self._needToFetch = new LocalCollection._IdMap;\n      self._currentlyFetching = null;\n      ++self._fetchGeneration;  // ignore any in-flight fetches\n      self._registerPhaseChange(PHASE.QUERYING);\n\n      // Defer so that we don't yield.  We don't need finishIfNeedToPollQuery\n      // here because SwitchedToQuery is not thrown in QUERYING mode.\n      Meteor.defer(function () {\n        self._runQuery();\n        self._doneQuerying();\n      });\n    });\n  },\n\n  // Yields!\n  _runQuery: function (options) {\n    var self = this;\n    options = options || {};\n    var newResults, newBuffer;\n\n    // This while loop is just to retry failures.\n    while (true) {\n      // If we've been stopped, we don't have to run anything any more.\n      if (self._stopped)\n        return;\n\n      newResults = new LocalCollection._IdMap;\n      newBuffer = new LocalCollection._IdMap;\n\n      // Query 2x documents as the half excluded from the original query will go\n      // into unpublished buffer to reduce additional Mongo lookups in cases\n      // when documents are removed from the published set and need a\n      // replacement.\n      // XXX needs more thought on non-zero skip\n      // XXX 2 is a \"magic number\" meaning there is an extra chunk of docs for\n      // buffer if such is needed.\n      var cursor = self._cursorForQuery({ limit: self._limit * 2 });\n      try {\n        cursor.forEach(function (doc, i) {  // yields\n          if (!self._limit || i < self._limit) {\n            newResults.set(doc._id, doc);\n          } else {\n            newBuffer.set(doc._id, doc);\n          }\n        });\n        break;\n      } catch (e) {\n        if (options.initial && typeof(e.code) === 'number') {\n          // This is an error document sent to us by mongod, not a connection\n          // error generated by the client. And we've never seen this query work\n          // successfully. Probably it's a bad selector or something, so we\n          // should NOT retry. Instead, we should halt the observe (which ends\n          // up calling `stop` on us).\n          self._multiplexer.queryError(e);\n          return;\n        }\n\n        // During failover (eg) if we get an exception we should log and retry\n        // instead of crashing.\n        Meteor._debug(\"Got exception while polling query\", e);\n        Meteor._sleepForMs(100);\n      }\n    }\n\n    if (self._stopped)\n      return;\n\n    self._publishNewResults(newResults, newBuffer);\n  },\n\n  // Transitions to QUERYING and runs another query, or (if already in QUERYING)\n  // ensures that we will query again later.\n  //\n  // This function may not block, because it is called from an oplog entry\n  // handler. However, if we were not already in the QUERYING phase, it throws\n  // an exception that is caught by the closest surrounding\n  // finishIfNeedToPollQuery call; this ensures that we don't continue running\n  // close that was designed for another phase inside PHASE.QUERYING.\n  //\n  // (It's also necessary whenever logic in this file yields to check that other\n  // phases haven't put us into QUERYING mode, though; eg,\n  // _fetchModifiedDocuments does this.)\n  _needToPollQuery: function () {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      if (self._stopped)\n        return;\n\n      // If we're not already in the middle of a query, we can query now\n      // (possibly pausing FETCHING).\n      if (self._phase !== PHASE.QUERYING) {\n        self._pollQuery();\n        throw new SwitchedToQuery;\n      }\n\n      // We're currently in QUERYING. Set a flag to ensure that we run another\n      // query when we're done.\n      self._requeryWhenDoneThisQuery = true;\n    });\n  },\n\n  // Yields!\n  _doneQuerying: function () {\n    var self = this;\n\n    if (self._stopped)\n      return;\n    self._mongoHandle._oplogHandle.waitUntilCaughtUp();  // yields\n    if (self._stopped)\n      return;\n    if (self._phase !== PHASE.QUERYING)\n      throw Error(\"Phase unexpectedly \" + self._phase);\n\n    Meteor._noYieldsAllowed(function () {\n      if (self._requeryWhenDoneThisQuery) {\n        self._requeryWhenDoneThisQuery = false;\n        self._pollQuery();\n      } else if (self._needToFetch.empty()) {\n        self._beSteady();\n      } else {\n        self._fetchModifiedDocuments();\n      }\n    });\n  },\n\n  _cursorForQuery: function (optionsOverwrite) {\n    var self = this;\n    return Meteor._noYieldsAllowed(function () {\n      // The query we run is almost the same as the cursor we are observing,\n      // with a few changes. We need to read all the fields that are relevant to\n      // the selector, not just the fields we are going to publish (that's the\n      // \"shared\" projection). And we don't want to apply any transform in the\n      // cursor, because observeChanges shouldn't use the transform.\n      var options = _.clone(self._cursorDescription.options);\n\n      // Allow the caller to modify the options. Useful to specify different\n      // skip and limit values.\n      _.extend(options, optionsOverwrite);\n\n      options.fields = self._sharedProjection;\n      delete options.transform;\n      // We are NOT deep cloning fields or selector here, which should be OK.\n      var description = new CursorDescription(\n        self._cursorDescription.collectionName,\n        self._cursorDescription.selector,\n        options);\n      return new Cursor(self._mongoHandle, description);\n    });\n  },\n\n\n  // Replace self._published with newResults (both are IdMaps), invoking observe\n  // callbacks on the multiplexer.\n  // Replace self._unpublishedBuffer with newBuffer.\n  //\n  // XXX This is very similar to LocalCollection._diffQueryUnorderedChanges. We\n  // should really: (a) Unify IdMap and OrderedDict into Unordered/OrderedDict\n  // (b) Rewrite diff.js to use these classes instead of arrays and objects.\n  _publishNewResults: function (newResults, newBuffer) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n\n      // If the query is limited and there is a buffer, shut down so it doesn't\n      // stay in a way.\n      if (self._limit) {\n        self._unpublishedBuffer.clear();\n      }\n\n      // First remove anything that's gone. Be careful not to modify\n      // self._published while iterating over it.\n      var idsToRemove = [];\n      self._published.forEach(function (doc, id) {\n        if (!newResults.has(id))\n          idsToRemove.push(id);\n      });\n      _.each(idsToRemove, function (id) {\n        self._removePublished(id);\n      });\n\n      // Now do adds and changes.\n      // If self has a buffer and limit, the new fetched result will be\n      // limited correctly as the query has sort specifier.\n      newResults.forEach(function (doc, id) {\n        self._handleDoc(id, doc);\n      });\n\n      // Sanity-check that everything we tried to put into _published ended up\n      // there.\n      // XXX if this is slow, remove it later\n      if (self._published.size() !== newResults.size()) {\n        throw Error(\n          \"The Mongo server and the Meteor query disagree on how \" +\n            \"many documents match your query. Maybe it is hitting a Mongo \" +\n            \"edge case? The query is: \" +\n            EJSON.stringify(self._cursorDescription.selector));\n      }\n      self._published.forEach(function (doc, id) {\n        if (!newResults.has(id))\n          throw Error(\"_published has a doc that newResults doesn't; \" + id);\n      });\n\n      // Finally, replace the buffer\n      newBuffer.forEach(function (doc, id) {\n        self._addBuffered(id, doc);\n      });\n\n      self._safeAppendToBuffer = newBuffer.size() < self._limit;\n    });\n  },\n\n  // This stop function is invoked from the onStop of the ObserveMultiplexer, so\n  // it shouldn't actually be possible to call it until the multiplexer is\n  // ready.\n  //\n  // It's important to check self._stopped after every call in this file that\n  // can yield!\n  stop: function () {\n    var self = this;\n    if (self._stopped)\n      return;\n    self._stopped = true;\n    _.each(self._stopHandles, function (handle) {\n      handle.stop();\n    });\n\n    // Note: we *don't* use multiplexer.onFlush here because this stop\n    // callback is actually invoked by the multiplexer itself when it has\n    // determined that there are no handles left. So nothing is actually going\n    // to get flushed (and it's probably not valid to call methods on the\n    // dying multiplexer).\n    _.each(self._writesToCommitWhenWeReachSteady, function (w) {\n      w.committed();  // maybe yields?\n    });\n    self._writesToCommitWhenWeReachSteady = null;\n\n    // Proactively drop references to potentially big things.\n    self._published = null;\n    self._unpublishedBuffer = null;\n    self._needToFetch = null;\n    self._currentlyFetching = null;\n    self._oplogEntryHandle = null;\n    self._listenersHandle = null;\n\n    Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n      \"mongo-livedata\", \"observe-drivers-oplog\", -1);\n  },\n\n  _registerPhaseChange: function (phase) {\n    var self = this;\n    Meteor._noYieldsAllowed(function () {\n      var now = new Date;\n\n      if (self._phase) {\n        var timeDiff = now - self._phaseStartTime;\n        Package['facts-base'] && Package['facts-base'].Facts.incrementServerFact(\n          \"mongo-livedata\", \"time-spent-in-\" + self._phase + \"-phase\", timeDiff);\n      }\n\n      self._phase = phase;\n      self._phaseStartTime = now;\n    });\n  }\n});\n\n// Does our oplog tailing code support this cursor? For now, we are being very\n// conservative and allowing only simple queries with simple options.\n// (This is a \"static method\".)\nOplogObserveDriver.cursorSupported = function (cursorDescription, matcher) {\n  // First, check the options.\n  var options = cursorDescription.options;\n\n  // Did the user say no explicitly?\n  // underscored version of the option is COMPAT with 1.2\n  if (options.disableOplog || options._disableOplog)\n    return false;\n\n  // skip is not supported: to support it we would need to keep track of all\n  // \"skipped\" documents or at least their ids.\n  // limit w/o a sort specifier is not supported: current implementation needs a\n  // deterministic way to order documents.\n  if (options.skip || (options.limit && !options.sort)) return false;\n\n  // If a fields projection option is given check if it is supported by\n  // minimongo (some operators are not supported).\n  if (options.fields) {\n    try {\n      LocalCollection._checkSupportedProjection(options.fields);\n    } catch (e) {\n      if (e.name === \"MinimongoError\") {\n        return false;\n      } else {\n        throw e;\n      }\n    }\n  }\n\n  // We don't allow the following selectors:\n  //   - $where (not confident that we provide the same JS environment\n  //             as Mongo, and can yield!)\n  //   - $near (has \"interesting\" properties in MongoDB, like the possibility\n  //            of returning an ID multiple times, though even polling maybe\n  //            have a bug there)\n  //           XXX: once we support it, we would need to think more on how we\n  //           initialize the comparators when we create the driver.\n  return !matcher.hasWhere() && !matcher.hasGeoQuery();\n};\n\nvar modifierCanBeDirectlyApplied = function (modifier) {\n  return _.all(modifier, function (fields, operation) {\n    return _.all(fields, function (value, field) {\n      return !/EJSON\\$/.test(field);\n    });\n  });\n};\n\nMongoInternals.OplogObserveDriver = OplogObserveDriver;\n","// singleton\nexport const LocalCollectionDriver = new (class LocalCollectionDriver {\n  constructor() {\n    this.noConnCollections = Object.create(null);\n  }\n\n  open(name, conn) {\n    if (! name) {\n      return new LocalCollection;\n    }\n\n    if (! conn) {\n      return ensureCollection(name, this.noConnCollections);\n    }\n\n    if (! conn._mongo_livedata_collections) {\n      conn._mongo_livedata_collections = Object.create(null);\n    }\n\n    // XXX is there a way to keep track of a connection's collections without\n    // dangling it off the connection object?\n    return ensureCollection(name, conn._mongo_livedata_collections);\n  }\n});\n\nfunction ensureCollection(name, collections) {\n  return (name in collections)\n    ? collections[name]\n    : collections[name] = new LocalCollection(name);\n}\n","MongoInternals.RemoteCollectionDriver = function (\n  mongo_url, options) {\n  var self = this;\n  self.mongo = new MongoConnection(mongo_url, options);\n};\n\n_.extend(MongoInternals.RemoteCollectionDriver.prototype, {\n  open: function (name) {\n    var self = this;\n    var ret = {};\n    _.each(\n      ['find', 'findOne', 'insert', 'update', 'upsert',\n       'remove', '_ensureIndex', '_dropIndex', '_createCappedCollection',\n       'dropCollection', 'rawCollection'],\n      function (m) {\n        ret[m] = _.bind(self.mongo[m], self.mongo, name);\n      });\n    return ret;\n  }\n});\n\n\n// Create the singleton RemoteCollectionDriver only on demand, so we\n// only require Mongo configuration if it's actually used (eg, not if\n// you're only trying to receive data from a remote DDP server.)\nMongoInternals.defaultRemoteCollectionDriver = _.once(function () {\n  var connectionOptions = {};\n\n  var mongoUrl = process.env.MONGO_URL;\n\n  if (process.env.MONGO_OPLOG_URL) {\n    connectionOptions.oplogUrl = process.env.MONGO_OPLOG_URL;\n  }\n\n  if (! mongoUrl)\n    throw new Error(\"MONGO_URL must be set in environment\");\n\n  return new MongoInternals.RemoteCollectionDriver(mongoUrl, connectionOptions);\n});\n","// options.connection, if given, is a LivedataClient or LivedataServer\n// XXX presently there is no way to destroy/clean up a Collection\n\n/**\n * @summary Namespace for MongoDB-related items\n * @namespace\n */\nMongo = {};\n\n/**\n * @summary Constructor for a Collection\n * @locus Anywhere\n * @instancename collection\n * @class\n * @param {String} name The name of the collection.  If null, creates an unmanaged (unsynchronized) local collection.\n * @param {Object} [options]\n * @param {Object} options.connection The server connection that will manage this collection. Uses the default connection if not specified.  Pass the return value of calling [`DDP.connect`](#ddp_connect) to specify a different server. Pass `null` to specify no connection. Unmanaged (`name` is null) collections cannot specify a connection.\n * @param {String} options.idGeneration The method of generating the `_id` fields of new documents in this collection.  Possible values:\n\n - **`'STRING'`**: random strings\n - **`'MONGO'`**:  random [`Mongo.ObjectID`](#mongo_object_id) values\n\nThe default id generation technique is `'STRING'`.\n * @param {Function} options.transform An optional transformation function. Documents will be passed through this function before being returned from `fetch` or `findOne`, and before being passed to callbacks of `observe`, `map`, `forEach`, `allow`, and `deny`. Transforms are *not* applied for the callbacks of `observeChanges` or to cursors returned from publish functions.\n * @param {Boolean} options.defineMutationMethods Set to `false` to skip setting up the mutation methods that enable insert/update/remove from client code. Default `true`.\n */\nMongo.Collection = function Collection(name, options) {\n  if (!name && (name !== null)) {\n    Meteor._debug(\"Warning: creating anonymous collection. It will not be \" +\n                  \"saved or synchronized over the network. (Pass null for \" +\n                  \"the collection name to turn off this warning.)\");\n    name = null;\n  }\n\n  if (name !== null && typeof name !== \"string\") {\n    throw new Error(\n      \"First argument to new Mongo.Collection must be a string or null\");\n  }\n\n  if (options && options.methods) {\n    // Backwards compatibility hack with original signature (which passed\n    // \"connection\" directly instead of in options. (Connections must have a \"methods\"\n    // method.)\n    // XXX remove before 1.0\n    options = {connection: options};\n  }\n  // Backwards compatibility: \"connection\" used to be called \"manager\".\n  if (options && options.manager && !options.connection) {\n    options.connection = options.manager;\n  }\n\n  options = {\n    connection: undefined,\n    idGeneration: 'STRING',\n    transform: null,\n    _driver: undefined,\n    _preventAutopublish: false,\n      ...options,\n  };\n\n  switch (options.idGeneration) {\n  case 'MONGO':\n    this._makeNewID = function () {\n      var src = name ? DDP.randomStream('/collection/' + name) : Random.insecure;\n      return new Mongo.ObjectID(src.hexString(24));\n    };\n    break;\n  case 'STRING':\n  default:\n    this._makeNewID = function () {\n      var src = name ? DDP.randomStream('/collection/' + name) : Random.insecure;\n      return src.id();\n    };\n    break;\n  }\n\n  this._transform = LocalCollection.wrapTransform(options.transform);\n\n  if (! name || options.connection === null)\n    // note: nameless collections never have a connection\n    this._connection = null;\n  else if (options.connection)\n    this._connection = options.connection;\n  else if (Meteor.isClient)\n    this._connection = Meteor.connection;\n  else\n    this._connection = Meteor.server;\n\n  if (!options._driver) {\n    // XXX This check assumes that webapp is loaded so that Meteor.server !==\n    // null. We should fully support the case of \"want to use a Mongo-backed\n    // collection from Node code without webapp\", but we don't yet.\n    // #MeteorServerNull\n    if (name && this._connection === Meteor.server &&\n        typeof MongoInternals !== \"undefined\" &&\n        MongoInternals.defaultRemoteCollectionDriver) {\n      options._driver = MongoInternals.defaultRemoteCollectionDriver();\n    } else {\n      const { LocalCollectionDriver } =\n        require(\"./local_collection_driver.js\");\n      options._driver = LocalCollectionDriver;\n    }\n  }\n\n  this._collection = options._driver.open(name, this._connection);\n  this._name = name;\n  this._driver = options._driver;\n\n  this._maybeSetUpReplication(name, options);\n\n  // XXX don't define these until allow or deny is actually used for this\n  // collection. Could be hard if the security rules are only defined on the\n  // server.\n  if (options.defineMutationMethods !== false) {\n    try {\n      this._defineMutationMethods({\n        useExisting: options._suppressSameNameError === true\n      });\n    } catch (error) {\n      // Throw a more understandable error on the server for same collection name\n      if (error.message === `A method named '/${name}/insert' is already defined`)\n        throw new Error(`There is already a collection named \"${name}\"`);\n      throw error;\n    }\n  }\n\n  // autopublish\n  if (Package.autopublish &&\n      ! options._preventAutopublish &&\n      this._connection &&\n      this._connection.publish) {\n    this._connection.publish(null, () => this.find(), {\n      is_auto: true,\n    });\n  }\n};\n\nObject.assign(Mongo.Collection.prototype, {\n  _maybeSetUpReplication(name, {\n    _suppressSameNameError = false\n  }) {\n    const self = this;\n    if (! (self._connection &&\n           self._connection.registerStore)) {\n      return;\n    }\n\n    // OK, we're going to be a slave, replicating some remote\n    // database, except possibly with some temporary divergence while\n    // we have unacknowledged RPC's.\n    const ok = self._connection.registerStore(name, {\n      // Called at the beginning of a batch of updates. batchSize is the number\n      // of update calls to expect.\n      //\n      // XXX This interface is pretty janky. reset probably ought to go back to\n      // being its own function, and callers shouldn't have to calculate\n      // batchSize. The optimization of not calling pause/remove should be\n      // delayed until later: the first call to update() should buffer its\n      // message, and then we can either directly apply it at endUpdate time if\n      // it was the only update, or do pauseObservers/apply/apply at the next\n      // update() if there's another one.\n      beginUpdate(batchSize, reset) {\n        // pause observers so users don't see flicker when updating several\n        // objects at once (including the post-reconnect reset-and-reapply\n        // stage), and so that a re-sorting of a query can take advantage of the\n        // full _diffQuery moved calculation instead of applying change one at a\n        // time.\n        if (batchSize > 1 || reset)\n          self._collection.pauseObservers();\n\n        if (reset)\n          self._collection.remove({});\n      },\n\n      // Apply an update.\n      // XXX better specify this interface (not in terms of a wire message)?\n      update(msg) {\n        var mongoId = MongoID.idParse(msg.id);\n        var doc = self._collection.findOne(mongoId);\n\n        // Is this a \"replace the whole doc\" message coming from the quiescence\n        // of method writes to an object? (Note that 'undefined' is a valid\n        // value meaning \"remove it\".)\n        if (msg.msg === 'replace') {\n          var replace = msg.replace;\n          if (!replace) {\n            if (doc)\n              self._collection.remove(mongoId);\n          } else if (!doc) {\n            self._collection.insert(replace);\n          } else {\n            // XXX check that replace has no $ ops\n            self._collection.update(mongoId, replace);\n          }\n          return;\n        } else if (msg.msg === 'added') {\n          if (doc) {\n            throw new Error(\"Expected not to find a document already present for an add\");\n          }\n          self._collection.insert({ _id: mongoId, ...msg.fields });\n        } else if (msg.msg === 'removed') {\n          if (!doc)\n            throw new Error(\"Expected to find a document already present for removed\");\n          self._collection.remove(mongoId);\n        } else if (msg.msg === 'changed') {\n          if (!doc)\n            throw new Error(\"Expected to find a document to change\");\n          const keys = Object.keys(msg.fields);\n          if (keys.length > 0) {\n            var modifier = {};\n            keys.forEach(key => {\n              const value = msg.fields[key];\n              if (typeof value === \"undefined\") {\n                if (!modifier.$unset) {\n                  modifier.$unset = {};\n                }\n                modifier.$unset[key] = 1;\n              } else {\n                if (!modifier.$set) {\n                  modifier.$set = {};\n                }\n                modifier.$set[key] = value;\n              }\n            });\n            self._collection.update(mongoId, modifier);\n          }\n        } else {\n          throw new Error(\"I don't know how to deal with this message\");\n        }\n      },\n\n      // Called at the end of a batch of updates.\n      endUpdate() {\n        self._collection.resumeObservers();\n      },\n\n      // Called around method stub invocations to capture the original versions\n      // of modified documents.\n      saveOriginals() {\n        self._collection.saveOriginals();\n      },\n      retrieveOriginals() {\n        return self._collection.retrieveOriginals();\n      },\n\n      // Used to preserve current versions of documents across a store reset.\n      getDoc(id) {\n        return self.findOne(id);\n      },\n\n      // To be able to get back to the collection from the store.\n      _getCollection() {\n        return self;\n      }\n    });\n\n    if (! ok) {\n      const message = `There is already a collection named \"${name}\"`;\n      if (_suppressSameNameError === true) {\n        // XXX In theory we do not have to throw when `ok` is falsy. The\n        // store is already defined for this collection name, but this\n        // will simply be another reference to it and everything should\n        // work. However, we have historically thrown an error here, so\n        // for now we will skip the error only when _suppressSameNameError\n        // is `true`, allowing people to opt in and give this some real\n        // world testing.\n        console.warn ? console.warn(message) : console.log(message);\n      } else {\n        throw new Error(message);\n      }\n    }\n  },\n\n  ///\n  /// Main collection API\n  ///\n\n  _getFindSelector(args) {\n    if (args.length == 0)\n      return {};\n    else\n      return args[0];\n  },\n\n  _getFindOptions(args) {\n    var self = this;\n    if (args.length < 2) {\n      return { transform: self._transform };\n    } else {\n      check(args[1], Match.Optional(Match.ObjectIncluding({\n        fields: Match.Optional(Match.OneOf(Object, undefined)),\n        sort: Match.Optional(Match.OneOf(Object, Array, Function, undefined)),\n        limit: Match.Optional(Match.OneOf(Number, undefined)),\n        skip: Match.Optional(Match.OneOf(Number, undefined))\n      })));\n\n      return {\n        transform: self._transform,\n        ...args[1],\n      };\n    }\n  },\n\n  /**\n   * @summary Find the documents in a collection that match the selector.\n   * @locus Anywhere\n   * @method find\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} [selector] A query describing the documents to find\n   * @param {Object} [options]\n   * @param {MongoSortSpecifier} options.sort Sort order (default: natural order)\n   * @param {Number} options.skip Number of results to skip at the beginning\n   * @param {Number} options.limit Maximum number of results to return\n   * @param {MongoFieldSpecifier} options.fields Dictionary of fields to return or exclude.\n   * @param {Boolean} options.reactive (Client only) Default `true`; pass `false` to disable reactivity\n   * @param {Function} options.transform Overrides `transform` on the  [`Collection`](#collections) for this cursor.  Pass `null` to disable transformation.\n   * @param {Boolean} options.disableOplog (Server only) Pass true to disable oplog-tailing on this query. This affects the way server processes calls to `observe` on this query. Disabling the oplog can be useful when working with data that updates in large batches.\n   * @param {Number} options.pollingIntervalMs (Server only) When oplog is disabled (through the use of `disableOplog` or when otherwise not available), the frequency (in milliseconds) of how often to poll this query when observing on the server. Defaults to 10000ms (10 seconds).\n   * @param {Number} options.pollingThrottleMs (Server only) When oplog is disabled (through the use of `disableOplog` or when otherwise not available), the minimum time (in milliseconds) to allow between re-polling when observing on the server. Increasing this will save CPU and mongo load at the expense of slower updates to users. Decreasing this is not recommended. Defaults to 50ms.\n   * @param {Number} options.maxTimeMs (Server only) If set, instructs MongoDB to set a time limit for this cursor's operations. If the operation reaches the specified time limit (in milliseconds) without the having been completed, an exception will be thrown. Useful to prevent an (accidental or malicious) unoptimized query from causing a full collection scan that would disrupt other database users, at the expense of needing to handle the resulting error.\n   * @param {String|Object} options.hint (Server only) Overrides MongoDB's default index selection and query optimization process. Specify an index to force its use, either by its name or index specification. You can also specify `{ $natural : 1 }` to force a forwards collection scan, or `{ $natural : -1 }` for a reverse collection scan. Setting this is only recommended for advanced users.\n   * @returns {Mongo.Cursor}\n   */\n  find(...args) {\n    // Collection.find() (return all docs) behaves differently\n    // from Collection.find(undefined) (return 0 docs).  so be\n    // careful about the length of arguments.\n    return this._collection.find(\n      this._getFindSelector(args),\n      this._getFindOptions(args)\n    );\n  },\n\n  /**\n   * @summary Finds the first document that matches the selector, as ordered by sort and skip options. Returns `undefined` if no matching document is found.\n   * @locus Anywhere\n   * @method findOne\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} [selector] A query describing the documents to find\n   * @param {Object} [options]\n   * @param {MongoSortSpecifier} options.sort Sort order (default: natural order)\n   * @param {Number} options.skip Number of results to skip at the beginning\n   * @param {MongoFieldSpecifier} options.fields Dictionary of fields to return or exclude.\n   * @param {Boolean} options.reactive (Client only) Default true; pass false to disable reactivity\n   * @param {Function} options.transform Overrides `transform` on the [`Collection`](#collections) for this cursor.  Pass `null` to disable transformation.\n   * @returns {Object}\n   */\n  findOne(...args) {\n    return this._collection.findOne(\n      this._getFindSelector(args),\n      this._getFindOptions(args)\n    );\n  }\n});\n\nObject.assign(Mongo.Collection, {\n  _publishCursor(cursor, sub, collection) {\n    var observeHandle = cursor.observeChanges({\n      added: function (id, fields) {\n        sub.added(collection, id, fields);\n      },\n      changed: function (id, fields) {\n        sub.changed(collection, id, fields);\n      },\n      removed: function (id) {\n        sub.removed(collection, id);\n      }\n    });\n\n    // We don't call sub.ready() here: it gets called in livedata_server, after\n    // possibly calling _publishCursor on multiple returned cursors.\n\n    // register stop callback (expects lambda w/ no args).\n    sub.onStop(function () {\n      observeHandle.stop();\n    });\n\n    // return the observeHandle in case it needs to be stopped early\n    return observeHandle;\n  },\n\n  // protect against dangerous selectors.  falsey and {_id: falsey} are both\n  // likely programmer error, and not what you want, particularly for destructive\n  // operations. If a falsey _id is sent in, a new string _id will be\n  // generated and returned; if a fallbackId is provided, it will be returned\n  // instead.\n  _rewriteSelector(selector, { fallbackId } = {}) {\n    // shorthand -- scalars match _id\n    if (LocalCollection._selectorIsId(selector))\n      selector = {_id: selector};\n\n    if (Array.isArray(selector)) {\n      // This is consistent with the Mongo console itself; if we don't do this\n      // check passing an empty array ends up selecting all items\n      throw new Error(\"Mongo selector can't be an array.\");\n    }\n\n    if (!selector || (('_id' in selector) && !selector._id)) {\n      // can't match anything\n      return { _id: fallbackId || Random.id() };\n    }\n\n    return selector;\n  }\n});\n\nObject.assign(Mongo.Collection.prototype, {\n  // 'insert' immediately returns the inserted document's new _id.\n  // The others return values immediately if you are in a stub, an in-memory\n  // unmanaged collection, or a mongo-backed collection and you don't pass a\n  // callback. 'update' and 'remove' return the number of affected\n  // documents. 'upsert' returns an object with keys 'numberAffected' and, if an\n  // insert happened, 'insertedId'.\n  //\n  // Otherwise, the semantics are exactly like other methods: they take\n  // a callback as an optional last argument; if no callback is\n  // provided, they block until the operation is complete, and throw an\n  // exception if it fails; if a callback is provided, then they don't\n  // necessarily block, and they call the callback when they finish with error and\n  // result arguments.  (The insert method provides the document ID as its result;\n  // update and remove provide the number of affected docs as the result; upsert\n  // provides an object with numberAffected and maybe insertedId.)\n  //\n  // On the client, blocking is impossible, so if a callback\n  // isn't provided, they just return immediately and any error\n  // information is lost.\n  //\n  // There's one more tweak. On the client, if you don't provide a\n  // callback, then if there is an error, a message will be logged with\n  // Meteor._debug.\n  //\n  // The intent (though this is actually determined by the underlying\n  // drivers) is that the operations should be done synchronously, not\n  // generating their result until the database has acknowledged\n  // them. In the future maybe we should provide a flag to turn this\n  // off.\n\n  /**\n   * @summary Insert a document in the collection.  Returns its unique _id.\n   * @locus Anywhere\n   * @method  insert\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {Object} doc The document to insert. May not yet have an _id attribute, in which case Meteor will generate one for you.\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the _id as the second.\n   */\n  insert(doc, callback) {\n    // Make sure we were passed a document to insert\n    if (!doc) {\n      throw new Error(\"insert requires an argument\");\n    }\n\n    // Make a shallow clone of the document, preserving its prototype.\n    doc = Object.create(\n      Object.getPrototypeOf(doc),\n      Object.getOwnPropertyDescriptors(doc)\n    );\n\n    if ('_id' in doc) {\n      if (! doc._id ||\n          ! (typeof doc._id === 'string' ||\n             doc._id instanceof Mongo.ObjectID)) {\n        throw new Error(\n          \"Meteor requires document _id fields to be non-empty strings or ObjectIDs\");\n      }\n    } else {\n      let generateId = true;\n\n      // Don't generate the id if we're the client and the 'outermost' call\n      // This optimization saves us passing both the randomSeed and the id\n      // Passing both is redundant.\n      if (this._isRemoteCollection()) {\n        const enclosing = DDP._CurrentMethodInvocation.get();\n        if (!enclosing) {\n          generateId = false;\n        }\n      }\n\n      if (generateId) {\n        doc._id = this._makeNewID();\n      }\n    }\n\n    // On inserts, always return the id that we generated; on all other\n    // operations, just return the result from the collection.\n    var chooseReturnValueFromCollectionResult = function (result) {\n      if (doc._id) {\n        return doc._id;\n      }\n\n      // XXX what is this for??\n      // It's some iteraction between the callback to _callMutatorMethod and\n      // the return value conversion\n      doc._id = result;\n\n      return result;\n    };\n\n    const wrappedCallback = wrapCallback(\n      callback, chooseReturnValueFromCollectionResult);\n\n    if (this._isRemoteCollection()) {\n      const result = this._callMutatorMethod(\"insert\", [doc], wrappedCallback);\n      return chooseReturnValueFromCollectionResult(result);\n    }\n\n    // it's my collection.  descend into the collection object\n    // and propagate any exception.\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      const result = this._collection.insert(doc, wrappedCallback);\n      return chooseReturnValueFromCollectionResult(result);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n      throw e;\n    }\n  },\n\n  /**\n   * @summary Modify one or more documents in the collection. Returns the number of matched documents.\n   * @locus Anywhere\n   * @method update\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to modify\n   * @param {MongoModifier} modifier Specifies how to modify the documents\n   * @param {Object} [options]\n   * @param {Boolean} options.multi True to modify all matching documents; false to only modify one of the matching documents (the default).\n   * @param {Boolean} options.upsert True to insert a document if no matching documents are found.\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the number of affected documents as the second.\n   */\n  update(selector, modifier, ...optionsAndCallback) {\n    const callback = popCallbackFromArgs(optionsAndCallback);\n\n    // We've already popped off the callback, so we are left with an array\n    // of one or zero items\n    const options = { ...(optionsAndCallback[0] || null) };\n    let insertedId;\n    if (options && options.upsert) {\n      // set `insertedId` if absent.  `insertedId` is a Meteor extension.\n      if (options.insertedId) {\n        if (!(typeof options.insertedId === 'string' || options.insertedId instanceof Mongo.ObjectID))\n          throw new Error(\"insertedId must be string or ObjectID\");\n        insertedId = options.insertedId;\n      } else if (!selector || !selector._id) {\n        insertedId = this._makeNewID();\n        options.generatedId = true;\n        options.insertedId = insertedId;\n      }\n    }\n\n    selector =\n      Mongo.Collection._rewriteSelector(selector, { fallbackId: insertedId });\n\n    const wrappedCallback = wrapCallback(callback);\n\n    if (this._isRemoteCollection()) {\n      const args = [\n        selector,\n        modifier,\n        options\n      ];\n\n      return this._callMutatorMethod(\"update\", args, wrappedCallback);\n    }\n\n    // it's my collection.  descend into the collection object\n    // and propagate any exception.\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      return this._collection.update(\n        selector, modifier, options, wrappedCallback);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n      throw e;\n    }\n  },\n\n  /**\n   * @summary Remove documents from the collection\n   * @locus Anywhere\n   * @method remove\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to remove\n   * @param {Function} [callback] Optional.  If present, called with an error object as its argument.\n   */\n  remove(selector, callback) {\n    selector = Mongo.Collection._rewriteSelector(selector);\n\n    const wrappedCallback = wrapCallback(callback);\n\n    if (this._isRemoteCollection()) {\n      return this._callMutatorMethod(\"remove\", [selector], wrappedCallback);\n    }\n\n    // it's my collection.  descend into the collection object\n    // and propagate any exception.\n    try {\n      // If the user provided a callback and the collection implements this\n      // operation asynchronously, then queryRet will be undefined, and the\n      // result will be returned through the callback instead.\n      return this._collection.remove(selector, wrappedCallback);\n    } catch (e) {\n      if (callback) {\n        callback(e);\n        return null;\n      }\n      throw e;\n    }\n  },\n\n  // Determine if this collection is simply a minimongo representation of a real\n  // database on another server\n  _isRemoteCollection() {\n    // XXX see #MeteorServerNull\n    return this._connection && this._connection !== Meteor.server;\n  },\n\n  /**\n   * @summary Modify one or more documents in the collection, or insert one if no matching documents were found. Returns an object with keys `numberAffected` (the number of documents modified)  and `insertedId` (the unique _id of the document that was inserted, if any).\n   * @locus Anywhere\n   * @method upsert\n   * @memberof Mongo.Collection\n   * @instance\n   * @param {MongoSelector} selector Specifies which documents to modify\n   * @param {MongoModifier} modifier Specifies how to modify the documents\n   * @param {Object} [options]\n   * @param {Boolean} options.multi True to modify all matching documents; false to only modify one of the matching documents (the default).\n   * @param {Function} [callback] Optional.  If present, called with an error object as the first argument and, if no error, the number of affected documents as the second.\n   */\n  upsert(selector, modifier, options, callback) {\n    if (! callback && typeof options === \"function\") {\n      callback = options;\n      options = {};\n    }\n\n    return this.update(selector, modifier, {\n      ...options,\n      _returnObject: true,\n      upsert: true,\n    }, callback);\n  },\n\n  // We'll actually design an index API later. For now, we just pass through to\n  // Mongo's, but make it synchronous.\n  _ensureIndex(index, options) {\n    var self = this;\n    if (!self._collection._ensureIndex)\n      throw new Error(\"Can only call _ensureIndex on server collections\");\n    self._collection._ensureIndex(index, options);\n  },\n\n  _dropIndex(index) {\n    var self = this;\n    if (!self._collection._dropIndex)\n      throw new Error(\"Can only call _dropIndex on server collections\");\n    self._collection._dropIndex(index);\n  },\n\n  _dropCollection() {\n    var self = this;\n    if (!self._collection.dropCollection)\n      throw new Error(\"Can only call _dropCollection on server collections\");\n    self._collection.dropCollection();\n  },\n\n  _createCappedCollection(byteSize, maxDocuments) {\n    var self = this;\n    if (!self._collection._createCappedCollection)\n      throw new Error(\"Can only call _createCappedCollection on server collections\");\n    self._collection._createCappedCollection(byteSize, maxDocuments);\n  },\n\n  /**\n   * @summary Returns the [`Collection`](http://mongodb.github.io/node-mongodb-native/2.2/api/Collection.html) object corresponding to this collection from the [npm `mongodb` driver module](https://www.npmjs.com/package/mongodb) which is wrapped by `Mongo.Collection`.\n   * @locus Server\n   */\n  rawCollection() {\n    var self = this;\n    if (! self._collection.rawCollection) {\n      throw new Error(\"Can only call rawCollection on server collections\");\n    }\n    return self._collection.rawCollection();\n  },\n\n  /**\n   * @summary Returns the [`Db`](http://mongodb.github.io/node-mongodb-native/2.2/api/Db.html) object corresponding to this collection's database connection from the [npm `mongodb` driver module](https://www.npmjs.com/package/mongodb) which is wrapped by `Mongo.Collection`.\n   * @locus Server\n   */\n  rawDatabase() {\n    var self = this;\n    if (! (self._driver.mongo && self._driver.mongo.db)) {\n      throw new Error(\"Can only call rawDatabase on server collections\");\n    }\n    return self._driver.mongo.db;\n  }\n});\n\n// Convert the callback to not return a result if there is an error\nfunction wrapCallback(callback, convertResult) {\n  return callback && function (error, result) {\n    if (error) {\n      callback(error);\n    } else if (typeof convertResult === \"function\") {\n      callback(null, convertResult(result));\n    } else {\n      callback(null, result);\n    }\n  };\n}\n\n/**\n * @summary Create a Mongo-style `ObjectID`.  If you don't specify a `hexString`, the `ObjectID` will generated randomly (not using MongoDB's ID construction rules).\n * @locus Anywhere\n * @class\n * @param {String} [hexString] Optional.  The 24-character hexadecimal contents of the ObjectID to create\n */\nMongo.ObjectID = MongoID.ObjectID;\n\n/**\n * @summary To create a cursor, use find. To access the documents in a cursor, use forEach, map, or fetch.\n * @class\n * @instanceName cursor\n */\nMongo.Cursor = LocalCollection.Cursor;\n\n/**\n * @deprecated in 0.9.1\n */\nMongo.Collection.Cursor = Mongo.Cursor;\n\n/**\n * @deprecated in 0.9.1\n */\nMongo.Collection.ObjectID = Mongo.ObjectID;\n\n/**\n * @deprecated in 0.9.1\n */\nMeteor.Collection = Mongo.Collection;\n\n// Allow deny stuff is now in the allow-deny package\nObject.assign(\n  Meteor.Collection.prototype,\n  AllowDeny.CollectionPrototype\n);\n\nfunction popCallbackFromArgs(args) {\n  // Pull off any callback (or perhaps a 'callback' variable that was passed\n  // in undefined, like how 'upsert' does it).\n  if (args.length &&\n      (args[args.length - 1] === undefined ||\n       args[args.length - 1] instanceof Function)) {\n    return args.pop();\n  }\n}\n","/**\n * @summary Allows for user specified connection options\n * @example http://mongodb.github.io/node-mongodb-native/2.2/reference/connecting/connection-settings/\n * @locus Server\n * @param {Object} options User specified Mongo connection options\n */\nMongo.setConnectionOptions = function setConnectionOptions (options) {\n  check(options, Object);\n  Mongo._connectionOptions = options;\n};"]}}]